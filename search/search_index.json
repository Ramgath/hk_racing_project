{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"decisions/","title":"Key Project Decisions","text":"<p>This document tracks the major design and process decisions for the HK Racing Project, along with context, alternatives considered, and rationale.</p> Date Decision Aspect Alternatives Considered Rationale / Notes 2025-05-04 Use MkDocs + Material theme for docs site Documentation GitHub Pages from <code>/docs</code>, Jekyll Better theming, built-in nav sidebar 2025-05-04 Deploy docs via GitHub Actions to <code>gh-pages</code> CI/CD Manual Pages from <code>/docs</code> folder Full control over build, future plugins 2025-05-05 Design repo for AI-only assistance; skip human-centric features Repository Setup Public repo setup, contributor templates, open-source guidelines Ensures proprietary strategies remain private, limits liability; sharing steps can be added later 2025-05-06 Configure pre-commit hooks for code and notebooks Tooling Manual formatting, commit-by-commit cleaning Automate code style enforcement and strip notebook outputs 2025-05-06 Add GitHub Actions workflows for CI and docs deploy CI/CD Manual test and docs builds Automatically lint, test, and deploy docs on push 2025-05-06 Establish branch protection rules on main Process Unrestricted direct pushes Ensure all changes are reviewed and pass CI before merge 2025-05-06 Create GitHub issue and PR templates Process Freeform issues and PR descriptions Standardize issue reporting and PR reviews 2025-05-06 Scaffold Makefile and setup scripts for environment Developer DX Manual venv creation and pip installs Provide reproducible one-command environment bootstrapping 2025-05-06 Rolled back branch protection rules for personal repo Process Enforced PR and status checks Simplify workflow for solo development; allow direct pushes 2025-05-08 Updated GitHub Pages setup and streamlined milestone tracking Documentation, Project Management Manual tracking, individual project boards Simplify the process with GitHub Issues and checkboxes for clarity and task management 2025-05-08 Remove GitHub Project board and house issues in Markdown Process Online project board Centralize issue tracking within repository docs 2025-05-09 Consolidate all phases plans into 1 master plan Project Managment Have each phase plan in each phase md file Centralize plan 2025-05-09 Phase .md files to house reports and findings only Project Management Treat each phase as a separate project with a dedicated plan Separates plan from results. 2025-05-XX (future decision)"},{"location":"master-plan/","title":"Hong Kong Racing Project: Master Plan","text":"<p>This document outlines the technical plan for building a handicapping and wagering system for thoroughbred horse racing in Hong Kong, with the primary objective of achieving sustainable financial gain through data-driven strategies. It serves as the central reference for project scope, methodology, and planned execution across all phases.</p>"},{"location":"master-plan/#1-project-definition-and-establishment","title":"1. Project Definition and Establishment","text":""},{"location":"master-plan/#11-introduction-and-aims","title":"1.1. Introduction and Aims","text":""},{"location":"master-plan/#111-project-objective","title":"1.1.1. Project Objective","text":"<ul> <li>Goal: Develop and implement a machine learning-based handicapping and wagering system aimed at generating a positive return on investment (ROI) from Hong Kong horse racing.</li> <li>Team: Solo project with assistance from AI (e.g., Google Gemini).</li> <li>Broader Context: This project focuses on the technical development of a predictive system for financial gain within the domain of horse race wagering. It's acknowledged that this operates within the context of gambling, and responsible practices should guide any potential future application of the system's outputs.</li> </ul>"},{"location":"master-plan/#112-document-purpose","title":"1.1.2. Document Purpose","text":"<p>This <code>project_plan.md</code> (and the accompanying MkDocs site) serves several key purposes:</p> <ul> <li>Centralized Record: Acts as the primary repository for documenting all project plans, methodologies, data sources, and strategic decisions made throughout the project lifecycle.</li> <li>Shared Context for AI Collaboration: Functions as a persistent memory and context for ongoing work and discussions with AI assistants. Referencing and updating this plan and related phase reports ensures continuity.</li> <li>Single Source of Truth: Establishes a definitive reference point for the project's scope, workflow, tools, and challenges.</li> <li>Tracking Evolution: While this document outlines the plan, individual phase reports (<code>docs/phase-XX-name.md</code>) will track the execution and evolution of the project.</li> </ul>"},{"location":"master-plan/#12-resource-and-environment-configuration","title":"1.2. Resource and Environment Configuration","text":""},{"location":"master-plan/#121-hardware","title":"1.2.1. Hardware","text":"<ul> <li>Local machine: MacBook Air, 8GB RAM, Apple Silicon (M1 chip).</li> <li>Online: Standard Colab CPU Environment (e.g., Intel Xeon, ~13 GB RAM). Google Colab free tier also provides variable access to GPU and TPU accelerators.</li> </ul>"},{"location":"master-plan/#122-software-and-cloud-services-primarily-google-ecosystem","title":"1.2.2. Software and Cloud Services (Primarily Google Ecosystem)","text":"<ul> <li>Google BigQuery: Central data warehouse for storing historical and current race data. Chosen for scalability, Colab integration, and cost-effectiveness within its free tier.</li> <li>Google Colab: Primary environment for data scraping, cleaning, analysis, feature engineering, visualization, and ML model development.</li> <li>Google Sheets: Used as an intermediary data hub, for manual input/correction if necessary, and potentially for controlling updates via Apps Script (original plan).</li> <li>Google Apps Script: Planned for automating data update processes (e.g., Sheets to BigQuery).</li> <li>Google Cloud Storage (GCS): Considered for intermediary data storage (e.g., Parquet files) to optimize data transfer between BigQuery and Colab.</li> <li>Python Libraries:<ul> <li>Data Acquisition: Beautiful Soup (or potentially Playwright/Selenium if dynamic content requires it).</li> <li>Data Manipulation &amp; Analysis: pandas, NumPy, Polars.</li> <li>Cloud Interaction: <code>google-cloud-bigquery</code>, <code>gspread</code>.</li> <li>Visualization: Plotly, Matplotlib, Seaborn.</li> <li>Machine Learning: Scikit-learn, TensorFlow, PyTorch, XGBoost, LightGBM (specific choices in modeling phase).</li> </ul> </li> <li>Version Control: Git, managed via a GitHub repository.</li> <li>Documentation: MkDocs with the Material theme.</li> </ul>"},{"location":"master-plan/#123-development-environment","title":"1.2.3. Development Environment","text":"<ul> <li>Google Colab: Primary for computationally intensive tasks (data processing, ML).</li> <li>Visual Studio Code (VS Code) - Local: For developing helper scripts, managing the project repository, and MkDocs site generation/preview.</li> </ul>"},{"location":"master-plan/#13-proposed-workflow-outline-original-hybrid-concept","title":"1.3. Proposed Workflow Outline (Original Hybrid Concept)","text":""},{"location":"master-plan/#131-rationale-for-hybrid-workflow-sheets-bigquery-colab","title":"1.3.1. Rationale for Hybrid Workflow (Sheets -&gt; BigQuery -&gt; Colab)","text":"<p>(This section reflects the original thinking from the Google Doc. The actual implementation might evolve and will be documented in phase reports.) The initially chosen workflow utilized a hybrid approach: Google Sheets (for easily editable data), BigQuery (External Tables linking to Sheets, then materializing into Native Tables for performance), and Google Colab for analysis and ML.</p> <ul> <li>Ease of Data Correction: Sheets as the primary editable source.</li> <li>Analytical Performance: Native BigQuery tables for querying.</li> <li>Scalability: BigQuery's inherent scalability.</li> <li>Resource Efficiency: Colab for computation.</li> <li>Integration &amp; Control: Google ecosystem synergy.</li> <li>Cost-Effectiveness: Leveraging free tiers.</li> </ul>"},{"location":"master-plan/#132-alternative-methodologies-considered-original-assessment","title":"1.3.2. Alternative Methodologies Considered (Original Assessment)","text":"<ul> <li>DuckDB (Local) + Colab: Rejected due to local RAM limits and less straightforward data correction than Sheets.</li> <li>Pandas/Polars (Local only): Rejected due to RAM limits and lack of persistence/scalability.</li> <li>SQLite (Local): Rejected due to performance for analytical queries and local resource limits.</li> <li>PostgreSQL (Local): Rejected due to overhead on local hardware.</li> <li>Snowflake (Cloud): Rejected due to lack of a comparable free tier to BigQuery.</li> </ul>"},{"location":"master-plan/#phase-1-data-collection-and-storage","title":"Phase 1: Data Collection and Storage","text":"<p>(This phase focuses on acquiring all necessary raw data and establishing initial storage.)</p>"},{"location":"master-plan/#11-data-sources","title":"1.1. Data Sources","text":"<ul> <li>Primary Source: Hong Kong Jockey Club (HKJC) official website.</li> <li>Data Types: Racecards (upcoming races), race results (historical), horse details, trackwork records, stewards' reports, etc.</li> <li>Historical Data Consideration: An initial dataset was acquired from a third-party vendor (pre-December 2023) with known minor inconsistencies. Data from December 2023 onwards is to be scraped directly. The project will prioritize direct scraping for ongoing data integrity.</li> </ul>"},{"location":"master-plan/#12-data-acquisition-methodology","title":"1.2. Data Acquisition Methodology","text":"<ul> <li>Primary Method: Web scraping using Python libraries (e.g., Beautiful Soup, potentially Playwright/Selenium if needed for dynamic content) executed in Google Colab or local scripts.</li> <li>API Limitations: HKJC does not offer a public API for comprehensive race data, necessitating web scraping.</li> <li>Scope per Session: Scraping will likely be batched (e.g., per race day) to manage load and avoid detection.</li> <li>Maintenance: Scraping scripts will require ongoing maintenance due to potential HKJC website changes.</li> </ul>"},{"location":"master-plan/#13-preliminary-data-formatting-post-scraping","title":"1.3. Preliminary Data Formatting (Post-Scraping)","text":"<ul> <li>Environment: Google Colab or local Python scripts.</li> <li>Objective: Ensure consistency, accuracy, and control over data format before storage. Includes data type enforcement, string manipulation, and basic structural validation.</li> <li>Rationale: Python scripts provide reproducibility and can handle complex logic more robustly than manual formatting or simple spreadsheet functions.</li> </ul>"},{"location":"master-plan/#14-data-storage-strategy","title":"1.4. Data Storage Strategy","text":"<ul> <li>Raw Data Storage: Initially, scraped data might be stored in flat files (JSON, CSV) in Google Cloud Storage or locally.</li> <li>Structured Data Storage: Google BigQuery will serve as the primary data warehouse for cleansed and structured data.<ul> <li>Schema Definition: A detailed data dictionary (see Appendix A) will define table structures and field types in BigQuery.</li> </ul> </li> <li>Intermediary Storage (Original Plan): Google Sheets was considered as an editable central repository before loading to BigQuery. This may be revised for a more direct GCS/local files to BigQuery pipeline.</li> <li>Partitioning: For BigQuery tables, partitioning (e.g., by race date/year) will be considered if data volume grows significantly, to optimize query performance and costs. Not planned initially given projected data sizes.</li> <li>Update Frequency: New race data will be collected and processed typically twice weekly, aligned with the HKJC racing calendar. The process will be automated as much as possible.</li> </ul>"},{"location":"master-plan/#phase-2-data-cleansing-and-preprocessing","title":"Phase 2: Data Cleansing and Preprocessing","text":"<p>(This phase focuses on transforming raw collected data into a clean, consistent, and usable dataset.)</p>"},{"location":"master-plan/#21-overview-of-collected-data","title":"2.1. Overview of Collected Data","text":"<p>The dataset will encompass: * Race identification and context (Date, Course, Race Number, Class, Distance, Going, Prize Money, etc.). * Horse performance metrics (Finishing Place, Finish Time, Sectional Times, Weight Carried, Draw, etc.). * Betting information (Win/Place Odds). * Jockey and Trainer details. * Pre-race horse information (Horse Weight, Rating, Rest Days, Gear, etc.). * (Refer to Appendix A: Data Dictionary for detailed schema).</p>"},{"location":"master-plan/#22-cleansing-procedure","title":"2.2. Cleansing Procedure","text":"<ul> <li>Environment: Primarily Google Colab or local Python scripts, with results stored in BigQuery.</li> <li>Key Steps:<ul> <li>Data Type Enforcement: Ensure columns match predefined types (integer, float, string, date).</li> <li>String Manipulation: Trim whitespace, standardize capitalization, handle special characters.</li> <li>Categorical Value Standardization: Ensure consistency in fields like <code>COURSE</code>, <code>CLASS</code>, <code>GOING</code>. Map variations to standard values.</li> <li>Handling Specific Non-Numeric/Placeholder Strings: Address values like 'UNRATED', 'GRIFFIN', 'DEBUT' in fields that are otherwise numeric or categorical.</li> <li>Addressing Known Inconsistencies: Programmatic fixes for known issues in historical data.</li> </ul> </li> </ul>"},{"location":"master-plan/#23-data-validation-and-format-consistency","title":"2.3. Data Validation and Format Consistency","text":"<ul> <li>Objective: Rigorously validate data against the schema in Appendix A.</li> <li>Checks: Data type verification, value range checks, categorical value consistency, basic relational integrity checks (e.g., consistent IDs).</li> <li>Discrepancy Handling: Refine cleansing scripts or (as a last resort for historical data) document manual corrections.</li> </ul>"},{"location":"master-plan/#24-management-of-missing-valuesoutliers","title":"2.4. Management of Missing Values/Outliers","text":"<ul> <li>Approach: Strategies will be determined based on EDA findings (Phase 3) and model requirements.</li> <li>Missing Values: Options include deletion (rows/columns), mean/median/mode imputation, regression imputation, or model-based imputation.</li> <li>Outliers: Identification (e.g., IQR, Z-scores) followed by potential capping, transformation, or removal.</li> </ul>"},{"location":"master-plan/#25-data-transformation-preparation-for-modeling","title":"2.5. Data Transformation (Preparation for Modeling)","text":"<ul> <li>Encoding Categorical Variables: Convert string categories (e.g., <code>CLASS</code>, <code>GOING</code>) into numerical representations (One-Hot, Label, Target Encoding).</li> <li>Numerical Scaling: Apply standardization or normalization if required by specific models.</li> <li>Other Transformations: Log transforms, polynomial features, etc., based on EDA and model needs.</li> </ul>"},{"location":"master-plan/#phase-3-exploratory-data-analysis-eda","title":"Phase 3: Exploratory Data Analysis (EDA)","text":"<p>(This phase focuses on understanding the data through querying, statistics, and visualizations to uncover patterns and formulate hypotheses.)</p>"},{"location":"master-plan/#31-data-querying","title":"3.1. Data Querying","text":"<ul> <li>Source: Cleansed data tables in Google BigQuery.</li> <li>Environment: Google Colab using the <code>google-cloud-bigquery</code> Python library.</li> <li>Process: Construct SQL queries in Colab, execute against BigQuery, load results into Pandas/Polars DataFrames for analysis.</li> </ul>"},{"location":"master-plan/#32-descriptive-statistics","title":"3.2. Descriptive Statistics","text":"<ul> <li>Tools: Python libraries (Pandas, NumPy) in Colab.</li> <li>Numerical Variables: Calculate count, mean, median, std dev, min, max, percentiles, skewness, kurtosis.</li> <li>Categorical Variables: Frequency counts, unique values, mode.</li> </ul>"},{"location":"master-plan/#33-visualization","title":"3.3. Visualization","text":"<ul> <li>Primary Tool: Plotly for interactive plots in Colab. Seaborn and Matplotlib as alternatives.</li> <li>Univariate Analysis: Histograms, density plots, box plots, bar charts.</li> <li>Bivariate/Multivariate Analysis: Scatter plots, correlation heatmaps, grouped plots, time series plots (if applicable).</li> </ul>"},{"location":"master-plan/#34-initial-observations-and-hypothesis-formulation","title":"3.4. Initial Observations and Hypothesis Formulation","text":"<ul> <li>Synthesize findings from statistics and visualizations.</li> <li>Identify significant patterns, trends, anomalies, and correlations.</li> <li>Formulate initial hypotheses about factors influencing race outcomes.</li> <li>Identify areas needing further investigation. These insights will guide Feature Engineering (Phase 4).</li> </ul>"},{"location":"master-plan/#phase-4-feature-engineering","title":"Phase 4: Feature Engineering","text":"<p>(This phase focuses on creating new, potentially more predictive variables from the cleaned dataset.)</p>"},{"location":"master-plan/#41-methodology","title":"4.1. Methodology","text":"<ul> <li>Environment: Google Colab using Pandas, NumPy, Polars, and Scikit-learn.</li> <li>Approach: Iterative process based on domain knowledge, EDA insights, and preliminary model testing.</li> <li>Goal: Transform base data into a richer feature set that captures complex racing dynamics.</li> </ul>"},{"location":"master-plan/#42-initial-feature-set","title":"4.2. Initial Feature Set","text":"<ul> <li>The starting point is the cleansed, validated dataset (approx. 40-50 core variables as per Appendix A).</li> </ul>"},{"location":"master-plan/#43-target-feature-set","title":"4.3. Target Feature Set","text":"<ul> <li>Strategically expand the initial set. The focus is on developing hypothesized predictive features and validating their impact, rather than a fixed target number of features.</li> </ul>"},{"location":"master-plan/#44-example-categories-of-engineered-features","title":"4.4. Example Categories of Engineered Features","text":"<ul> <li>Form &amp; Consistency: Rolling win/place percentages, average finishing position (recent races), days since last win.</li> <li>Speed &amp; Pace: Calculated speed figures, sectional speed ratings, comparisons to class/distance/track averages.</li> <li>Jockey/Trainer Statistics: Win/place rates (overall, by course, distance, class, horse combination), recent form.</li> <li>Odds-Based Features: Odds movement (if available), probability derived from odds, value indicators (odds vs. finish).</li> <li>Class &amp; Weight Related: Rating relative to class, weight carried relative to past or standard weights.</li> <li>Interaction &amp; Derived Features: Jockey win rate on this course, horse average speed at this distance.</li> <li>Lagged Variables: Performance metrics from the previous race.</li> </ul>"},{"location":"master-plan/#45-feature-engineering-approach","title":"4.5. Feature Engineering Approach","text":"<ul> <li>Iterative: Develop, test (correlation, feature importance from simple models, backtesting), refine/discard.</li> <li>New ideas may emerge during modeling and evaluation.</li> </ul>"},{"location":"master-plan/#46-roles-of-bigquery-and-colab","title":"4.6. Roles of BigQuery and Colab","text":"<ul> <li>BigQuery: Source for cleaned base data. Potentially store validated engineered features in new tables/views for efficient reuse.</li> <li>Colab: Primary environment for implementing complex feature calculation logic.</li> </ul>"},{"location":"master-plan/#phase-5-model-development-and-training","title":"Phase 5: Model Development and Training","text":"<p>(This phase involves selecting, training, and optimizing machine learning models to predict race outcomes.)</p>"},{"location":"master-plan/#51-model-selection","title":"5.1. Model Selection","text":"<ul> <li>Target Variable(s): To be clearly defined (e.g., predict win probability, predict top N finish, predict expected ROI).</li> <li>Baseline Models: Start with simpler, interpretable models (Logistic Regression, Linear Regression, Decision Trees, Random Forests).</li> <li>Advanced Models: Explore Gradient Boosting Machines (XGBoost, LightGBM, CatBoost), Neural Networks (MLPs, potentially RNNs/LSTMs if sequential data like sectional times are heavily used).</li> <li>Selection Criteria: Predictive performance (via backtesting), interpretability, computational cost, training time.</li> </ul>"},{"location":"master-plan/#52-training-environment","title":"5.2. Training Environment","text":"<ul> <li>Primary: Google Colab, leveraging free-tier GPU/TPU accelerators for computationally intensive models.</li> </ul>"},{"location":"master-plan/#53-validation-approach","title":"5.3. Validation Approach","text":"<ul> <li>Primary Method: Rigorous Backtesting.<ul> <li>Simulate training on historical data up to a point and evaluating on subsequent unseen historical data.</li> <li>Employ time-series aware validation (e.g., walk-forward validation) to prevent data leakage.</li> </ul> </li> </ul>"},{"location":"master-plan/#54-hyperparameter-optimization","title":"5.4. Hyperparameter Optimization","text":"<ul> <li>For promising models, optimize hyperparameters to maximize performance on validation sets.</li> <li>Techniques: Grid Search, Randomized Search, Bayesian Optimization (using libraries like Optuna or Scikit-learn tools).</li> </ul>"},{"location":"master-plan/#phase-6-model-evaluation-and-validation","title":"Phase 6: Model Evaluation and Validation","text":"<p>(This phase focuses on rigorously evaluating model performance, especially in the context of wagering profitability.)</p>"},{"location":"master-plan/#61-performance-metrics","title":"6.1. Performance Metrics","text":"<ul> <li>Primary Focus (Wagering Profitability):<ul> <li>Return on Investment (ROI).</li> <li>Hit Rate (Win Prediction Accuracy, Place Prediction Accuracy).</li> </ul> </li> <li>Standard ML Metrics (Task-Dependent):<ul> <li>Classification: Accuracy, Precision, Recall, F1-score, Log Loss, AUC-ROC, AUC-PR.</li> <li>Regression (if predicting rank/time): MAE, RMSE.</li> </ul> </li> </ul>"},{"location":"master-plan/#62-backtesting-outcomes","title":"6.2. Backtesting Outcomes","text":"<ul> <li>Present detailed quantitative results from backtesting simulations.</li> <li>Compare different models and hyperparameter configurations across historical validation periods.</li> </ul>"},{"location":"master-plan/#63-wagering-strategy-simulation","title":"6.3. Wagering Strategy Simulation","text":"<ul> <li>Simulate model use within defined wagering strategies during backtesting.</li> <li>Examples: Fixed Stakes, Percentage Stakes (e.g., fixed percentage of bankroll), Kelly Criterion (adjusting bet size based on perceived edge and odds).</li> <li>Simulation must account for historical odds and race results.</li> </ul>"},{"location":"master-plan/#64-profitability-analysis","title":"6.4. Profitability Analysis","text":"<ul> <li>In-depth analysis of simulated financial performance (total profit/loss, ROI, drawdown, risk-adjusted returns).</li> <li>Assess feasibility of achieving the project's primary objective (positive ROI).</li> </ul>"},{"location":"master-plan/#65-iterative-refinement","title":"6.5. Iterative Refinement","text":"<ul> <li>Evaluation results drive improvements:<ul> <li>Revisit Feature Engineering (Phase 4).</li> <li>Revisit Model Selection (Phase 5.1).</li> <li>Revisit Hyperparameter Optimization (Phase 5.4).</li> <li>Analyze errors to understand model strengths/weaknesses.</li> </ul> </li> </ul>"},{"location":"master-plan/#phase-7-deployment-and-monitoring-future-phase","title":"Phase 7: Deployment and Monitoring (Future Phase)","text":"<p>(This phase outlines operationalizing the model and monitoring its ongoing performance.)</p>"},{"location":"master-plan/#71-prediction-generation-workflow","title":"7.1. Prediction Generation Workflow","text":"<ul> <li>End-to-end process for generating predictions/insights for upcoming race days:<ul> <li>Acquire new racecard data.</li> <li>Apply preprocessing and feature engineering steps consistently.</li> <li>Load trained model.</li> <li>Generate predictions.</li> <li>Store/present predictions for decision-making.</li> </ul> </li> <li>Define automation level and tools.</li> </ul>"},{"location":"master-plan/#72-performance-monitoring","title":"7.2. Performance Monitoring","text":"<ul> <li>Track real-world effectiveness and profitability:<ul> <li>Collect actual race results.</li> <li>Compare outcomes against predictions.</li> <li>Track ROI based on simulated/actual wagers.</li> <li>Monitor for model drift or changes in data distributions.</li> </ul> </li> <li>Define metrics, frequency, and tools.</li> </ul>"},{"location":"master-plan/#73-retraining-approach","title":"7.3. Retraining Approach","text":"<ul> <li>Strategy for periodic model retraining:<ul> <li>Triggers: Performance degradation, fixed schedule, or significant new data accumulation.</li> <li>Process: Reuse pipelines from Phases 2-6 with updated data.</li> <li>Validation: Retrained models validated via backtesting before deployment.</li> </ul> </li> </ul>"},{"location":"master-plan/#phase-8-project-management-and-continuous-improvement","title":"Phase 8: Project Management and Continuous Improvement","text":"<p>(This section covers ongoing project aspects, learnings, and future considerations.)</p>"},{"location":"master-plan/#81-potential-challenges-and-resolutions-ongoing-log","title":"8.1. Potential Challenges and Resolutions (Ongoing Log)","text":"<p>(This list will be dynamic and updated in phase reports or a dedicated decisions/risks log as they arise.) * Cloud Costs (BigQuery/GCP): Monitor usage, optimize queries, leverage free tiers. * Feature Engineering Complexity: Iterative approach, start simple, leverage domain knowledge and EDA. * Model Validation &amp; Profitability: Rigorous backtesting, realistic wagering simulation. * Data Pipeline Robustness: Error handling, logging, monitoring. * Data Integrity &amp; Correction: Ongoing validation checks, clear process for corrections. * Web Scraping Maintenance: Monitor for HKJC site changes, allocate time for script updates.</p>"},{"location":"master-plan/#82-data-size-projections-and-growth","title":"8.2. Data Size Projections and Growth","text":"<ul> <li>Initial dataset (18 years, ~171k rows, 40-50 cols): ~20-50 MB.</li> <li>With engineered features (~150-200 cols): ~50-100 MB.</li> <li>Long-term growth (next 15-20 years): Potentially doubling to ~200-400 MB.</li> <li>These volumes are manageable within BigQuery free tiers and Colab.</li> </ul>"},{"location":"master-plan/#83-tools-summary","title":"8.3. Tools Summary","text":"<ul> <li>Data Storage &amp; Querying: Google BigQuery.</li> <li>Data Processing &amp; Modeling: Python in Google Colab (Pandas, Scikit-learn, etc.).</li> <li>Web Scraping: Python (Beautiful Soup / Playwright).</li> <li>Version Control: Git / GitHub.</li> <li>Documentation: MkDocs (Material theme).</li> <li>Project Management / Task Tracking: <code>docs/project-status.md</code>.</li> <li>(Original) Intermediary Data/Control: Google Sheets, Google Apps Script (may be revised).</li> </ul>"},{"location":"master-plan/#84-future-considerations","title":"8.4. Future Considerations","text":"<ul> <li>Advanced Deployment: If successful, explore more sophisticated deployment (e.g., dedicated prediction server, API).</li> <li>Alternative Data Sources: If HKJC scraping becomes untenable (unlikely to be better external sources).</li> <li>Deeper Model Exploration: More complex architectures if justified by performance.</li> </ul>"},{"location":"master-plan/#85-version-control-strategy","title":"8.5. Version Control Strategy","text":"<ul> <li>All project code, documentation, and configuration files will be version controlled using Git, hosted on a GitHub repository.</li> <li>Branches will be used for feature development and experimentation (e.g., <code>feature/new-scraper</code>, <code>experiment/new-model-arch</code>).</li> <li>The <code>main</code> branch will represent the stable, working version of the project.</li> <li>Commits should be descriptive and atomic.</li> </ul>"},{"location":"master-plan/#86-references","title":"8.6. References","text":"<p>(Placeholder for links to key documentation, research papers, articles, etc., consulted during the project.)</p> <ul> <li>HKJC Website: <code>[Link to be added]</code></li> <li>Pandas Documentation: <code>https://pandas.pydata.org/pandas-docs/stable/</code></li> <li>Scikit-learn Documentation: <code>https://scikit-learn.org/stable/</code></li> <li>MkDocs Material Theme: <code>https://squidfunk.github.io/mkdocs-material/</code></li> </ul>"},{"location":"master-plan/#appendix-a-data-dictionary","title":"Appendix A: Data Dictionary","text":"<p>(This defines the planned schema for data stored in BigQuery. It may evolve.)</p>"},{"location":"master-plan/#a1-table-race_details","title":"A.1. Table: <code>race_details</code>","text":"<p>(Contains details specific to each race event)</p> Column Name Data Type Description Notes/Example <code>RACE_ID</code> INTEGER Unique identifier for each race. Format: <code>YYYYMMDD</code> + <code>RACE_NUM_SEASON</code> (e.g., <code>20240414581</code>). Seasonal race number is 3 digits (e.g., <code>581</code>). <code>DATE</code> DATE Date the race was held. Format: <code>YYYY-MM-DD</code> <code>COURSE</code> STRING Racecourse where the race took place. Values: <code>Sha Tin</code>, <code>Sha Tin (AWT)</code>, <code>Happy Valley</code> <code>RACE_NUM_SEASON</code> INTEGER The sequential number of the race within the racing season. e.g., <code>581</code> <code>CLASS</code> STRING The class of the race. e.g., <code>Class 1</code>, <code>Group 1</code>, <code>Griffin</code> <code>DISTANCE</code> INTEGER The race distance in meters. e.g., <code>1200</code>, <code>1650</code> <code>RANKING</code> STRING The rating bracket for the race. e.g., <code>85-60</code> <code>GOING</code> STRING Description of surface going. e.g., <code>GOOD</code>, <code>YIELDING (WET SLOW)</code> <code>RACE_DESCRIPTION</code> STRING The official title or name of the race. e.g., <code>THE HONG KONG EXCHANGES CHALLENGE CUP HANDICAP</code> <code>TRACK_CONFIG</code> STRING The track configuration for the race. e.g., <code>TURF - \"C\" Course</code>, <code>ALL WEATHER TRACK</code> <code>PRIZE</code> INTEGER The total prize money in HKD for the race. <code>PEN_READING</code> FLOAT Penetrometer reading (turf) or Clegg hammer reading (all-weather track)."},{"location":"master-plan/#a2-table-race_card-or-runners","title":"A.2. Table: <code>race_card</code> (or <code>runners</code>)","text":"<p>(Contains details for each horse participating in a race, pre-race information)</p> Column Name Data Type Description Notes/Example <code>RUNNER_ID</code> STRING Unique identifier for a horse in a specific race. Format: <code>RACE_ID</code> + <code>*</code> + <code>HORSE_ID</code> (e.g., <code>20240414581*CLEARWIN*H255</code>) <code>RACE_ID</code> INTEGER Foreign key referencing <code>race_details.RACE_ID</code>. <code>HORSE_ID</code> STRING Unique identifier for the horse (stable across races). Format: <code>HORSE_NAME</code> (no spaces/special chars) + <code>*</code> + <code>HORSE_CODE</code> (e.g., <code>CLEARWIN*H255</code>) <code>HORSE_NUM</code> INTEGER The number assigned to the horse for that race (usually printed on saddle cloth). e.g., <code>1</code>, <code>2</code>, ... <code>14</code> <code>WEIGHT</code> INTEGER Total weight carried by the horse (lbs), including jockey and gear. <code>HORSE_WEIGHT</code> INTEGER Declared weight of the horse (lbs), usually taken a day or two before the race. <code>DRAW</code> INTEGER Starting gate (barrier) number. Lower numbers are closer to the inside rail. <code>JOCKEY</code> STRING Jockey's name. <code>TRAINER</code> STRING Trainer's name. <code>RATING</code> STRING Official HKJC rating of the horse at the time of the race. Numeric string, or <code>UNRATED</code> (overseas), <code>GRIFFIN</code> (novices). <code>REST_DAYS</code> STRING Number of days since the horse's last run. Numeric string, or <code>DEBUT</code> (first run in HK or ever). <code>RACE_AGE</code> STRING Age of the horse at the time of the race. Numeric string, or <code>UNKNOWN</code>. <code>GEAR</code> STRING Symbols representing gear used by the horse. e.g., <code>PC/XB/TT</code>. See Gear Key below. <p>Gear Key (Example - to be confirmed from HKJC source):</p> <ul> <li><code>B</code>: Blinkers</li> <li><code>CP</code>: Sheepskin Cheek Pieces</li> <li><code>TT</code>: Tongue Tie</li> <li><code>XB</code>: Crossed Nose Band</li> <li><code>P</code>: Pacifier</li> <li><code>V</code>: Visor</li> <li><code>H</code>: Hood</li> <li><code>E</code>: Ear Plugs</li> <li><code>1</code> (suffix): First time using this gear.</li> </ul>"},{"location":"master-plan/#a3-table-race_results","title":"A.3. Table: <code>race_results</code>","text":"<p>(Contains the official results for each horse in a race)</p> Column Name Data Type Description Notes/Example <code>RUNNER_ID</code> STRING Foreign key referencing <code>race_card.RUNNER_ID</code>. <code>RACE_ID</code> INTEGER Foreign key referencing <code>race_details.RACE_ID</code>. <code>HORSE_ID</code> STRING Foreign key referencing horse identity. <code>FINISH_POS</code> INTEGER Final official finishing position. <code>1</code> for winner, <code>2</code> for second, etc. May include codes for non-finishers. <code>STARTING_ODDS</code> FLOAT Decimal odds of the horse just before race start. e.g., <code>1.8</code>, <code>10.5</code> <code>PLACE_PAYOUTS</code> FLOAT Decimal odds payout for a successful place bet. <code>0</code> or <code>NULL</code> if unplaced or no payout. <code>FINISH_TIME</code> FLOAT Finishing time of the horse in seconds. e.g., <code>71.52</code> <code>SEC_TIME_1</code> FLOAT Time taken to finish section 1 (seconds). <code>SEC_TIME_2</code> FLOAT Time taken to finish section 2 (seconds). <code>SEC_TIME_3</code> FLOAT Time taken to finish section 3 (seconds). <code>SEC_TIME_4</code> FLOAT Time taken to finish section 4 (seconds). (Sectional times depend on race distance and course) <code>SEC_TIME_5</code> FLOAT Time taken to finish section 5 (seconds). <code>SEC_TIME_6</code> FLOAT Time taken to finish section 6 (seconds). <code>DIST_BEATEN</code> FLOAT Distance beaten by the winner, in lengths (approx). <code>0</code> for winner. <code>INCIDENTS</code> STRING Notes on any racing incidents involving the horse during the race. e.g., \"Bumped at start\", \"Checked near 800m\""},{"location":"master-plan/#a4-table-horse_register","title":"A.4. Table: <code>horse_register</code>","text":"<p>(Contains static details for all registered horses)</p> Column Name Data Type Description Notes/Example <code>HORSE_ID</code> STRING Unique identifier for the horse. Format: <code>HORSE_NAME</code> (no spaces/specials) + <code>*</code> + <code>HORSE_CODE</code> <code>HORSE_CODE</code> STRING Unique code assigned by HKJC to differentiate horses (esp. same names). e.g., <code>H255</code>, <code>D466</code> <code>HORSE_NAME</code> STRING Official name of the horse. Raw name, e.g., \"DEAN'S ANGEL\" <code>SEX</code> STRING Horse's sex. <code>Gelding</code>, <code>Mare</code>, <code>Colt</code>, <code>Filly</code>, <code>Horse</code>, <code>Rig</code> <code>COLOR</code> STRING Color of the horse. e.g., <code>Bay</code>, <code>Chestnut</code> <code>COUNTRY_OF_ORIGIN</code> STRING Country where the horse was born. e.g., <code>AUS</code>, <code>NZ</code>, <code>IRE</code> <code>IMPORT_TYPE</code> STRING Category of entry into Hong Kong racing. <code>PP</code> (Privately Purchased), <code>PPG</code> (Privately Purchased Griffin), <code>ISG</code> (International Sale Griffin), <code>VIS</code> (Visitor) <code>SIRE</code> STRING The horse's father (sire). <code>DAM</code> STRING The horse's mother (dam). <code>DAM_SIRE</code> STRING The sire of the horse's dam (maternal grandsire). <code>OWNER</code> STRING Name(s) of the horse's owner(s). <p>Import Type Key (Example): * <code>PP</code>: Privately Purchased Horses (previously raced elsewhere). * <code>PPG</code>: Privately Purchased Griffins (unraced young horses). * <code>ISG</code>: International Sale Griffins (unraced horses from approved sales). * <code>VIS</code>: Visiting Invitational Horses (invited for specific major races).</p>"},{"location":"phase-01-collection/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-02-cleansing/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-03-eda/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-04-features/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-05-model/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-06-evaluation/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-07-deployment/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-08-management/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"project-status/","title":"Project Status","text":"<p>Last Manually Updated: 2025-05-09</p> <p>Overall Project Health: Green</p> <p>Initial setup and planning are progressing well. The new project structure and documentation plan are being finalized.</p> <p>Key Focus for This Week (ending 2005-05-09):</p> Status Task / Issue Description Milestone \ud83d\udd04 Final review and sign-off on <code>project_plan.md</code>. M2"},{"location":"project-status/#general-project-setup","title":"General Project Setup","text":"<p>(Tasks related to overall project infrastructure, documentation, and planning)</p> <p>Major Milestones:</p> <ul> <li>\u2705 M1: Initial project repository configured (Completed: YYYY-MM-DD)</li> <li>\u2b1c M2: <code>project_plan.md</code> created and populated from Google Doc (Completed: YYYY-MM-DD)</li> <li>\u2b1c M3: <code>mkdocs.yml</code> updated for new site structure (Target: YYYY-MM-DD)</li> <li>\u2b1c M4: All phase report Markdown files named and structured (Target: YYYY-MM-DD)</li> <li>\u2b1c M5: This <code>project-status.md</code> file structure finalized (Target: YYYY-MM-DD)</li> </ul>"},{"location":"project-status/#phase-1-data-collection","title":"Phase 1: Data Collection","text":"<p>(Objective: To gather all necessary raw data from defined sources - see <code>project_plan.md</code> for details)</p> <p>Major Milestones:</p> <ul> <li>\u2b1c M1: All data sources and specific data fields fully identified and documented in <code>project_plan.md</code>. (Target: YYYY-MM-DD)</li> <li>\u2b1c M2: Web scraping scripts for HKJC racecards developed and robustly tested. (Target: YYYY-MM-DD)</li> <li>\u2b1c M3: Web scraping scripts for HKJC race results developed and robustly tested. (Target: YYYY-MM-DD)</li> <li>\u2b1c M4: Historical data (target: X seasons/Y race days) successfully collected. (Target: YYYY-MM-DD)</li> <li>\u2b1c M5: Initial storage solution for raw data implemented and populated. (Target: YYYY-MM-DD)</li> <li>\u2b1c M6: Report: <code>docs/phase-01-collection.md</code> completed and reviewed. (Target: YYYY-MM-DD)</li> </ul>"},{"location":"project-status/#phase-2-data-cleansing-preprocessing","title":"Phase 2: Data Cleansing &amp; Preprocessing","text":"<p>(Objective: To transform raw data into a clean, consistent, and usable format - see <code>project_plan.md</code> for details)</p> <p>Major Milestones:</p> <ul> <li>\u2b1c M1: Data quality issues from raw data fully profiled and documented. (Target: YYYY-MM-DD)</li> <li>\u2b1c M2: Comprehensive data cleansing rules and procedures defined. (Target: YYYY-MM-DD)</li> <li>\u2b1c M3: Scripts for all data type conversions and value standardizations developed. (Target: YYYY-MM-DD)</li> <li>\u2b1c M4: Strategy for handling missing values and outliers defined and implemented. (Target: YYYY-MM-DD)</li> <li>\u2b1c M5: Cleansed dataset validated against defined quality criteria and schema. (Target: YYYY-MM-DD)</li> <li>\u2b1c M6: Report: <code>docs/phase-02-cleansing.md</code> completed and reviewed. (Target: YYYY-MM-DD)</li> </ul>"},{"location":"project-status/#phase-3-exploratory-data-analysis-eda","title":"Phase 3: Exploratory Data Analysis (EDA)","text":"<p>(Objective: To understand data patterns, relationships, and formulate initial hypotheses - see <code>project_plan.md</code> for details)</p> <p>Major Milestones:</p> <ul> <li>\u2b1c M1: Descriptive statistics generated and analyzed for all key variables. (Target: YYYY-MM-DD)</li> <li>\u2b1c M2: Key visualizations (distributions, correlations, time series) created and interpreted. (Target: YYYY-MM-DD)</li> <li>\u2b1c M3: Significant patterns, anomalies, and relationships documented. (Target: YYYY-MM-DD)</li> <li>\u2b1c M4: Initial hypotheses about predictive factors formulated and listed. (Target: YYYY-MM-DD)</li> <li>\u2b1c M5: Report: <code>docs/phase-03-eda.md</code> completed and reviewed. (Target: YYYY-MM-DD)</li> </ul>"},{"location":"project-status/#phase-4-feature-engineering","title":"Phase 4: Feature Engineering","text":"<p>(Objective: To create new predictive features from the cleansed data - see <code>project_plan.md</code> for details)</p> <p>Major Milestones:</p> <ul> <li>\u2b1c M1: List of potential engineered features brainstormed and prioritized. (Target: YYYY-MM-DD)</li> <li>\u2b1c M2: Initial set of ~20-30 engineered features designed and documented. (Target: YYYY-MM-DD)</li> <li>\u2b1c M3: Scripts to generate these engineered features implemented and tested. (Target: YYYY-MM-DD)</li> <li>\u2b1c M4: Engineered feature set validated and stored. (Target: YYYY-MM-DD)</li> <li>\u2b1c M5: Report: <code>docs/phase-04-features.md</code> completed and reviewed. (Target: YYYY-MM-DD)</li> </ul>"},{"location":"project-status/#phase-5-model-development","title":"Phase 5: Model Development","text":"<p>(Objective: To train and select predictive models - see <code>project_plan.md</code> for details) (Structure: Major Milestones list, then Detailed Tasks &amp; Issues table) ... (Content to be filled similarly) ...</p>"},{"location":"project-status/#phase-6-model-evaluation","title":"Phase 6: Model Evaluation","text":"<p>(Objective: To rigorously assess model performance and potential profitability - see <code>project_plan.md</code> for details) (Structure: Major Milestones list, then Detailed Tasks &amp; Issues table) ... (Content to be filled similarly) ...</p>"},{"location":"project-status/#phase-7-deployment","title":"Phase 7: Deployment","text":"<p>(Objective: To set up a system for generating predictions on new races - see <code>project_plan.md</code> for details) (Structure: Major Milestones list, then Detailed Tasks &amp; Issues table) ... (Content to be filled similarly) ...</p>"},{"location":"project-status/#phase-8-ongoing-management-iteration","title":"Phase 8: Ongoing Management &amp; Iteration","text":"<p>(Objective: To maintain the system, monitor performance, and plan for future improvements - see <code>project_plan.md</code> for details) (Structure: Major Milestones list, then Detailed Tasks &amp; Issues table) ... (Content to be filled similarly) ...</p>"},{"location":"project-status/#detailed-tasks-issues","title":"Detailed Tasks &amp; Issues:","text":"Task / Issue Description Milestone Notes / Resolution Date Due Genaral Project Setup Draft initial project_plan.md content. M2 Moved content from Google Doc. Final review and sign-off on project_plan.md. M2 Rename docs/index.md to project_plan.md. M2 Update nav section in mkdocs.yml. M3 Point home to project_plan.md. Delete old docs/milestones.md. M6 Rename phase files (e.g., phase-01-collection.md) M4 Reflect new numbering &amp; report focus. Phase 1: Data Collection and Storage Draft structure for docs/phase-01-collection.md report. M6 Research and select Python library for web scraping. M2 Options: BeautifulSoup, Playwright, Scrapy. Implement scrape_race_dates() function. M2 Implement scrape_racecard(race_date_url) function. M2 Implement scrape_results(race_date_url) function. M3 Define error handling and retry logic for scrapers. M7 E.g., for network issues, unexpected page structure. Test scrapers on a diverse sample of 5-10 race days. M8 Include different tracks, number of races. Address Issue: Potential for IP blocking during scraping. You Monitor, implement delays, consider proxy/VPN if necessary. Define schema for raw racecard data (JSON/CSV). M9 Define schema for raw results data (JSON/CSV). M10 Phase 2: Data Cleansing and Preprocessing Draft structure for docs/phase-02-cleansing.md report. M6 Perform data profiling on raw collected data (from Phase 1). M1 Use Pandas Profiling or custom scripts. Develop script for converting date/time fields. M3 Ensure consistent YYYY-MM-DD HH:MM:SS format. Script to standardize categorical values (e.g., track conditions). M3 Research and select imputation techniques for HORSE_WEIGHT. M4 Mean, median, model-based? Implement chosen imputation for HORSE_WEIGHT. M4 Identify and handle outliers in FINISH_TIME. M4 E.g., Capping, removal based on IQR. Phase 3: Exploratory Data Analysis (EDA) Draft structure for docs/phase-03-eda.md report. M5 Set up EDA Jupyter notebook (notebooks/01-race-eda.ipynb). M1 Load cleansed data. Generate histograms and density plots for numerical features. M2 E.g., FINISH_TIME, STARTING_ODDS. Create bar charts for categorical feature frequencies. M2 E.g., COURSE, GOING. Calculate and visualize correlation matrix. M2 Identify highly correlated features. Box plots for numerical features grouped by key categories. M2 E.g., FINISH_TIME by CLASS. Investigate any surprising findings from initial plots. M3 Phase 4: Feature Engineering Draft structure for docs/phase-04-features.md report. M5 Create rolling average features for horse past performance. M3 E.g., avg finish pos last 3/5 races. Calculate speed figures based on time and distance. M3 Encode categorical variables (e.g., one-hot, target encoding). M3 Create interaction features (e.g., jockey-trainer win rate). M3 <p>---</p>"}]}