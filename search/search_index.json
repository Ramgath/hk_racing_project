{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"hk horse racing","text":""},{"location":"decisions/","title":"Key Project Decisions","text":"<p>This document tracks the major design and process decisions for the HK Racing Project, along with context and rationale.</p>"},{"location":"decisions/#week-1-2025-05-04","title":"WEEK 1: 2025-05-04","text":"<ul> <li> <p>Decision: Define primary development environment roles: VS Code for core development, Google Colab for EDA &amp; intensive ML.</p> <ul> <li>Rationale: Leverages VS Code's strengths for project management &amp; script development, and Colab's strengths for experimentation &amp; hardware acceleration. Clear separation of concerns. (Alternatives: Using only Colab; Using only VS Code).</li> </ul> </li> <li> <p>Decision: Adopt direct Python-to-BigQuery for raw data ingestion.</p> <ul> <li>Rationale: Increases robustness, scalability, and efficiency of the automated scraping pipeline. Reduces manual steps and potential points of failure associated with Sheets intermediary. (Alternatives: Google Sheets as intermediary for raw data; Local files then upload to BQ).</li> </ul> </li> <li> <p>Decision: Implement data corrections in BigQuery via Python scripts.</p> <ul> <li>Rationale: Scripted corrections are version-controllable, auditable, and more robust. A GSheet for logging corrections could be a future UI enhancement if needed. (Alternatives: Direct manual edits in BQ console; Google Sheet as a UI for triggering updates).</li> </ul> </li> <li> <p>Decision: Use Google Cloud Storage (GCS) for storing trained model artifacts.</p> <ul> <li>Rationale: GCS offers better versioning, programmatic access, and integration with MLOps tools (like Vertex AI Model Registry). Likely free/low-cost for project scale. (Alternatives: Google Drive; Storing models directly in the Git repository).</li> </ul> </li> <li> <p>Decision: Utilize Vertex AI Model Registry for model versioning and metadata.</p> <ul> <li>Rationale: Provides a centralized, free (for registration) service for managing model lifecycle, improving organization and reproducibility. Points to models in GCS. (Alternatives: Manual tracking in spreadsheets; Custom solution).</li> </ul> </li> <li> <p>Decision: Defer dashboarding; consider Streamlit for future results presentation.</p> <ul> <li>Rationale: Focus on core pipeline first. Streamlit offers a Python-native way to quickly build interactive UIs when predictions are ready. (Alternatives: Dash; Custom HTML/JS; GitHub Pages for static reports).</li> </ul> </li> <li> <p>Decision: Implement <code>config/</code> directory with <code>config.yaml</code> (gitignored) and <code>config.yaml.example</code> for project settings.</p> <ul> <li>Rationale: Centralizes configuration, improves clarity, facilitates different environments (if needed later), and keeps secrets out of version control. (Alternatives: Hardcoding configurations; Environment variables only).</li> </ul> </li> <li> <p>Decision: Create <code>src/common/config_loader.py</code> for loading YAML configurations.</p> <ul> <li>Rationale: Provides a standardized, reusable way to access configurations throughout the project. (Alternatives: Ad-hoc loading in multiple scripts).</li> </ul> </li> </ul>"},{"location":"decisions/#week-2-2025-05-11","title":"WEEK 2: 2025-05-11","text":"<ul> <li> <p>Decision: Manage <code>project-status.md</code> manually instead of script-based generation from Google Sheets for detailed tasks.</p> <ul> <li>Rationale: User preference for direct Markdown editing and control. Simplifies tooling if more comfortable with manual updates. (Alternatives: Python script to generate phase-specific task tables; Python script for single task table).</li> </ul> </li> <li> <p>Decision: Exclude pre-2008 historical data from the project scope.</p> <ul> <li>Rationale:<ol> <li>Data is error-prone and difficult to load/validate in BigQuery.</li> <li>Significant missing values for critical data points (win odds, horse weights, HKJC ratings).</li> <li>Absence of sectional timings, and concerns about the accuracy of overall finish times.</li> <li>Inconsistent false rail configurations prior to the 2008 GPS tracking system introduction, making comparisons with modern data unreliable.</li> <li>Lack of advanced timing systems (e.g., precision to two decimal places).</li> <li>The effort to cleanse and integrate this data outweighs the potential benefits, and focusing on 2008+ data ensures higher quality and relevance.</li> </ol> </li> <li>Impact: Simplifies Phase 1 data collection and Phase 2 cleansing efforts. The <code>hk_racing_historical_raw</code> BigQuery dataset will not be created.</li> </ul> </li> <li> <p>Decision: Refine BigQuery Dataset Strategy for Phase 1.</p> <ul> <li><code>hk_racing_dataset</code> (Main Dataset):<ul> <li>Will store processed historical data (2008 - November 2023) ingested from user-provided Google Sheets.</li> <li>Target schemas for tables (<code>results</code>, <code>racecard</code>, <code>race_details</code>, <code>horse_register</code>) are defined by the user in <code>Appendix A: Phase 1 Data Dictionary</code> of the <code>master-plan</code></li> <li>This dataset will also be the target for fully cleansed and integrated analytical data in later phases.</li> </ul> </li> <li><code>hk_racing_scraped_raw</code> (Staging/Raw Dataset):<ul> <li>Will store raw data collected from the HKJC website (December 2023 onwards) after preliminary Python-based formatting.</li> <li>Table structures will initially mirror the scraped data structure.</li> </ul> </li> <li>Rationale: Clear separation of already processed historical data from newly scraped raw data. Facilitates a focused approach for Phase 1 collection and prepares for Phase 2 cleansing and integration.</li> <li>Impact: <code>config/config.yaml</code> to be updated with <code>bq_main_dataset_id</code> and <code>bq_scraped_raw_dataset_id</code>.</li> </ul> </li> <li> <p>Decision: Confirm target schemas for <code>hk_racing_dataset</code> tables.</p> <ul> <li>Source: The structure and field definitions provided by the user are adopted as the definitive schemas for the <code>results</code>, <code>racecard</code>, <code>race_details</code>, and <code>horse_register</code> tables within the <code>hk_racing_dataset</code>.</li> <li>Impact: Provides clear targets for the ingestion of processed Google Sheets data. These schemas will be documented in Appendix A of <code>master-plan.md</code>.</li> </ul> </li> <li> <p>Decision: Evaluate Google Cloud Dataform for SQL transformation management in future phases.</p> <ul> <li>Rationale: For phases involving significant SQL-based data transformations within BigQuery (e.g., Phase 2: Cleansing, Phase 4: Features), Dataform offers potential benefits for version control, dependency management, testing, and orchestration of SQL workflows. This will be assessed as SQL complexity grows.</li> <li>Impact: No immediate change to Phase 1. Local Git repository remains the primary version control for all project assets. Dataform exploration is a consideration for later stages.</li> </ul> </li> </ul>"},{"location":"decisions/#week-3-2025-05-18","title":"WEEK 3: 2025-05-18","text":""},{"location":"master-plan/","title":"Hong Kong Racing Project: Master Plan","text":"<p>This document outlines the technical plan for building a handicapping and wagering system for thoroughbred horse racing in Hong Kong, with the primary objective of achieving sustainable financial gain through data-driven strategies. It serves as the central reference for project scope, methodology, and planned execution across all phases.</p>"},{"location":"master-plan/#0-project-definition-and-establishment","title":"0. Project Definition and Establishment","text":""},{"location":"master-plan/#01-introduction-and-aims","title":"0.1. Introduction and Aims","text":""},{"location":"master-plan/#011-project-objective","title":"0.1.1. Project Objective","text":"<ul> <li>Goal: Develop and implement a machine learning-based handicapping and wagering system aimed at generating a positive return on investment (ROI) from Hong Kong horse racing.</li> <li>Team: Solo project with assistance from AI (e.g., Google Gemini).</li> <li>Broader Context: This project focuses on the technical development of a predictive system for financial gain within the domain of horse race wagering. It's acknowledged that this operates within the context of gambling, and responsible practices should guide any potential future application of the system's outputs.</li> </ul>"},{"location":"master-plan/#012-document-purpose","title":"0.1.2. Document Purpose","text":"<p>This <code>project_plan.md</code> (and the accompanying MkDocs site) serves several key purposes:</p> <ul> <li>Centralized Record: Acts as the primary repository for documenting all project plans, methodologies, data sources, and strategic decisions made throughout the project lifecycle.</li> <li>Shared Context for AI Collaboration: Functions as a persistent memory and context for ongoing work and discussions with AI assistants. Referencing and updating this plan and related phase reports ensures continuity.</li> <li>Single Source of Truth: Establishes a definitive reference point for the project's scope, workflow, tools, and challenges.</li> <li>Tracking Evolution: While this document outlines the plan, individual phase reports (<code>docs/phase-XX-name.md</code>) will track the execution and evolution of the project.</li> </ul>"},{"location":"master-plan/#02-resource-and-environment-configuration","title":"0.2. Resource and Environment Configuration","text":""},{"location":"master-plan/#021-hardware","title":"0.2.1. Hardware","text":"<ul> <li>Local machine: MacBook Air, 8GB RAM, Apple Silicon (M1 chip).</li> <li>Online: Standard Colab CPU Environment (e.g., Intel Xeon, ~13 GB RAM). Google Colab free tier also provides variable access to GPU and TPU accelerators.</li> </ul>"},{"location":"master-plan/#022-software-and-cloud-services-primarily-google-ecosystem","title":"0.2.2. Software and Cloud Services (Primarily Google Ecosystem)","text":"<ul> <li>Google BigQuery: Central data warehouse for storing historical and current race data. Chosen for scalability, Colab integration, and cost-effectiveness within its free tier.</li> <li>Google Colab: Primary environment for data scraping, cleaning, analysis, feature engineering, visualization, and ML model development.</li> <li>Google Sheets: Used as an intermediary data hub, for manual input/correction if necessary, and potentially for controlling updates via Apps Script (original plan).</li> <li>Google Apps Script: Planned for automating data update processes (e.g., Sheets to BigQuery).</li> <li>Google Cloud Storage (GCS): Considered for intermediary data storage (e.g., Parquet files) to optimize data transfer between BigQuery and Colab.</li> <li>Python Libraries:<ul> <li>Data Acquisition: Beautiful Soup (or potentially Playwright/Selenium if dynamic content requires it).</li> <li>Data Manipulation &amp; Analysis: pandas, NumPy, Polars.</li> <li>Cloud Interaction: <code>google-cloud-bigquery</code>, <code>gspread</code>.</li> <li>Visualization: Plotly, Matplotlib, Seaborn.</li> <li>Machine Learning: Scikit-learn, TensorFlow, PyTorch, XGBoost, LightGBM (specific choices in modeling phase).</li> </ul> </li> <li>Version Control: Git, managed via a GitHub repository.</li> <li>Documentation: MkDocs with the Material theme.</li> </ul>"},{"location":"master-plan/#023-development-environment","title":"0.2.3. Development Environment","text":"<ul> <li>Google Colab: Primary for computationally intensive tasks (data processing, ML).</li> <li>Visual Studio Code (VS Code) - Local: For developing helper scripts, managing the project repository, and MkDocs site generation/preview.</li> </ul>"},{"location":"master-plan/#03-proposed-workflow-outline-original-hybrid-concept","title":"0.3. Proposed Workflow Outline (Original Hybrid Concept)","text":""},{"location":"master-plan/#031-rationale-for-hybrid-workflow-sheets-bigquery-colab","title":"0.3.1. Rationale for Hybrid Workflow (Sheets -&gt; BigQuery -&gt; Colab)","text":"<p>(This section reflects the original thinking from the Google Doc. The actual implementation might evolve and will be documented in phase reports.) The initially chosen workflow utilized a hybrid approach: Google Sheets (for easily editable data), BigQuery (External Tables linking to Sheets, then materializing into Native Tables for performance), and Google Colab for analysis and ML.</p> <ul> <li>Ease of Data Correction: Sheets as the primary editable source.</li> <li>Analytical Performance: Native BigQuery tables for querying.</li> <li>Scalability: BigQuery's inherent scalability.</li> <li>Resource Efficiency: Colab for computation.</li> <li>Integration &amp; Control: Google ecosystem synergy.</li> <li>Cost-Effectiveness: Leveraging free tiers.</li> </ul>"},{"location":"master-plan/#032-alternative-methodologies-considered-original-assessment","title":"0.3.2. Alternative Methodologies Considered (Original Assessment)","text":"<ul> <li>DuckDB (Local) + Colab: Rejected due to local RAM limits and less straightforward data correction than Sheets.</li> <li>Pandas/Polars (Local only): Rejected due to RAM limits and lack of persistence/scalability.</li> <li>SQLite (Local): Rejected due to performance for analytical queries and local resource limits.</li> <li>PostgreSQL (Local): Rejected due to overhead on local hardware.</li> <li>Snowflake (Cloud): Rejected due to lack of a comparable free tier to BigQuery.</li> </ul>"},{"location":"master-plan/#phase-1-data-collection-and-storage","title":"Phase 1: Data Collection and Storage","text":"<p>Revised 2025-05-11</p> <p>Objective: To acquire all relevant raw and processed historical data from 2008 onwards and establish a structured and robust initial storage solution in Google BigQuery. This phase focuses on ingesting previously processed data and setting up the capability to collect ongoing race data.</p> <p>1. Data Sources:</p> <ul> <li>Primary Historical Processed Data (2008 - November 2023):<ul> <li>Source: User-provided Google Sheets from a 3rd party source. This data has undergone previous processing and error correction by the user.</li> <li>Content: Includes race results, race cards, race details, and horse register information.</li> <li>Period: From 2008 (coinciding with GPS tracking implementation) up to November 2023.</li> </ul> </li> <li>Primary Ongoing Raw Data (December 2023 onwards):<ul> <li>Source: Hong Kong Jockey Club (HKJC) official website (<code>https://racing.hkjc.com/</code>).</li> <li>Content: Racecards (for upcoming races), race results (historical, post-race), horse details, trackwork records, stewards' reports, and any other relevant data available.</li> <li>Period: From December 2023 onwards.</li> </ul> </li> </ul> <p>2. Historical Data Consideration (Pre-2008):</p> <ul> <li>Data prior to 2008, while available in CSV format, has been deemed out of scope for this project.</li> <li>Rationale for Exclusion:<ul> <li>Significant data quality issues (error-prone, missing values for critical fields like win odds, horse weights, and HKJC ratings).</li> <li>Absence of sectional timings and less accurate overall finish times.</li> <li>Fundamental differences in track configurations (e.g., false rail positions) before the consistent GPS tracking system was implemented in 2008.</li> <li>Lack of advanced timing systems (e.g., precision to two decimal places for finish and sectional times).</li> </ul> </li> <li>Focusing on data from 2008 onwards ensures higher quality, consistency, and relevance to current racing conditions.</li> </ul> <p>3. Data Acquisition Methodology:</p> <ul> <li>Processed Historical Data (Google Sheets):<ul> <li>Method: Python scripts utilizing libraries such as <code>gspread</code> and <code>pandas</code> to read data directly from the user's Google Sheets.</li> <li>Environment: Local Python environment or Google Colab.</li> </ul> </li> <li>Ongoing Raw Data (HKJC Website):<ul> <li>Primary Method: Web scraping using Python libraries (e.g., <code>requests</code>, <code>Beautiful Soup</code>, and potentially <code>Playwright</code> or <code>Selenium</code> if dynamic content rendering is a significant factor).</li> <li>Environment: Scripts will be developed locally or in Google Colab and designed for potential future deployment in an automated environment (e.g., Google Cloud Functions).</li> <li>API Limitations: The HKJC does not offer a public API, necessitating web scraping.</li> <li>Scope per Session: Scraping will be batched, likely per race day or specific data types (e.g., all results for a given day, all upcoming racecards).</li> <li>Race Calendar: The <code>src/ingestion/race_calendar.py</code> script, which reads race meeting dates from a Google Sheet, will be utilized to guide the scraping schedule for race-specific data.</li> <li>Maintenance: To ensure the scraping scripts continue to function correctly despite potential modifications to the HKJC website, they will need consistent oversight and upkeep. Health status updates for the scraping system will be generated and recorded in <code>phase-01-collection.md</code>.</li> </ul> </li> </ul> <p>4. Preliminary Data Formatting (Post-Scraping - for HKJC Data):</p> <ul> <li>Environment: Python scripts (local or Colab).</li> <li>Objective: For newly scraped data, perform initial transformations to ensure basic consistency before storage in the raw BigQuery dataset. This includes:<ul> <li>Data type enforcement (e.g., converting strings to numbers or dates where appropriate).</li> <li>Basic string manipulation (trimming whitespace, standardizing case for certain fields).</li> <li>Structural validation to ensure essential fields are present.</li> </ul> </li> <li>Rationale: Python scripts provide reproducibility, version control, and robust error handling for these initial formatting steps.</li> </ul> <p>5. Data Storage Strategy:</p> <ul> <li>Primary Data Warehouse: Google BigQuery.</li> <li>BigQuery Datasets:<ul> <li><code>hk_racing_dataset</code> (Main Dataset):<ul> <li>Purpose: To store the processed historical data (2008 - November 2023) from Google Sheets. This dataset will also serve as the target for fully cleansed, integrated, and modeled analytical data in later phases.</li> <li>Schema: Tables (<code>results</code>, <code>racecard</code>, <code>race_details</code>, <code>horse_register</code>) will adhere to the structures defined by the user (see Appendix A: Data Dictionary, based on <code>BQ_TABLES - bq tables.csv</code>).</li> </ul> </li> <li><code>hk_racing_scraped_raw</code> (Staging/Raw Dataset):<ul> <li>Purpose: To store the raw data collected from the HKJC website (December 2023 onwards) after preliminary formatting.</li> <li>Schema: Table structures in this dataset will initially mirror the scraped data structure closely. Data will be transformed and loaded into the main <code>hk_racing_dataset</code> during Phase 2 (Cleansing and Preprocessing).</li> </ul> </li> </ul> </li> <li>Data Ingestion Pipeline:<ul> <li>Sheets to BigQuery: Python scripts will read from Google Sheets and load data directly into the corresponding tables in <code>hk_racing_dataset</code>.</li> <li>HKJC Scrapes to BigQuery: Python scraping scripts will perform preliminary formatting and then load data directly into tables within <code>hk_racing_scraped_raw</code>. Temporary local file storage (e.g., JSON, CSV) or GCS may be used as an intermediate step during the scraping and loading process if beneficial for batching or error handling.</li> </ul> </li> <li>Configuration: GCP project ID, BigQuery dataset IDs, and other relevant parameters will be managed via <code>config/config.yaml</code> and accessed using <code>src/common/config_loader.py</code>.</li> <li>Update Frequency: New race data from HKJC will be collected and processed typically twice weekly, aligned with the HKJC racing calendar. Automation of this collection is a future goal (Phase 4).</li> </ul>"},{"location":"master-plan/#phase-2-data-cleansing-and-preprocessing","title":"Phase 2: Data Cleansing and Preprocessing","text":"<p>(This phase focuses on transforming raw collected data into a clean, consistent, and usable dataset.)</p>"},{"location":"master-plan/#21-overview-of-collected-data","title":"2.1. Overview of Collected Data","text":"<p>The dataset will encompass: * Race identification and context (Date, Course, Race Number, Class, Distance, Going, Prize Money, etc.). * Horse performance metrics (Finishing Place, Finish Time, Sectional Times, Weight Carried, Draw, etc.). * Betting information (Win/Place Odds). * Jockey and Trainer details. * Pre-race horse information (Horse Weight, Rating, Rest Days, Gear, etc.). * (Refer to Appendix A: Data Dictionary for detailed schema).</p>"},{"location":"master-plan/#22-cleansing-procedure","title":"2.2. Cleansing Procedure","text":"<ul> <li>Environment: Primarily Google Colab or local Python scripts, with results stored in BigQuery.</li> <li>Key Steps:<ul> <li>Data Type Enforcement: Ensure columns match predefined types (integer, float, string, date).</li> <li>String Manipulation: Trim whitespace, standardize capitalization, handle special characters.</li> <li>Categorical Value Standardization: Ensure consistency in fields like <code>COURSE</code>, <code>CLASS</code>, <code>GOING</code>. Map variations to standard values.</li> <li>Handling Specific Non-Numeric/Placeholder Strings: Address values like 'UNRATED', 'GRIFFIN', 'DEBUT' in fields that are otherwise numeric or categorical.</li> <li>Addressing Known Inconsistencies: Programmatic fixes for known issues in historical data.</li> </ul> </li> </ul>"},{"location":"master-plan/#23-data-validation-and-format-consistency","title":"2.3. Data Validation and Format Consistency","text":"<ul> <li>Objective: Rigorously validate data against the schema in Appendix A.</li> <li>Checks: Data type verification, value range checks, categorical value consistency, basic relational integrity checks (e.g., consistent IDs).</li> <li>Discrepancy Handling: Refine cleansing scripts or (as a last resort for historical data) document manual corrections.</li> </ul>"},{"location":"master-plan/#24-management-of-missing-valuesoutliers","title":"2.4. Management of Missing Values/Outliers","text":"<ul> <li>Approach: Strategies will be determined based on EDA findings (Phase 3) and model requirements.</li> <li>Missing Values: Options include deletion (rows/columns), mean/median/mode imputation, regression imputation, or model-based imputation.</li> <li>Outliers: Identification (e.g., IQR, Z-scores) followed by potential capping, transformation, or removal.</li> </ul>"},{"location":"master-plan/#25-data-transformation-preparation-for-modeling","title":"2.5. Data Transformation (Preparation for Modeling)","text":"<ul> <li>Encoding Categorical Variables: Convert string categories (e.g., <code>CLASS</code>, <code>GOING</code>) into numerical representations (One-Hot, Label, Target Encoding).</li> <li>Numerical Scaling: Apply standardization or normalization if required by specific models.</li> <li>Other Transformations: Log transforms, polynomial features, etc., based on EDA and model needs.</li> </ul>"},{"location":"master-plan/#phase-3-exploratory-data-analysis-eda","title":"Phase 3: Exploratory Data Analysis (EDA)","text":"<p>(This phase focuses on understanding the data through querying, statistics, and visualizations to uncover patterns and formulate hypotheses.)</p>"},{"location":"master-plan/#31-data-querying","title":"3.1. Data Querying","text":"<ul> <li>Source: Cleansed data tables in Google BigQuery.</li> <li>Environment: Google Colab using the <code>google-cloud-bigquery</code> Python library.</li> <li>Process: Construct SQL queries in Colab, execute against BigQuery, load results into Pandas/Polars DataFrames for analysis.</li> </ul>"},{"location":"master-plan/#32-descriptive-statistics","title":"3.2. Descriptive Statistics","text":"<ul> <li>Tools: Python libraries (Pandas, NumPy) in Colab.</li> <li>Numerical Variables: Calculate count, mean, median, std dev, min, max, percentiles, skewness, kurtosis.</li> <li>Categorical Variables: Frequency counts, unique values, mode.</li> </ul>"},{"location":"master-plan/#33-visualization","title":"3.3. Visualization","text":"<ul> <li>Primary Tool: Plotly for interactive plots in Colab. Seaborn and Matplotlib as alternatives.</li> <li>Univariate Analysis: Histograms, density plots, box plots, bar charts.</li> <li>Bivariate/Multivariate Analysis: Scatter plots, correlation heatmaps, grouped plots, time series plots (if applicable).</li> </ul>"},{"location":"master-plan/#34-initial-observations-and-hypothesis-formulation","title":"3.4. Initial Observations and Hypothesis Formulation","text":"<ul> <li>Synthesize findings from statistics and visualizations.</li> <li>Identify significant patterns, trends, anomalies, and correlations.</li> <li>Formulate initial hypotheses about factors influencing race outcomes.</li> <li>Identify areas needing further investigation. These insights will guide Feature Engineering (Phase 4).</li> </ul>"},{"location":"master-plan/#phase-4-feature-engineering","title":"Phase 4: Feature Engineering","text":"<p>(This phase focuses on creating new, potentially more predictive variables from the cleaned dataset.)</p>"},{"location":"master-plan/#41-methodology","title":"4.1. Methodology","text":"<ul> <li>Environment: Google Colab using Pandas, NumPy, Polars, and Scikit-learn.</li> <li>Approach: Iterative process based on domain knowledge, EDA insights, and preliminary model testing.</li> <li>Goal: Transform base data into a richer feature set that captures complex racing dynamics.</li> </ul>"},{"location":"master-plan/#42-initial-feature-set","title":"4.2. Initial Feature Set","text":"<ul> <li>The starting point is the cleansed, validated dataset (approx. 40-50 core variables as per Appendix A).</li> </ul>"},{"location":"master-plan/#43-target-feature-set","title":"4.3. Target Feature Set","text":"<ul> <li>Strategically expand the initial set. The focus is on developing hypothesized predictive features and validating their impact, rather than a fixed target number of features.</li> </ul>"},{"location":"master-plan/#44-example-categories-of-engineered-features","title":"4.4. Example Categories of Engineered Features","text":"<ul> <li>Form &amp; Consistency: Rolling win/place percentages, average finishing position (recent races), days since last win.</li> <li>Speed &amp; Pace: Calculated speed figures, sectional speed ratings, comparisons to class/distance/track averages.</li> <li>Jockey/Trainer Statistics: Win/place rates (overall, by course, distance, class, horse combination), recent form.</li> <li>Odds-Based Features: Odds movement (if available), probability derived from odds, value indicators (odds vs. finish).</li> <li>Class &amp; Weight Related: Rating relative to class, weight carried relative to past or standard weights.</li> <li>Interaction &amp; Derived Features: Jockey win rate on this course, horse average speed at this distance.</li> <li>Lagged Variables: Performance metrics from the previous race.</li> </ul>"},{"location":"master-plan/#45-feature-engineering-approach","title":"4.5. Feature Engineering Approach","text":"<ul> <li>Iterative: Develop, test (correlation, feature importance from simple models, backtesting), refine/discard.</li> <li>New ideas may emerge during modeling and evaluation.</li> </ul>"},{"location":"master-plan/#46-roles-of-bigquery-and-colab","title":"4.6. Roles of BigQuery and Colab","text":"<ul> <li>BigQuery: Source for cleaned base data. Potentially store validated engineered features in new tables/views for efficient reuse.</li> <li>Colab: Primary environment for implementing complex feature calculation logic.</li> </ul>"},{"location":"master-plan/#phase-5-model-development-and-training","title":"Phase 5: Model Development and Training","text":"<p>(This phase involves selecting, training, and optimizing machine learning models to predict race outcomes.)</p>"},{"location":"master-plan/#51-model-selection","title":"5.1. Model Selection","text":"<ul> <li>Target Variable(s): To be clearly defined (e.g., predict win probability, predict top N finish, predict expected ROI).</li> <li>Baseline Models: Start with simpler, interpretable models (Logistic Regression, Linear Regression, Decision Trees, Random Forests).</li> <li>Advanced Models: Explore Gradient Boosting Machines (XGBoost, LightGBM, CatBoost), Neural Networks (MLPs, potentially RNNs/LSTMs if sequential data like sectional times are heavily used).</li> <li>Selection Criteria: Predictive performance (via backtesting), interpretability, computational cost, training time.</li> </ul>"},{"location":"master-plan/#52-training-environment","title":"5.2. Training Environment","text":"<ul> <li>Primary: Google Colab, leveraging free-tier GPU/TPU accelerators for computationally intensive models.</li> </ul>"},{"location":"master-plan/#53-validation-approach","title":"5.3. Validation Approach","text":"<ul> <li>Primary Method: Rigorous Backtesting.<ul> <li>Simulate training on historical data up to a point and evaluating on subsequent unseen historical data.</li> <li>Employ time-series aware validation (e.g., walk-forward validation) to prevent data leakage.</li> </ul> </li> </ul>"},{"location":"master-plan/#54-hyperparameter-optimization","title":"5.4. Hyperparameter Optimization","text":"<ul> <li>For promising models, optimize hyperparameters to maximize performance on validation sets.</li> <li>Techniques: Grid Search, Randomized Search, Bayesian Optimization (using libraries like Optuna or Scikit-learn tools).</li> </ul>"},{"location":"master-plan/#phase-6-model-evaluation-and-validation","title":"Phase 6: Model Evaluation and Validation","text":"<p>(This phase focuses on rigorously evaluating model performance, especially in the context of wagering profitability.)</p>"},{"location":"master-plan/#61-performance-metrics","title":"6.1. Performance Metrics","text":"<ul> <li>Primary Focus (Wagering Profitability):<ul> <li>Return on Investment (ROI).</li> <li>Hit Rate (Win Prediction Accuracy, Place Prediction Accuracy).</li> </ul> </li> <li>Standard ML Metrics (Task-Dependent):<ul> <li>Classification: Accuracy, Precision, Recall, F1-score, Log Loss, AUC-ROC, AUC-PR.</li> <li>Regression (if predicting rank/time): MAE, RMSE.</li> </ul> </li> </ul>"},{"location":"master-plan/#62-backtesting-outcomes","title":"6.2. Backtesting Outcomes","text":"<ul> <li>Present detailed quantitative results from backtesting simulations.</li> <li>Compare different models and hyperparameter configurations across historical validation periods.</li> </ul>"},{"location":"master-plan/#63-wagering-strategy-simulation","title":"6.3. Wagering Strategy Simulation","text":"<ul> <li>Simulate model use within defined wagering strategies during backtesting.</li> <li>Examples: Fixed Stakes, Percentage Stakes (e.g., fixed percentage of bankroll), Kelly Criterion (adjusting bet size based on perceived edge and odds).</li> <li>Simulation must account for historical odds and race results.</li> </ul>"},{"location":"master-plan/#64-profitability-analysis","title":"6.4. Profitability Analysis","text":"<ul> <li>In-depth analysis of simulated financial performance (total profit/loss, ROI, drawdown, risk-adjusted returns).</li> <li>Assess feasibility of achieving the project's primary objective (positive ROI).</li> </ul>"},{"location":"master-plan/#65-iterative-refinement","title":"6.5. Iterative Refinement","text":"<ul> <li>Evaluation results drive improvements:<ul> <li>Revisit Feature Engineering (Phase 4).</li> <li>Revisit Model Selection (Phase 5.1).</li> <li>Revisit Hyperparameter Optimization (Phase 5.4).</li> <li>Analyze errors to understand model strengths/weaknesses.</li> </ul> </li> </ul>"},{"location":"master-plan/#phase-7-deployment-and-monitoring-future-phase","title":"Phase 7: Deployment and Monitoring (Future Phase)","text":"<p>(This phase outlines operationalizing the model and monitoring its ongoing performance.)</p>"},{"location":"master-plan/#71-prediction-generation-workflow","title":"7.1. Prediction Generation Workflow","text":"<ul> <li>End-to-end process for generating predictions/insights for upcoming race days:<ul> <li>Acquire new racecard data.</li> <li>Apply preprocessing and feature engineering steps consistently.</li> <li>Load trained model.</li> <li>Generate predictions.</li> <li>Store/present predictions for decision-making.</li> </ul> </li> <li>Define automation level and tools.</li> </ul>"},{"location":"master-plan/#72-performance-monitoring","title":"7.2. Performance Monitoring","text":"<ul> <li>Track real-world effectiveness and profitability:<ul> <li>Collect actual race results.</li> <li>Compare outcomes against predictions.</li> <li>Track ROI based on simulated/actual wagers.</li> <li>Monitor for model drift or changes in data distributions.</li> </ul> </li> <li>Define metrics, frequency, and tools.</li> </ul>"},{"location":"master-plan/#73-retraining-approach","title":"7.3. Retraining Approach","text":"<ul> <li>Strategy for periodic model retraining:<ul> <li>Triggers: Performance degradation, fixed schedule, or significant new data accumulation.</li> <li>Process: Reuse pipelines from Phases 2-6 with updated data.</li> <li>Validation: Retrained models validated via backtesting before deployment.</li> </ul> </li> </ul>"},{"location":"master-plan/#phase-8-project-management-and-continuous-improvement","title":"Phase 8: Project Management and Continuous Improvement","text":"<p>(This section covers ongoing project aspects, learnings, and future considerations.)</p>"},{"location":"master-plan/#81-potential-challenges-and-resolutions-ongoing-log","title":"8.1. Potential Challenges and Resolutions (Ongoing Log)","text":"<p>(This list will be dynamic and updated in phase reports or a dedicated decisions/risks log as they arise.) * Cloud Costs (BigQuery/GCP): Monitor usage, optimize queries, leverage free tiers. * Feature Engineering Complexity: Iterative approach, start simple, leverage domain knowledge and EDA. * Model Validation &amp; Profitability: Rigorous backtesting, realistic wagering simulation. * Data Pipeline Robustness: Error handling, logging, monitoring. * Data Integrity &amp; Correction: Ongoing validation checks, clear process for corrections. * Web Scraping Maintenance: Monitor for HKJC site changes, allocate time for script updates.</p>"},{"location":"master-plan/#82-data-size-projections-and-growth","title":"8.2. Data Size Projections and Growth","text":"<ul> <li>Initial dataset (18 years, ~171k rows, 40-50 cols): ~20-50 MB.</li> <li>With engineered features (~150-200 cols): ~50-100 MB.</li> <li>Long-term growth (next 15-20 years): Potentially doubling to ~200-400 MB.</li> <li>These volumes are manageable within BigQuery free tiers and Colab.</li> </ul>"},{"location":"master-plan/#83-tools-summary","title":"8.3. Tools Summary","text":"<ul> <li>Data Storage &amp; Querying: Google BigQuery.</li> <li>Data Processing &amp; Modeling: Python in Google Colab (Pandas, Scikit-learn, etc.).</li> <li>Web Scraping: Python (Beautiful Soup / Playwright).</li> <li>Version Control: Git / GitHub.</li> <li>Documentation: MkDocs (Material theme).</li> <li>Project Management / Task Tracking: <code>docs/project-status.md</code>.</li> <li>(Original) Intermediary Data/Control: Google Sheets, Google Apps Script (may be revised).</li> </ul>"},{"location":"master-plan/#84-future-considerations","title":"8.4. Future Considerations","text":"<ul> <li>Advanced Deployment: If successful, explore more sophisticated deployment (e.g., dedicated prediction server, API).</li> <li>Alternative Data Sources: If HKJC scraping becomes untenable (unlikely to be better external sources).</li> <li>Deeper Model Exploration: More complex architectures if justified by performance.</li> </ul>"},{"location":"master-plan/#85-version-control-strategy","title":"8.5. Version Control Strategy","text":"<ul> <li>All project code, documentation, and configuration files will be version controlled using Git, hosted on a GitHub repository.</li> <li>Branches will be used for feature development and experimentation (e.g., <code>feature/new-scraper</code>, <code>experiment/new-model-arch</code>).</li> <li>The <code>main</code> branch will represent the stable, working version of the project.</li> <li>Commits should be descriptive and atomic.</li> </ul>"},{"location":"master-plan/#86-references","title":"8.6. References","text":"<p>(Placeholder for links to key documentation, research papers, articles, etc., consulted during the project.)</p> <ul> <li>HKJC Website: <code>[Link to be added]</code></li> <li>Pandas Documentation: <code>https://pandas.pydata.org/pandas-docs/stable/</code></li> <li>Scikit-learn Documentation: <code>https://scikit-learn.org/stable/</code></li> <li>MkDocs Material Theme: <code>https://squidfunk.github.io/mkdocs-material/</code></li> </ul> <p>Appendix A: Phase 1 Data Dictionary</p> <p>The following tables are from the <code>hk_racing_dataset</code></p>"},{"location":"master-plan/#a1-hk_racing_datasetrace_details","title":"A.1. <code>hk_racing_dataset.race_details</code>","text":"Column Name Data Type Description Notes / Example RACE_ID INTEGER Primary key. Unique identifier for each race, combining date and seasonal sequence. e.g. <code>20240414581</code> (YYYYMMDD + <code>581</code>) DATE DATE Calendar date when the race was held. <code>2024-04-14</code> VENUE STRING Name of the racecourse. <code>Sha Tin</code>, <code>Happy Valley</code> SURFACE STRING Track surface type. <code>Turf</code> or <code>AWT</code> (all-weather track) RACE_NUM_SEASON INTEGER Sequence number of this race in the current season (3-digit). <code>581</code> CLASS STRING Classification of the race by quality/conditions. <code>Class 1</code>, <code>Group 1</code>, <code>Griffin</code> DISTANCE INTEGER Race distance in metres. <code>1200</code>, <code>1650</code> RANKING STRING Official rating bracket for eligibility (upper-lower). <code>85-60</code>, <code>100-85</code> GOING STRING Turf going description, or condition of AWT. <code>GOOD</code>, <code>YIELDING (WET SLOW)</code>, <code>AWT</code> RACE_DESCRIPTION STRING Official race title. <code>THE HONG KONG EXCHANGES CHALLENGE CUP</code> TRACK_CONFIG STRING Course layout variant (e.g., inside rail offsets). <code>A</code>, <code>C+2</code>, <code>AWT</code> PRIZE INTEGER Total purse awarded (in HKD). <code>1200000</code> PEN_READING FLOAT Penetrometer reading for turf (strength) or Clegg hammer reading for AWT. <code>2.72</code> (turf), <code>8.4</code> (AWT)"},{"location":"master-plan/#a2-hk_racing_datasetrace_card","title":"A.2. <code>hk_racing_dataset.race_card</code>","text":"Column Name Data Type Description Notes / Example RUNNER_ID STRING Primary key. Uniquely identifies a horse in a specific race. <code>20240414581*CLEARWIN*H255</code> RACE_ID INTEGER Foreign key \u2192 <code>race_details.RACE_ID</code>. <code>20240414581</code> HORSE_ID STRING Foreign key \u2192 <code>horse_register.HORSE_ID</code>. <code>CLEARWIN*H255</code> WEIGHT INTEGER Total impost carried (jockey + equipment), in pounds. <code>126</code> HORSE_WEIGHT INTEGER Declared bodyweight of the horse (taken pre-race), in pounds. <code>1180</code> DRAW INTEGER Barrier (gate) number at start. <code>1</code> (inside rail) JOCKEY STRING Name of the jockey riding this runner. <code>Z Purton</code> TRAINER STRING Name of the trainer responsible for this runner. <code>D J Whyte</code> RATING INTEGER Official HKJC rating at time of race. <code>112</code> DEBUT_BOOL BOOLEAN Indicates if this was the horse\u2019s first-ever start in Hong Kong. <code>TRUE</code>, <code>FALSE</code> REST_DAYS INTEGER Days elapsed since the horse\u2019s previous run. <code>21</code> RACE_AGE INTEGER Age of the horse on race day, in years. <code>6</code> GEAR STRING Codes for equipment fitted (see Gear Key below). <code>PC/XB/TT</code>, <code>E</code>, <code>H1</code> <p>Gear Key (HKJC standard abbreviations):</p> Code Meaning Notes B Blinkers BO Blinker (one cowl) CC Cornell Collar CP Sheepskin Cheek Pieces CO Sheepskin (one side) E Ear Plugs H Hood P Pacifier PC Pacifier + cowls PS Pacifier (one cowl) SB Sheepskin Browband SR Shadow Roll TT Tongue Tie V Visor VO Visor (one cowl) XB Crossed Nose Band *1 First time use of that gear Suffix, e.g. <code>H1</code> *2 Gear replaced Suffix, e.g. <code>B2</code> -* Gear removed Suffix, e.g. <code>CC-</code>"},{"location":"master-plan/#a3-hk_racing_datasetrace_results","title":"A.3. <code>hk_racing_dataset.race_results</code>","text":"Column Name Data Type Description Notes / Example RUNNER_ID STRING Foreign key \u2192 <code>race_card.RUNNER_ID</code>. Matches each runner to its card entry. <code>20240414581*CLEARWIN*H255</code> RACE_ID INTEGER Foreign key \u2192 <code>race_details.RACE_ID</code>. <code>20240414581</code> HORSE_ID STRING Foreign key \u2192 <code>horse_register.HORSE_ID</code>. <code>CLEARWIN*H255</code> FINISH_POS INTEGER Official finishing position. Codes \u226590 may indicate non-finishers (e.g. DNS, UR). <code>1</code>, <code>2</code>, <code>DNF</code> STARTING_ODDS FLOAT Decimal odds at race start. <code>1.8</code>, <code>10.5</code> PLACE_PAYOUTS FLOAT Dividend payout for a successful \u201cplace\u201d bet. <code>0</code> or <code>NULL</code> if unplaced or no payout available. <code>2.5</code>, <code>NULL</code> FINISH_TIME FLOAT Winner\u2019s official finishing time in seconds. <code>71.52</code> SEC_TIME_1 FLOAT Sectional time for first segment (varies by course layout). <code>22.15</code> SEC_TIME_2 FLOAT Sectional time for second segment. <code>23.00</code> SEC_TIME_3 FLOAT Sectional time for third segment. <code>26.37</code> SEC_TIME_4 FLOAT Sectional time for fourth segment (if applicable). \u2014 SEC_TIME_5 FLOAT Sectional time for fifth segment (if race &gt;1,600 m). \u2014 SEC_TIME_6 FLOAT Sectional time for sixth segment (if race &gt;2,200 m). \u2014"},{"location":"master-plan/#a4-hk_racing_datasethorse_register","title":"A.4. <code>hk_racing_dataset.horse_register</code>","text":"Column Name Data Type Description Notes / Example HORSE_ID STRING Primary key. Stable identifier for each horse across all races. <code>DEANSANGEL*D123</code> HORSE_CODE STRING Unique alphanumeric code assigned by HKJC (distinguishes duplicates). <code>D466</code>, <code>H255</code> HORSE_NAME STRING Official registered name of the horse. <code>DEAN\u2019S ANGEL</code> SEX STRING Gender classification. <code>MALE</code>,<code>FEMALE</code> COLOR STRING Coat colour. <code>Bay</code>, <code>Chestnut</code> COUNTRY_OF_ORIGIN STRING Country where the horse was foaled (ISO 3-letter code). <code>AUS</code>, <code>NZ</code>, <code>IRE</code> IMPORT_TYPE STRING Means by which horse entered HK racing. <code>PP</code>, <code>PPG</code>, <code>ISG</code>, <code>VIS</code> SIRE STRING Registered name of the horse\u2019s father. <code>ALL TOO HARD</code> DAM STRING Registered name of the horse\u2019s mother. <code>ANGEL IN MY HEART</code> DAM_SIRE STRING Registered sire of the dam (maternal grandsire). <code>SEBRING</code> OWNER STRING Name(s) of the owner(s) as recorded by HKJC. <code>Mr &amp; Mrs John Smith</code> <p>Key relationship summary:</p> <ul> <li><code>race_details.RACE_ID</code> \u2192 parent of both <code>race_card</code> and <code>race_results</code>.</li> <li><code>race_card.RUNNER_ID</code> \u2192 referenced by <code>race_results.RUNNER_ID</code>.</li> <li><code>horse_register.HORSE_ID</code> \u2192 parent of both <code>race_card.HORSE_ID</code> and <code>race_results.HORSE_ID</code>.</li> </ul> <p>Import Type Key:</p> <ul> <li><code>PP</code>: Privately Purchased Horses (previously raced elsewhere).</li> <li><code>PPG</code>: Privately Purchased Griffins (unraced young horses).</li> <li><code>ISG</code>: International Sale Griffins (unraced horses from approved sales).</li> <li><code>VIS</code>: Visiting Invitational Horses (invited for specific major races).</li> </ul>"},{"location":"phase-01-collection/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-02-cleansing/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-03-eda/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-04-features/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-05-model/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-06-evaluation/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-07-deployment/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-08-management/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"project-accomplishments/","title":"Project Accomplishments","text":""},{"location":"project-accomplishments/#genaral-project-setup-accomplishments","title":"Genaral Project Setup Accomplishments","text":"<ul> <li> <p>\u2705 M0.1: Project Repository and Core Structure Established:</p> <ul> <li>GitHub repository (<code>hk_racing_project</code>) initialized and configured.</li> <li>Standardized project directory structure (<code>src</code>, <code>docs</code>, <code>data</code>, <code>tests</code>, <code>notebooks</code>, <code>scripts</code>, <code>config</code>) implemented, promoting clear separation of concerns.</li> <li>Comprehensive <code>.gitignore</code> file established to manage version control hygiene.</li> <li>Initial <code>README.md</code> created, providing a project overview.</li> </ul> </li> <li> <p>\u2705 M0.2: Master Plan Document (<code>master-plan.md</code>) Finalized:</p> <ul> <li>The \"0. Project Definition and Establishment\" section of <code>master-plan.md</code> has been thoroughly reviewed, refined, and finalized.</li> <li>Key decisions regarding project workflow, toolset (VS Code, Colab), data handling strategies (direct BQ ingestion, GCS for models), and configuration management have been documented.</li> <li>The <code>master-plan.md</code> now serves as a robust foundational document for the project.</li> </ul> </li> <li> <p>\u2705 M0.3: Documentation Site (MkDocs) Configured and Operational:</p> <ul> <li>MkDocs and the Material theme successfully installed and configured.</li> <li><code>mkdocs.yml</code> created, defining site navigation, theme settings, and linking to the project repository.</li> <li>The documentation site is buildable locally, providing a clear and accessible way to view project documentation.</li> <li>(Optional, if done) GitHub Pages deployment for the documentation site is operational.</li> </ul> </li> <li> <p>\u2705 M0.4: Standard Project Documentation Shells Created:</p> <ul> <li>Shell markdown files for all project phases (Phase 1 through Phase 8), <code>decisions.md</code>, and <code>project-status.md</code> have been created within the <code>docs/</code> directory.</li> <li>The structure for <code>project-status.md</code> has been defined and implemented, enabling effective manual progress tracking.</li> <li>This establishes a complete framework for ongoing project documentation.</li> </ul> </li> <li> <p>\u2705  M0.5: Development Environment and Tooling Configured:</p> <ul> <li>Local Python virtual environment (<code>.venv</code>) established.</li> <li>Core Python libraries (e.g., <code>pandas</code>, <code>requests</code>, <code>google-cloud-*</code>) installed via <code>requirements.txt</code>.</li> <li>Development libraries (e.g., <code>pytest</code>, <code>mkdocs</code>, <code>black</code>, <code>flake8</code>) installed via <code>requirements-dev.txt</code>.</li> <li>Visual Studio Code configured for Python development, including interpreter selection, linting (Flake8), and formatting (Black).</li> <li>Confirmed access to Google Colab and successful connection to Google Cloud Platform (GCP) services from Colab environment.</li> </ul> </li> <li> <p>\u2705 M0.6: Cloud Services (GCP) Initial Setup and Access Confirmed: Accomplishments:</p> <ul> <li>Google Cloud Platform (GCP) project established.</li> <li>Necessary APIs (BigQuery, Cloud Storage, IAM) enabled in the GCP console.</li> <li>A GCP Service Account created with appropriate roles (e.g., BigQuery Data Editor, Storage Object Admin) for data access.</li> <li>Service account JSON key downloaded, stored securely, and the <code>GOOGLE_APPLICATION_CREDENTIALS</code> environment variable configured for programmatic access.</li> </ul> </li> <li> <p>\u2705 M0.7: Configuration Management Strategy Implemented: Accomplishments:</p> <ul> <li><code>config/</code> directory established at the project root for centralized configuration management.</li> <li>An example configuration file, <code>config/config.yaml.example</code>, created, outlining the structure for data sources, GCP project ID, and BigQuery details.</li> <li>A local <code>config/config.yaml</code> file (copied from the example) created for actual project configurations.</li> <li><code>config/config.yaml</code> added to <code>.gitignore</code> to prevent accidental versioning of sensitive or environment-specific settings.</li> <li>A basic Python utility, <code>src/common/config_loader.py</code>, developed to load configurations from <code>config.yaml</code>.</li> </ul> </li> </ul>"},{"location":"project-accomplishments/#phase-1-accomplishments","title":"Phase 1 Accomplishments","text":"<ul> <li> <p>\u2705 M1.1: BigQuery Environment Setup &amp; Configuration</p> <ul> <li>The <code>hk_racing_dataset</code> and <code>hk_racing_scraped_raw</code> BigQuery datasets are created in the designated GCP project.</li> <li><code>config/config.yaml</code> updated to include <code>bq_main_dataset_id: \"hk_racing_dataset\"</code> and <code>bq_scraped_raw_dataset_id: \"hk_racing_scraped_raw\"</code>.</li> <li><code>src/common/config_loader.py</code> verified to correctly load these dataset IDs.</li> <li>Purpose and intended content of each BigQuery dataset documented in <code>docs/phase-01-collection.md</code> (or equivalent documentation).</li> </ul> </li> <li> <p>\u2705 M1.2: Ingestion of Processed Historical Data (Google Sheets to BigQuery)     *Table schemas in <code>hk_racing_dataset</code> (for <code>results</code>, <code>racecard</code>, <code>race_details</code>, <code>horse_register</code>) are defined and documented in Appendix A of <code>master-plan.md</code>, and corresponding tables are understood to be created/creatable in BigQuery.</p> </li> </ul>"},{"location":"project-status/","title":"Project Status","text":"<p>Last Manually Updated: 2025-05-13</p> <p>Overall Project Health: Green</p> <p>Current Phase: Phase 1: Data Collection and Storage</p> <p>Genaral Project Setup is complete. Phase 1 set to begin</p> <p>Key Focus for This Week (ending 2005-05-17):</p> <p>Milestone 1.1: BigQuery Environment Setup &amp; Configuration</p>"},{"location":"project-status/#0-general-project-setup","title":"0. General Project Setup","text":"<p>Overall Phase Objective: Complete to overall project infrastructure, documentation, planning, and core technical setup before specific data work begins</p> <p>current status: complete</p>"},{"location":"project-status/#genaral-project-setup-milestones","title":"Genaral Project Setup Milestones","text":"<ul> <li>\u2705M0.1: Project Repository and Core Structure Established: Ensure the GitHub repository is correctly set up with a logical folder structure for code, docs, data, etc.</li> <li>\u2705 M0.2: Master Plan Document (<code>master-plan.md</code>) Finalized: Complete and finalize the comprehensive General Project Setup plan in <code>master-plan.md</code> incorporating all decisions from the initial planning phase.</li> <li>\u2705 M0.3: Documentation Site (MkDocs) Configured and Operational: Set up MkDocs with the chosen theme, configure navigation in <code>mkdocs.yml</code>, and ensure the site builds and deploys correctly (e.g., to GitHub Pages).</li> <li>\u2705 M0.4: Standard Project Documentation Shells Created: Create placeholder markdown files for all planned phases (e.g., <code>phase-01-collection.md</code>, <code>phase-02-cleansing.md</code>, etc.), a <code>decisions.md</code> log, and any other key supporting documentation. Finalize <code>docs/project-status.md</code> structure (current working version).</li> <li>\u2705  M0.5: Development Environment and Tooling Configured: Set up local (VS Code) and cloud (Google Colab) development environments, including Python, necessary libraries, and IDE configurations.</li> <li>\u2705 M0.6: Cloud Services (GCP) Initial Setup and Access Confirmed: Set up the Google Cloud Project, enable necessary APIs (BigQuery, Cloud Storage, IAM), and confirm programmatic access (e.g., service account credentials).</li> <li>\u2705 M0.7: Configuration Management Strategy Implemented: Establish the <code>config/</code> directory structure with example configuration files and ensure sensitive configurations are correctly handled (e.g., via <code>.gitignore</code>).</li> </ul>"},{"location":"project-status/#ongoing-task-and-issues","title":"Ongoing Task and Issues","text":"Status Task / Issue Description Milestone Notes / Resolution Priority Date Due Tags \u2705 No current tasks or issues All completed"},{"location":"project-status/#phase-1-data-collection-and-storage","title":"Phase 1: Data Collection and Storage","text":"<p>Overall Phase Objective: To acquire all relevant raw and processed historical data from 2008 onwards and establish a structured and robust initial storage solution in Google BigQuery. This involves ingesting previously processed data (2008-Nov 2023 from Google Sheets) and developing the capability to collect ongoing race data (Dec 2023 onwards from HKJC website).</p> <p>Current Status: In Progress (Milestone 1.1 Complete, Milestone 1.2 In Progress)</p>"},{"location":"project-status/#phase-1-milestones","title":"Phase 1 Milestones","text":"<ul> <li>M1.1: BigQuery Environment Setup &amp; Configuration: Ensure BigQuery datasets are created and project configuration is updated.</li> <li>M1.2: Ingestion of Processed Historical Data (Google Sheets to BigQuery): Transfer the user's existing processed and error-corrected data (2008 - November 2023) from Google Sheets into the <code>hk_racing_dataset</code> in BigQuery, matching schemas defined in Appendix A of <code>master-plan.md</code>.</li> <li>M1.3: Development of HKJC Web Scraping Capability: Develop Python scripts to scrape required data types (racecards, results, horse details, etc.) from the HKJC website for data from December 2023 onwards.</li> <li>M1.4: Initial Ingestion of Scraped HKJC Data into BigQuery: Load an initial batch of scraped HKJC data (e.g., December 2023 - current date) into the <code>hk_racing_scraped_raw</code> BigQuery dataset.</li> <li>M1.5: Phase 1 Documentation and Review: Ensure all Phase 1 activities, designs, and processes are documented and reviewed.</li> </ul>"},{"location":"project-status/#phase-1-tasksissues","title":"Phase 1 Tasks/Issues","text":"ID Description Milestone Priority Status Due Date Notes M1.2 Ingestion of Processed Historical Data (Google Sheets to BigQuery) P1.2.2 Develop/finalize Python scripts (<code>src/ingestion/load_sheets_data.py</code>) to read data from the specified Google Sheets. M1.2 High Open Parameterize Sheet names/IDs and target BigQuery table names. Implement robust error handling and logging. P1.2.3 Perform a full load of the historical processed data (2008-Nov 2023) from Google Sheets into the corresponding BigQuery tables in <code>hk_racing_dataset</code>. M1.2 High Open Ensure data conforms to schemas in Appendix A. P1.2.4 Validate data integrity post-ingestion (e.g., row counts, spot checks on key fields against Google Sheets source). M1.2 Medium Open P1.2.5 Document the Google Sheets ingestion process and script usage in <code>docs/phase-01-collection.md</code>. M1.2 Medium Open M1.3 Development of HKJC Web Scraping Capability P1.3.1 Identify specific HKJC website URLs and page structures for each required data type (race results, race cards, horse details). M1.3 High Open Investigate if Playwright/Selenium is needed or if <code>requests</code>/<code>BeautifulSoup</code> is sufficient. P1.3.2 Develop initial scraping script for one data type (e.g., Race Results). M1.3 High Open Handle pagination, navigation. Define preliminary data formatting. Structure output for <code>hk_racing_scraped_raw</code>. P1.3.3 Develop scraping scripts for remaining data types (Race Cards, Horse Details). M1.3 High Open P1.3.4 Implement robust error handling, logging, and mechanisms to manage scraping responsibly (e.g., delays, user-agent). M1.3 High Open P1.3.5 Integrate <code>src/ingestion/race_calendar.py</code> to guide the scraping of race-specific data based on meeting dates. M1.3 Medium Open P1.3.6 Store scraping scripts in <code>src/ingestion/</code>. M1.3 Low Open Code organization. P1.3.7 Document scraper design, dependencies, and usage in <code>docs/phase-01-collection.md</code>. M1.3 Medium Open M1.4 Initial Ingestion of Scraped HKJC Data into BigQuery P1.4.1 Define table schemas for the <code>hk_racing_scraped_raw</code> dataset. M1.4 High Open These should initially be flexible to accommodate the raw scraped data structure. P1.4.2 Develop/finalize Python scripts (<code>src/ingestion/load_scraped_data.py</code>) to load formatted scraped data into <code>hk_racing_scraped_raw</code>. M1.4 High Open From intermediate JSON/CSV files or directly from scraper output. P1.4.3 Perform an initial batch load of scraped data (Dec 2023 - present) into BigQuery. M1.4 High Open P1.4.4 Validate data integrity post-ingestion (Scraped data). M1.4 Medium Open P1.4.5 Document scraped data loading process in <code>docs/phase-01-collection.md</code>. M1.4 Medium Open M1.5 Phase 1 Documentation and Review P1.5.1 Ensure <code>docs/master-plan.md</code> accurately reflects all Phase 1 decisions and scope. M1.5 Medium Open Confirm Appendix A is complete and accurate. P1.5.2 Complete all documentation tasks mentioned in previous milestones (within <code>docs/phase-01-collection.md</code> or other relevant documents). M1.5 Medium Open Consolidate documentation for ingestion scripts, scraper design etc. P1.5.3 Update <code>project-status.md</code> to reflect the completion of all Phase 1 tasks and milestones. M1.5 Medium Open P1.5.4 Conduct a review of Phase 1 deliverables and plan for Phase 2. M1.5 High Open"}]}