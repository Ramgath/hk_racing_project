{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"hk horse racing","text":""},{"location":"decisions/","title":"Key Project Decisions","text":"<p>This document tracks the major design and process decisions for the HK Racing Project, along with context and rationale.</p>"},{"location":"decisions/#week-1-2025-05-04","title":"WEEK 1: 2025-05-04","text":"<ul> <li> <p>Decision: Define primary development environment roles: VS Code for core development, Google Colab for EDA &amp; intensive ML.</p> <ul> <li>Rationale: Leverages VS Code's strengths for project management &amp; script development, and Colab's strengths for experimentation &amp; hardware acceleration. Clear separation of concerns. (Alternatives: Using only Colab; Using only VS Code).</li> </ul> </li> <li> <p>Decision: Adopt direct Python-to-BigQuery for raw data ingestion.</p> <ul> <li>Rationale: Increases robustness, scalability, and efficiency of the automated scraping pipeline. Reduces manual steps and potential points of failure associated with Sheets intermediary. (Alternatives: Google Sheets as intermediary for raw data; Local files then upload to BQ).</li> </ul> </li> <li> <p>Decision: Implement data corrections in BigQuery via Python scripts.</p> <ul> <li>Rationale: Scripted corrections are version-controllable, auditable, and more robust. A GSheet for logging corrections could be a future UI enhancement if needed. (Alternatives: Direct manual edits in BQ console; Google Sheet as a UI for triggering updates).</li> </ul> </li> <li> <p>Decision: Use Google Cloud Storage (GCS) for storing trained model artifacts.</p> <ul> <li>Rationale: GCS offers better versioning, programmatic access, and integration with MLOps tools (like Vertex AI Model Registry). Likely free/low-cost for project scale. (Alternatives: Google Drive; Storing models directly in the Git repository).</li> </ul> </li> <li> <p>Decision: Utilize Vertex AI Model Registry for model versioning and metadata.</p> <ul> <li>Rationale: Provides a centralized, free (for registration) service for managing model lifecycle, improving organization and reproducibility. Points to models in GCS. (Alternatives: Manual tracking in spreadsheets; Custom solution).</li> </ul> </li> <li> <p>Decision: Defer dashboarding; consider Streamlit for future results presentation.</p> <ul> <li>Rationale: Focus on core pipeline first. Streamlit offers a Python-native way to quickly build interactive UIs when predictions are ready. (Alternatives: Dash; Custom HTML/JS; GitHub Pages for static reports).</li> </ul> </li> <li> <p>Decision: Implement <code>config/</code> directory with <code>config.yaml</code> (gitignored) and <code>config.yaml.example</code> for project settings.</p> <ul> <li>Rationale: Centralizes configuration, improves clarity, facilitates different environments (if needed later), and keeps secrets out of version control. (Alternatives: Hardcoding configurations; Environment variables only).</li> </ul> </li> <li> <p>Decision: Create <code>src/common/config_loader.py</code> for loading YAML configurations.</p> <ul> <li>Rationale: Provides a standardized, reusable way to access configurations throughout the project. (Alternatives: Ad-hoc loading in multiple scripts).</li> </ul> </li> </ul> <p>Coherence Summary for Week 1: The decisions in Week 1 collectively establish a robust MLOps foundation. They define clear roles for development environments (VS Code, Colab), establish a direct and script-based data ingestion and correction pipeline (Python to BigQuery), and set up best practices for model artifact storage and versioning (GCS, Vertex AI Model Registry). Configuration management is also addressed systematically. This coherent set of choices prioritizes automation, scalability, and reproducibility from the project's inception, focusing on building a solid technical backbone before tackling UI or dashboarding aspects.</p>"},{"location":"decisions/#week-2-2025-05-11","title":"WEEK 2: 2025-05-11","text":"<ul> <li> <p>Decision: Manage <code>project-status.md</code> manually instead of script-based generation from Google Sheets for detailed tasks.</p> <ul> <li>Rationale: User preference for direct Markdown editing and control. Simplifies tooling if more comfortable with manual updates. (Alternatives: Python script to generate phase-specific task tables; Python script for single task table).</li> </ul> </li> <li> <p>Decision: Exclude pre-2008 historical data from the project scope.</p> <ul> <li>Rationale:<ol> <li>Data is error-prone and difficult to load/validate in BigQuery.</li> <li>Significant missing values for critical data points (win odds, horse weights, HKJC ratings).</li> <li>Absence of sectional timings, and concerns about the accuracy of overall finish times.</li> <li>Inconsistent false rail configurations prior to the 2008 GPS tracking system introduction, making comparisons with modern data unreliable.</li> <li>Lack of advanced timing systems (e.g., precision to two decimal places).</li> <li>The effort to cleanse and integrate this data outweighs the potential benefits, and focusing on 2008+ data ensures higher quality and relevance.</li> </ol> </li> <li>Impact: Simplifies Phase 1 data collection and Phase 2 cleansing efforts. The <code>hk_racing_historical_raw</code> BigQuery dataset will not be created.</li> </ul> </li> <li> <p>Decision: Refine BigQuery Dataset Strategy for Phase 1.</p> <ul> <li><code>hk_racing_dataset</code> (Main Dataset):<ul> <li>Will store processed historical data (2008 - November 2023) ingested from user-provided Google Sheets.</li> <li>Target schemas for tables (<code>results</code>, <code>racecard</code>, <code>race_details</code>, <code>horse_register</code>) are defined by the user in <code>Appendix A: Phase 1 Data Dictionary</code> of the <code>master-plan</code></li> <li>This dataset will also be the target for fully cleansed and integrated analytical data in later phases.</li> </ul> </li> <li><code>hk_racing_scraped_raw</code> (Staging/Raw Dataset):<ul> <li>Will store raw data collected from the HKJC website (December 2023 onwards) after preliminary Python-based formatting.</li> <li>Table structures will initially mirror the scraped data structure.</li> </ul> </li> <li>Rationale: Clear separation of already processed historical data from newly scraped raw data. Facilitates a focused approach for Phase 1 collection and prepares for Phase 2 cleansing and integration.</li> <li>Impact: <code>config/config.yaml</code> to be updated with <code>bq_main_dataset_id</code> and <code>bq_scraped_raw_dataset_id</code>.</li> </ul> </li> <li> <p>Decision: Confirm target schemas for <code>hk_racing_dataset</code> tables.</p> <ul> <li>Source: The structure and field definitions provided by the user are adopted as the definitive schemas for the <code>results</code>, <code>racecard</code>, <code>race_details</code>, and <code>horse_register</code> tables within the <code>hk_racing_dataset</code>.</li> <li>Impact: Provides clear targets for the ingestion of processed Google Sheets data. These schemas will be documented in Appendix A of <code>master-plan.md</code>.</li> </ul> </li> <li> <p>Decision: Evaluate Google Cloud Dataform for SQL transformation management in future phases.</p> <ul> <li>Rationale: For phases involving significant SQL-based data transformations within BigQuery (e.g., Phase 2: Cleansing, Phase 4: Features), Dataform offers potential benefits for version control, dependency management, testing, and orchestration of SQL workflows. This will be assessed as SQL complexity grows.</li> <li>Impact: No immediate change to Phase 1. Local Git repository remains the primary version control for all project assets. Dataform exploration is a consideration for later stages.</li> </ul> </li> </ul> <p>Coherence Summary for Week 2: The decisions in Week 2 refine the project's data strategy and operational management. Key choices include scoping out problematic pre-2008 data to ensure data quality and relevance, and establishing a clear two-tiered BigQuery dataset structure (<code>hk_racing_dataset</code> for processed historical data and <code>hk_racing_scraped_raw</code> for new raw data). Confirming the schemas for the main dataset provides a solid foundation for historical data ingestion. The decision to manually manage <code>project-status.md</code> reflects a practical choice for task tracking, while the consideration of Dataform for future SQL transformations indicates forward-thinking for later project phases. These decisions collectively streamline the data collection focus and prepare for systematic data processing.</p>"},{"location":"decisions/#week-3-2025-05-18","title":"WEEK 3: 2025-05-18","text":"<p>The decisions made in Week 3 demonstrate a clear strategic shift to prioritize the acquisition of a rich historical dataset. They flow logically as follows:</p> <p>Strategic Pivot to Historical Data:</p> <ul> <li>Decision: Pause scraping of the live HKJC website to prioritize the acquisition of historical data from CSV files spanning 2008-2023.</li> <li>Rationale: This recognizes that a deep historical dataset is crucial for robust model training, taking precedence over immediately available current season data.</li> <li>Impact: Development focus shifts to tooling for CSV extraction, potentially delaying current data ingestion but significantly enriching the dataset's historical depth.</li> </ul> <p>Method for Historical Data Acquisition:</p> <ul> <li>Decision: Utilize Google Colab for the one-time scraping of these historical CSV reports.</li> <li>Rationale: This approach aims to mitigate the risk of IP address blocking during a large, one-off data extraction task by leveraging Colab's environment.</li> <li>Impact: Increases the likelihood of successfully acquiring the bulk historical data without interruption.</li> </ul> <p>Code Management for One-Off Task:</p> <ul> <li>Decision: Exclude the historical CSV scraping code from the main project repository and automated pipeline.</li> <li>Rationale: As this is a specialized, one-time task dealing with an outdated format, keeping this code separate avoids cluttering the main repository, which is focused on the ongoing, automated pipeline for current data.</li> <li>Impact: The main codebase remains lean and focused on reproducible, ongoing processes. The historical scraping script can be archived separately.</li> </ul> <p>Coherence Summary for Week 3: These decisions coherently address a strategic goal: secure extensive historical data first. The choice of tool (Colab) supports this goal by minimizing scraping risks, and the decision on code management keeps the main project focused and clean.</p>"},{"location":"decisions/#week-4-2025-05-25","title":"WEEK 4: 2025-05-25","text":"<p>Week 4's decisions address the complexities arising from integrating the newly prioritized historical data with current data formats, particularly concerning textual incident reports. There's a clear progression from identifying a problem to exploring a solution and then reacting to implementation challenges:</p> <p>Addressing Data Heterogeneity:</p> <ul> <li>Decision: Formally acknowledge and plan to address the structural differences between historical race reports (comprehensive, single documents from CSVs) and current HKJC reports (more granular, incident-focused). The goal is to attempt data alignment for a cohesive longitudinal dataset.</li> <li>Rationale: To enable consistent analysis and modeling across the entire dataset (2008-present), these different data structures must be reconciled.</li> <li> <p>Impact: This necessitates significant data wrangling and transformation efforts. The success of this alignment will heavily influence the analytical capabilities of the combined dataset.</p> </li> <li> <p>Decision: Redefine <code>race_calendar.py</code> (reading from a user-managed Google Sheet) as the primary trigger for the scraping pipeline for new race meetings.</p> <ul> <li>Rationale: The <code>race_calendar.py</code> script currently fetches manually entered race meeting dates. By making this script the starting point of the scraping pipeline, subsequent scraping scripts (for racecards, results, horse details, etc.) can be orchestrated to run based on the dates provided by this calendar. This centralizes control over which race meetings are targeted for scraping and automates the initiation of the process.</li> <li>Impact: The Google Sheet serving as the race calendar becomes a critical control input for the ongoing data collection pipeline. Subsequent scraping modules will be designed to consume dates/meeting information from the output of <code>race_calendar.py</code>. This decision moves the project towards a more automated and orchestrated scraping workflow for new data.</li> </ul> </li> <li> <p>Decision: Incorporate \"Comments on Running\" reports alongside \"Full Stewards' Reports\" for a comprehensive incident analysis.</p> <ul> <li>Rationale: Initial inspection reveals that Full Stewards' Reports primarily detail the factual nature of incidents (e.g., \"horse was bumped, stumbled, and lost lengths\"). In contrast, \"Comments on Running\" often focus on the implications or consequences of these incidents from a performance perspective (e.g., \"slow in the start\"). Utilizing both report types will provide a more holistic understanding of incidents and their impact on a horse's race.</li> <li>Impact: This requires identifying and scraping/extracting \"Comments on Running\" data, which may have its own distinct format. Data integration strategies will need to account for linking these comments to specific incidents or horses from the stewards' reports. This enriches the dataset for nuanced incident-based feature engineering.</li> </ul> </li> </ul> <p>Proposed Solution for Nuanced Incident Extraction:</p> <ul> <li>Decision: Utilize a reasoning model (Large Language Model via API) to interpret and categorize horse-related incidents from textual reports in the historical data.</li> <li>Rationale: This approach aims to preserve the nuances often lost in simpler rule-based extraction when trying to map comprehensive older reports to newer, granular incident structures.</li> <li>Impact: Introduces an external API dependency and potential costs but offers higher fidelity incident data.</li> </ul> <p>Challenges and Pausing of API-Based Solution: This central decision led to a series of sub-decisions based on empirical testing and cost analysis of different LLMs:</p> <ul> <li> <p>Sub-Decision (Gemini Flash 2.5 Preview): Paused due to hallucination issues (specifically, it provided data related to an incorrect geographical context - South Africa - instead of using the provided Hong Kong data) and potential ongoing API costs beyond initial free tiers. This model (updated on May 20, 2025, offering 500 free prompts) was initially considered the most cost-effective and fast.</p> <ul> <li>API Pricing:<ul> <li>Non-thinking (per 1M tokens):<ul> <li>Input: $0.15</li> <li>Output: $0.60</li> </ul> </li> <li>Thinking (per 1M tokens):<ul> <li>Input: $0.15</li> <li>Output: $3.50</li> </ul> </li> </ul> </li> <li>Impact: Initial preferred cost-effective model proved unreliable for this task.</li> </ul> </li> <li> <p>Sub-Decision (OpenAI GPT-4o mini): Paused due to slow processing speed and, critically, unexpectedly high \"thinking\" or processing token consumption (approximately 10 times the input token count). This significantly altered the projected cost, escalating it from an anticipated sub-$20 to over $200 for the required task, making it economically unviable. This was an oversight by the user, unaware that thinking tokens are included in the output token count. (An initial $20 API credit was purchased, only 50c was used, and $19.50 will be used in future if an opportunity arises, or API prices significantly decrease).</p> <ul> <li>API Pricing (per 1M tokens):<ul> <li>Input: $1.100</li> <li>Cached input: $0.275</li> <li>Output: $4.400</li> </ul> </li> <li>Impact: A seemingly viable alternative also became economically unfeasible.</li> </ul> </li> <li> <p>Sub-Decision (Gemini 2.5 Pro Preview): While paused for bulk historical processing due to API costs, this model remains the best performer in terms of reasoning capabilities among those tested. The free tier (currently 25 free messages/prompts per day, as of May 06, 2025 update) will be utilized. Testing has shown the model is capable of handling a full raceday's reports within this daily free limit. Unfortunately, with over 1370 historical racedays (and growing), comprehensive processing of the entire backlog is not feasible under current free tier constraints. Once the API price comes down or free limits increase, more workload can be taken on.</p> <ul> <li>API Pricing (per 1M tokens, UI remains free of charge):<ul> <li>Input:<ul> <li><code>&lt;=200K tokens</code>: $1.25</li> <li><code>&gt; 200K tokens</code>: $2.50</li> </ul> </li> <li>Output:<ul> <li><code>&lt;=200K tokens</code>: $10.00</li> <li><code>&gt; 200K tokens</code>: $15.00</li> </ul> </li> </ul> </li> <li>Impact: The highest quality model tested is currently too expensive for bulk historical processing. However, the free tier allows for limited, ongoing processing or targeted analysis of specific race days, and increased workload adoption is contingent on future API price reductions or an increase in free tier limits.</li> </ul> </li> </ul> <p>Coherence Summary for Week 4: These decisions coherently outline strategies for handling data heterogeneity (differing report structures, comprehensive incident data), including enriching incident understanding by incorporating both \"Stewards' Reports\" and \"Comments on Running.\" A key operational decision redefines the <code>race_calendar.py</code> script as the trigger for a more orchestrated scraping pipeline. Furthermore, a sophisticated proposed solution for nuanced incident data extraction (LLM) was explored, leading to a data-driven rationale for pausing that solution due to model unreliability and prohibitive costs identified during testing. This demonstrates a pragmatic approach to R&amp;D, data enrichment, and pipeline automation within budget constraints. The project will proceed with other alignment tasks while the LLM-dependent component is on hold, but with a clearer path for future incident data integration and a more structured approach to ongoing data collection.</p>"},{"location":"master-plan/","title":"Hong Kong Racing Project: Master Plan","text":"<p>This document outlines the technical plan for building a handicapping and wagering system for thoroughbred horse racing in Hong Kong, with the primary objective of achieving sustainable financial gain through data-driven strategies. It serves as the central reference for project scope, methodology, and planned execution across all phases.</p>"},{"location":"master-plan/#project-definition-and-establishment","title":"Project Definition and Establishment","text":""},{"location":"master-plan/#01-introduction-and-aims","title":"0.1. Introduction and Aims","text":""},{"location":"master-plan/#011-project-objective","title":"0.1.1. Project Objective","text":"<ul> <li>Goal: Develop and implement a machine learning-based handicapping and wagering system aimed at generating a positive return on investment (ROI) from Hong Kong horse racing.</li> <li>Team: Solo project with assistance from AI (e.g., Google Gemini).</li> <li>Broader Context: This project focuses on the technical development of a predictive system for financial gain within the domain of horse race wagering. It's acknowledged that this operates within the context of gambling, and responsible practices should guide any potential future application of the system's outputs.</li> </ul>"},{"location":"master-plan/#012-document-purpose","title":"0.1.2. Document Purpose","text":"<p>This <code>project_plan.md</code> (and the accompanying MkDocs site) serves several key purposes:</p> <ul> <li>Centralized Record: Acts as the primary repository for documenting all project plans, methodologies, data sources, and strategic decisions made throughout the project lifecycle.</li> <li>Shared Context for AI Collaboration: Functions as a persistent memory and context for ongoing work and discussions with AI assistants. Referencing and updating this plan and related phase reports ensures continuity.</li> <li>Single Source of Truth: Establishes a definitive reference point for the project's scope, workflow, tools, and challenges.</li> <li>Tracking Evolution: While this document outlines the plan, individual phase reports (<code>docs/phase-XX-name.md</code>) will track the execution and evolution of the project.</li> </ul>"},{"location":"master-plan/#02-resource-and-environment-configuration","title":"0.2. Resource and Environment Configuration","text":""},{"location":"master-plan/#021-hardware","title":"0.2.1. Hardware","text":"<ul> <li>Local machine: MacBook Air, 8GB RAM, Apple Silicon (M1 chip).</li> <li>Online: Standard Colab CPU Environment (e.g., Intel Xeon, ~13 GB RAM). Google Colab free tier also provides variable access to GPU and TPU accelerators.</li> </ul>"},{"location":"master-plan/#022-software-and-cloud-services-primarily-google-ecosystem","title":"0.2.2. Software and Cloud Services (Primarily Google Ecosystem)","text":"<ul> <li>Google BigQuery: Central data warehouse for storing historical and current race data. Chosen for scalability, Colab integration, and cost-effectiveness within its free tier.</li> <li>Google Colab: Primary environment for data scraping, cleaning, analysis, feature engineering, visualization, and ML model development.</li> <li>Google Sheets: Used as an intermediary data hub, for manual input/correction if necessary, and potentially for controlling updates via Apps Script (original plan).</li> <li>Google Apps Script: Planned for automating data update processes (e.g., Sheets to BigQuery).</li> <li>Google Cloud Storage (GCS): Considered for intermediary data storage (e.g., Parquet files) to optimize data transfer between BigQuery and Colab.</li> <li>Python Libraries:<ul> <li>Data Acquisition: Beautiful Soup (or potentially Playwright/Selenium if dynamic content requires it).</li> <li>Data Manipulation &amp; Analysis: pandas, NumPy, Polars.</li> <li>Cloud Interaction: <code>google-cloud-bigquery</code>, <code>gspread</code>.</li> <li>Visualization: Plotly, Matplotlib, Seaborn.</li> <li>Machine Learning: Scikit-learn, TensorFlow, PyTorch, XGBoost, LightGBM (specific choices in modeling phase).</li> </ul> </li> <li>Version Control: Git, managed via a GitHub repository.</li> <li>Documentation: MkDocs with the Material theme.</li> </ul>"},{"location":"master-plan/#023-development-environment","title":"0.2.3. Development Environment","text":"<ul> <li>Google Colab: Primary for computationally intensive tasks (data processing, ML).</li> <li>Visual Studio Code (VS Code) - Local: For developing helper scripts, managing the project repository, and MkDocs site generation/preview.</li> </ul>"},{"location":"master-plan/#03-proposed-workflow-outline-original-hybrid-concept","title":"0.3. Proposed Workflow Outline (Original Hybrid Concept)","text":""},{"location":"master-plan/#031-rationale-for-hybrid-workflow-sheets-bigquery-colab","title":"0.3.1. Rationale for Hybrid Workflow (Sheets -&gt; BigQuery -&gt; Colab)","text":"<p>(This section reflects the original thinking from the Google Doc. The actual implementation might evolve and will be documented in phase reports.) The initially chosen workflow utilized a hybrid approach: Google Sheets (for easily editable data), BigQuery (External Tables linking to Sheets, then materializing into Native Tables for performance), and Google Colab for analysis and ML.</p> <ul> <li>Ease of Data Correction: Sheets as the primary editable source.</li> <li>Analytical Performance: Native BigQuery tables for querying.</li> <li>Scalability: BigQuery's inherent scalability.</li> <li>Resource Efficiency: Colab for computation.</li> <li>Integration &amp; Control: Google ecosystem synergy.</li> <li>Cost-Effectiveness: Leveraging free tiers.</li> </ul>"},{"location":"master-plan/#032-alternative-methodologies-considered-original-assessment","title":"0.3.2. Alternative Methodologies Considered (Original Assessment)","text":"<ul> <li>DuckDB (Local) + Colab: Rejected due to local RAM limits and less straightforward data correction than Sheets.</li> <li>Pandas/Polars (Local only): Rejected due to RAM limits and lack of persistence/scalability.</li> <li>SQLite (Local): Rejected due to performance for analytical queries and local resource limits.</li> <li>PostgreSQL (Local): Rejected due to overhead on local hardware.</li> <li>Snowflake (Cloud): Rejected due to lack of a comparable free tier to BigQuery.</li> </ul>"},{"location":"master-plan/#phase-1-data-collection-and-storage","title":"Phase 1: Data Collection and Storage","text":"<p>Objective: To acquire all relevant raw and processed historical data from 2008 onwards and establish a structured and robust initial storage solution in Google BigQuery. This phase focuses on ingesting previously processed data and setting up the capability to collect ongoing race data.</p>"},{"location":"master-plan/#11-data-sources","title":"1.1 Data Sources:","text":"<ul> <li> <p>Primary Historical Processed Data (2008 - March 2025):</p> <ul> <li>Source 1: User-provided Google Sheets from a 3rd party source. This data has undergone previous processing and error correction by the user.</li> <li>Content: Includes race results, race cards, race details, and horse register information.</li> <li> <p>Period: From 2008 (coinciding with GPS tracking implementation) up to November 2023.</p> </li> <li> <p>Source 2: User scraped data using a copy and paste method with the aid of app script for processing.</p> </li> <li>Content: Continuation of the 3rd party data.</li> <li>Period: From Dec 2023 to 19 March 2025.</li> </ul> </li> <li> <p>Primary Ongoing Raw Data (March 2025 onwards):</p> <ul> <li>Source: Hong Kong Jockey Club (HKJC) official website (<code>https://racing.hkjc.com/</code>).</li> <li>Content: Racecards (for upcoming races), race results (historical, post-race), horse details, trackwork records, stewards' reports, and any other relevant data available.</li> <li>Period: From March 2025 onwards.</li> </ul> </li> </ul>"},{"location":"master-plan/#12-historical-data-consideration-pre-2008","title":"1.2. Historical Data Consideration (Pre-2008):","text":"<ul> <li>Data prior to 2008, from the 3rd party source, while available in CSV format, has been deemed out of scope for this project.</li> <li>Rationale for Exclusion:<ul> <li>Significant data quality issues (error-prone, missing values for critical fields like win odds, horse weights, and HKJC ratings).</li> <li>Absence of sectional timings and less accurate overall finish times.</li> <li>Fundamental differences in track configurations (e.g., false rail positions) before the consistent GPS tracking system was implemented in 2008.</li> <li>Lack of advanced timing systems (e.g., precision to two decimal places for finish and sectional times).</li> </ul> </li> <li>Focusing on data from 2008 onwards ensures higher quality, consistency, and relevance to current racing conditions.</li> </ul>"},{"location":"master-plan/#13-data-acquisition-methodology","title":"1.3. Data Acquisition Methodology:","text":"<ul> <li>Processed Historical Data (Google Sheets):<ul> <li>Method: Python scripts utilizing libraries such as <code>gspread</code> and <code>pandas</code> to read data directly from the user's Google Sheets.</li> <li>Environment: Local Python environment or Google Colab.</li> <li>Note: While Google Sheets were the initial source for some data, the focus for acquiring bulk historical data (2008-2023), particularly for detailed race reports and \"Comments on Running,\" has shifted to processing CSV files.</li> </ul> </li> <li>Historical CSV Report Scraping (One-Off Task - 2008-2023):<ul> <li>Method: A one-time scraping effort was undertaken to extract detailed race reports and \"Comments on Running\" from historical CSV files covering the period 2008-2023. This was prioritized to secure a rich historical dataset (as per Week 3 decisions).</li> <li>Environment: Google Colab was utilized for this bulk scraping task to mitigate risks associated with IP address blocking during the large, one-off data extraction.</li> <li>Code Management: The Python scripts developed for this specific one-off historical CSV scraping task are intentionally excluded from the main project repository (<code>hk_racing_project</code>). This decision keeps the main repository focused on the ongoing, automated data collection pipeline and avoids cluttering it with code for a completed, non-recurring task (as per Week 3 decisions).</li> </ul> </li> <li>Ongoing Raw Data (HKJC Website):<ul> <li>Status Note: Collection of ongoing raw data from the HKJC website was temporarily paused (as per Week 3 decisions) to prioritize the acquisition of bulk historical reports data (2008-2023) from CSVs. Development of the automated scraping pipeline for new data will resume based on the refined strategy below.</li> <li>Primary Method: Web scraping using Python libraries (e.g., <code>requests</code>, <code>Beautiful Soup</code>, and potentially <code>Playwright</code> or <code>Selenium</code> if dynamic content rendering is a significant factor).</li> <li>Primary Trigger &amp; Orchestration: The <code>src/ingestion/race_calendar.py</code> script, which reads race meeting dates from a user-managed Google Sheet, has been redefined as the primary trigger for the scraping pipeline for new race meetings (as per Week 4 decisions). This script will orchestrate subsequent scraping tasks for racecards, results, etc., based on the fetched dates.</li> <li>Data Scope Expansion (Incident Reports): To enable a more comprehensive incident analysis for ongoing data collection, scraping will include \"Comments on Running\" reports in addition to \"Full Stewards' Reports\" (as per Week 4 decisions).</li> <li>Environment: Scripts will be developed locally or in Google Colab and designed for potential future deployment in an automated environment (e.g., Google Cloud Functions).</li> <li>API Limitations: The HKJC does not offer a public API, necessitating web scraping.</li> <li>Scope per Session: Scraping will be batched, likely per race day or specific data types (e.g., all results for a given day, all upcoming racecards), orchestrated by the race calendar.</li> <li>Maintenance: To ensure the scraping scripts continue to function correctly despite potential modifications to the HKJC website, they will need consistent oversight and upkeep. Health status updates for the scraping system will be generated and recorded in <code>phase-01-collection.md</code>.</li> </ul> </li> </ul>"},{"location":"master-plan/#14-preliminary-data-formatting-post-scraping-for-hkjc-data","title":"1.4. Preliminary Data Formatting (Post-Scraping - for HKJC Data):","text":"<ul> <li>Environment: Python scripts (local or Colab).</li> <li>Objective: For newly scraped data, perform initial transformations to ensure basic consistency before storage in the raw BigQuery dataset. This includes:<ul> <li>Data type enforcement (e.g., converting strings to numbers or dates where appropriate).</li> <li>Basic string manipulation (trimming whitespace, standardizing case for certain fields).</li> <li>Structural validation to ensure essential fields are present.</li> </ul> </li> <li>Rationale: Python scripts provide reproducibility, version control, and robust error handling for these initial formatting steps.</li> </ul>"},{"location":"master-plan/#15-data-storage-strategy","title":"1.5. Data Storage Strategy:","text":"<ul> <li>Primary Data Warehouse: Google BigQuery.</li> <li>BigQuery Datasets:<ul> <li><code>hk_racing_dataset</code> (Main Dataset):<ul> <li>Purpose: To store the processed historical data (2008 - March 2025) from Google Sheets. This dataset will also serve as the target for fully cleansed, integrated, and modeled analytical data in later phases.</li> <li>Schema: Tables (<code>results</code>, <code>racecard</code>, <code>race_details</code>, <code>horse_register</code>) will adhere to the structures defined by the user (see Appendix A: Data Dictionary).</li> </ul> </li> <li><code>hk_racing_scraped_raw</code> (Staging/Raw Dataset):<ul> <li>Purpose: To store the raw data collected from the HKJC website (December 2023 onwards) after preliminary formatting.</li> <li>Schema: Table structures in this dataset will initially mirror the scraped data structure closely. Data will be transformed and loaded into the main <code>hk_racing_dataset</code> during Phase 2 (Cleansing and Preprocessing).</li> </ul> </li> </ul> </li> <li>Data Ingestion Pipeline:<ul> <li>Sheets to BigQuery: Python scripts will read from Google Sheets and load data directly into the corresponding tables in <code>hk_racing_dataset</code>.</li> <li>HKJC Scrapes to BigQuery: Python scraping scripts will perform preliminary formatting and then load data directly into tables within <code>hk_racing_scraped_raw</code>. Temporary local file storage (e.g., JSON, CSV) or GCS may be used as an intermediate step during the scraping and loading process if beneficial for batching or error handling.</li> </ul> </li> <li>Configuration: GCP project ID, BigQuery dataset IDs, and other relevant parameters will be managed via <code>config/config.yaml</code> and accessed using <code>src/common/config_loader.py</code>.</li> <li>Update Frequency: New race data from HKJC will be collected and processed typically twice weekly, aligned with the HKJC racing calendar. Automation of this collection is a future goal (Phase 4).</li> </ul>"},{"location":"master-plan/#phase-2-data-cleansing-and-preprocessing","title":"Phase 2: Data Cleansing and Preprocessing","text":"<p>(This phase focuses on transforming raw collected data into a clean, consistent, and usable dataset.)</p>"},{"location":"master-plan/#21-overview-of-collected-data","title":"2.1. Overview of Collected Data","text":"<p>The dataset will encompass: *   Core Race &amp; Horse Data: As detailed in Appendix A (Data Dictionary), this includes race identification, horse performance metrics, betting information, jockey/trainer details, and pre-race horse information. *   Incident Report Data:     *   Historical (2008-2023 from CSVs): Comprehensive race reports, often including both stewards' observations and comments on running within single documents.     *   Ongoing (HKJC Website): More granular reports, typically separating \"Full Stewards' Reports\" (factual incident details) from \"Comments on Running\" (performance implications).     *   Challenge: A key task in this phase will be to address the structural differences between these historical and current report formats to enable consistent analysis (as per Week 4 decisions).</p>"},{"location":"master-plan/#22-cleansing-procedure","title":"2.2. Cleansing Procedure","text":"<ul> <li>Environment: Primarily Google Colab or local Python scripts, with results stored in BigQuery.</li> <li>Key Steps:<ul> <li>Data Type Enforcement: Ensure columns match predefined types (integer, float, string, date).</li> <li>String Manipulation: Trim whitespace, standardize capitalization, handle special characters.</li> <li>Categorical Value Standardization: Ensure consistency in fields like <code>COURSE</code>, <code>CLASS</code>, <code>GOING</code>. Map variations to standard values.</li> <li>Handling Specific Non-Numeric/Placeholder Strings: Address values like 'UNRATED', 'GRIFFIN', 'DEBUT' in fields that are otherwise numeric or categorical.</li> <li>Addressing Known Inconsistencies: Programmatic fixes for known issues in historical data.</li> <li>Incident Data Integration &amp; Harmonization:<ul> <li>Integrate \"Comments on Running\" with \"Full Stewards' Reports\" to create a more holistic view of in-race incidents and their consequences (as per Week 4 decisions).</li> <li>Attempt to harmonize the structure of incident data extracted from historical CSVs and ongoing HKJC website scrapes.</li> <li>Note on LLM-based Nuanced Extraction: The plan to use LLMs (Gemini Flash 2.5, OpenAI GPT-4o mini, Gemini 2.5 Pro Preview) for detailed interpretation and categorization of incidents from textual reports is currently paused. This is due to issues encountered during Week 4 testing, including model reliability (hallucinations), unexpected processing token consumption leading to high costs, and overall cost-prohibitive API pricing for bulk historical data. For now, simpler rule-based extraction methods will be employed for incident data, or this highly nuanced extraction task will be deferred until LLM solutions become more viable.</li> </ul> </li> </ul> </li> </ul>"},{"location":"master-plan/#23-data-validation-and-format-consistency","title":"2.3. Data Validation and Format Consistency","text":"<ul> <li>Objective: Rigorously validate data against the schema in Appendix A.</li> <li>Checks: Data type verification, value range checks, categorical value consistency, basic relational integrity checks (e.g., consistent IDs).</li> <li>Discrepancy Handling: Refine cleansing scripts or (as a last resort for historical data) document manual corrections.</li> </ul>"},{"location":"master-plan/#24-management-of-missing-valuesoutliers","title":"2.4. Management of Missing Values/Outliers","text":"<ul> <li>Approach: Strategies will be determined based on EDA findings (Phase 3) and model requirements.</li> <li>Missing Values: Options include deletion (rows/columns), mean/median/mode imputation, regression imputation, or model-based imputation.</li> <li>Outliers: Identification (e.g., IQR, Z-scores) followed by potential capping, transformation, or removal.</li> </ul>"},{"location":"master-plan/#25-data-transformation-preparation-for-modeling","title":"2.5. Data Transformation (Preparation for Modeling)","text":"<ul> <li>Encoding Categorical Variables: Convert string categories (e.g., <code>CLASS</code>, <code>GOING</code>) into numerical representations (One-Hot, Label, Target Encoding).</li> <li>Numerical Scaling: Apply standardization or normalization if required by specific models.</li> <li>Other Transformations: Log transforms, polynomial features, etc., based on EDA and model needs.</li> </ul>"},{"location":"master-plan/#phase-3-exploratory-data-analysis-eda","title":"Phase 3: Exploratory Data Analysis (EDA)","text":"<p>(This phase focuses on understanding the data through querying, statistics, and visualizations to uncover patterns and formulate hypotheses.)</p>"},{"location":"master-plan/#31-data-querying","title":"3.1. Data Querying","text":"<ul> <li>Source: Cleansed data tables in Google BigQuery.</li> <li>Environment: Google Colab using the <code>google-cloud-bigquery</code> Python library.</li> <li>Process: Construct SQL queries in Colab, execute against BigQuery, load results into Pandas/Polars DataFrames for analysis.</li> </ul>"},{"location":"master-plan/#32-descriptive-statistics","title":"3.2. Descriptive Statistics","text":"<ul> <li>Tools: Python libraries (Pandas, NumPy) in Colab.</li> <li>Numerical Variables: Calculate count, mean, median, std dev, min, max, percentiles, skewness, kurtosis.</li> <li>Categorical Variables: Frequency counts, unique values, mode.</li> </ul>"},{"location":"master-plan/#33-visualization","title":"3.3. Visualization","text":"<ul> <li>Primary Tool: Plotly for interactive plots in Colab. Seaborn and Matplotlib as alternatives.</li> <li>Univariate Analysis: Histograms, density plots, box plots, bar charts.</li> <li>Bivariate/Multivariate Analysis: Scatter plots, correlation heatmaps, grouped plots, time series plots (if applicable).</li> </ul>"},{"location":"master-plan/#34-initial-observations-and-hypothesis-formulation","title":"3.4. Initial Observations and Hypothesis Formulation","text":"<ul> <li>Synthesize findings from statistics and visualizations.</li> <li>Identify significant patterns, trends, anomalies, and correlations.</li> <li>Formulate initial hypotheses about factors influencing race outcomes.</li> <li>Identify areas needing further investigation. These insights will guide Feature Engineering (Phase 4).</li> </ul>"},{"location":"master-plan/#phase-4-feature-engineering","title":"Phase 4: Feature Engineering","text":"<p>(This phase focuses on creating new, potentially more predictive variables from the cleaned dataset.)</p>"},{"location":"master-plan/#41-methodology","title":"4.1. Methodology","text":"<ul> <li>Environment: Google Colab using Pandas, NumPy, Polars, and Scikit-learn.</li> <li>Approach: Iterative process based on domain knowledge, EDA insights, and preliminary model testing.</li> <li>Goal: Transform base data into a richer feature set that captures complex racing dynamics.</li> </ul>"},{"location":"master-plan/#42-initial-feature-set","title":"4.2. Initial Feature Set","text":"<ul> <li>The starting point is the cleansed, validated dataset (approx. 40-50 core variables as per Appendix A).</li> </ul>"},{"location":"master-plan/#43-target-feature-set","title":"4.3. Target Feature Set","text":"<ul> <li>Strategically expand the initial set. The focus is on developing hypothesized predictive features and validating their impact, rather than a fixed target number of features.</li> </ul>"},{"location":"master-plan/#44-example-categories-of-engineered-features","title":"4.4. Example Categories of Engineered Features","text":"<ul> <li>Form &amp; Consistency: Rolling win/place percentages, average finishing position (recent races), days since last win.</li> <li>Speed &amp; Pace: Calculated speed figures, sectional speed ratings, comparisons to class/distance/track averages.</li> <li>Jockey/Trainer Statistics: Win/place rates (overall, by course, distance, class, horse combination), recent form.</li> <li>Odds-Based Features: Odds movement (if available), probability derived from odds, value indicators (odds vs. finish).</li> <li>Class &amp; Weight Related: Rating relative to class, weight carried relative to past or standard weights.</li> <li>Interaction &amp; Derived Features: Jockey win rate on this course, horse average speed at this distance.</li> <li>Lagged Variables: Performance metrics from the previous race.</li> <li>LLM-Derived Incident Features: Utilize the Gemini 2.5 Pro Preview API to summarize, interpret, and categorize incidents from textual data in \"Full Stewards' Reports\" and \"Comments on Running.\" This process aims to generate nuanced features reflecting the nature, severity, and potential impact of in-race events. (Note: Application to bulk historical data is contingent on cost-effectiveness, as explored in <code>decisions.md</code> Week 4.).</li> </ul>"},{"location":"master-plan/#45-feature-engineering-approach","title":"4.5. Feature Engineering Approach","text":"<ul> <li>Iterative: Develop, test (correlation, feature importance from simple models, backtesting), refine/discard.</li> <li>New ideas may emerge during modeling and evaluation.</li> </ul>"},{"location":"master-plan/#46-roles-of-bigquery-and-colab","title":"4.6. Roles of BigQuery and Colab","text":"<ul> <li>BigQuery: Source for cleaned base data. Potentially store validated engineered features in new tables/views for efficient reuse.</li> <li>Colab: Primary environment for implementing complex feature calculation logic.</li> </ul>"},{"location":"master-plan/#phase-5-model-development-and-training","title":"Phase 5: Model Development and Training","text":"<p>(This phase involves selecting, training, and optimizing machine learning models to predict race outcomes.)</p>"},{"location":"master-plan/#51-model-selection","title":"5.1. Model Selection","text":"<ul> <li>Target Variable(s): To be clearly defined (e.g., predict win probability, predict top N finish, predict expected ROI).</li> <li>Baseline Models: Start with simpler, interpretable models (Logistic Regression, Linear Regression, Decision Trees, Random Forests).</li> <li>Advanced Models: Explore Gradient Boosting Machines (XGBoost, LightGBM, CatBoost), Neural Networks (MLPs, potentially RNNs/LSTMs if sequential data like sectional times are heavily used).</li> <li>Selection Criteria: Predictive performance (via backtesting), interpretability, computational cost, training time.</li> </ul>"},{"location":"master-plan/#52-training-environment","title":"5.2. Training Environment","text":"<ul> <li>Primary: Google Colab, leveraging free-tier GPU/TPU accelerators for computationally intensive models.</li> </ul>"},{"location":"master-plan/#53-validation-approach","title":"5.3. Validation Approach","text":"<ul> <li>Primary Method: Rigorous Backtesting.<ul> <li>Simulate training on historical data up to a point and evaluating on subsequent unseen historical data.</li> <li>Employ time-series aware validation (e.g., walk-forward validation) to prevent data leakage.</li> </ul> </li> </ul>"},{"location":"master-plan/#54-hyperparameter-optimization","title":"5.4. Hyperparameter Optimization","text":"<ul> <li>For promising models, optimize hyperparameters to maximize performance on validation sets.</li> <li>Techniques: Grid Search, Randomized Search, Bayesian Optimization (using libraries like Optuna or Scikit-learn tools).</li> </ul>"},{"location":"master-plan/#phase-6-model-evaluation-and-validation","title":"Phase 6: Model Evaluation and Validation","text":"<p>(This phase focuses on rigorously evaluating model performance, especially in the context of wagering profitability.)</p>"},{"location":"master-plan/#61-performance-metrics","title":"6.1. Performance Metrics","text":"<ul> <li>Primary Focus (Wagering Profitability):<ul> <li>Return on Investment (ROI).</li> <li>Hit Rate (Win Prediction Accuracy, Place Prediction Accuracy).</li> </ul> </li> <li>Standard ML Metrics (Task-Dependent):<ul> <li>Classification: Accuracy, Precision, Recall, F1-score, Log Loss, AUC-ROC, AUC-PR.</li> <li>Regression (if predicting rank/time): MAE, RMSE.</li> </ul> </li> </ul>"},{"location":"master-plan/#62-backtesting-outcomes","title":"6.2. Backtesting Outcomes","text":"<ul> <li>Present detailed quantitative results from backtesting simulations.</li> <li>Compare different models and hyperparameter configurations across historical validation periods.</li> </ul>"},{"location":"master-plan/#63-wagering-strategy-simulation","title":"6.3. Wagering Strategy Simulation","text":"<ul> <li>Simulate model use within defined wagering strategies during backtesting.</li> <li>Examples: Fixed Stakes, Percentage Stakes (e.g., fixed percentage of bankroll), Kelly Criterion (adjusting bet size based on perceived edge and odds).</li> <li>Simulation must account for historical odds and race results.</li> </ul>"},{"location":"master-plan/#64-profitability-analysis","title":"6.4. Profitability Analysis","text":"<ul> <li>In-depth analysis of simulated financial performance (total profit/loss, ROI, drawdown, risk-adjusted returns).</li> <li>Assess feasibility of achieving the project's primary objective (positive ROI).</li> </ul>"},{"location":"master-plan/#65-iterative-refinement","title":"6.5. Iterative Refinement","text":"<ul> <li>Evaluation results drive improvements:<ul> <li>Revisit Feature Engineering (Phase 4).</li> <li>Revisit Model Selection (Phase 5.1).</li> <li>Revisit Hyperparameter Optimization (Phase 5.4).</li> <li>Analyze errors to understand model strengths/weaknesses.</li> </ul> </li> </ul>"},{"location":"master-plan/#phase-7-deployment-and-monitoring-future-phase","title":"Phase 7: Deployment and Monitoring (Future Phase)","text":"<p>(This phase outlines operationalizing the model and monitoring its ongoing performance.)</p>"},{"location":"master-plan/#71-prediction-generation-workflow","title":"7.1. Prediction Generation Workflow","text":"<ul> <li>End-to-end process for generating predictions/insights for upcoming race days:<ul> <li>Acquire new racecard data.</li> <li>Apply preprocessing and feature engineering steps consistently.</li> <li>Load trained model.</li> <li>Generate predictions.</li> <li>Store/present predictions for decision-making.</li> </ul> </li> <li>Define automation level and tools.</li> </ul>"},{"location":"master-plan/#72-performance-monitoring","title":"7.2. Performance Monitoring","text":"<ul> <li>Track real-world effectiveness and profitability:<ul> <li>Collect actual race results.</li> <li>Compare outcomes against predictions.</li> <li>Track ROI based on simulated/actual wagers.</li> <li>Monitor for model drift or changes in data distributions.</li> </ul> </li> <li>Define metrics, frequency, and tools.</li> </ul>"},{"location":"master-plan/#73-retraining-approach","title":"7.3. Retraining Approach","text":"<ul> <li>Strategy for periodic model retraining:<ul> <li>Triggers: Performance degradation, fixed schedule, or significant new data accumulation.</li> <li>Process: Reuse pipelines from Phases 2-6 with updated data.</li> <li>Validation: Retrained models validated via backtesting before deployment.</li> </ul> </li> </ul>"},{"location":"master-plan/#phase-8-project-management-and-continuous-improvement","title":"Phase 8: Project Management and Continuous Improvement","text":"<p>(This section covers ongoing project aspects, learnings, and future considerations.)</p>"},{"location":"master-plan/#81-potential-challenges-and-resolutions-ongoing-log","title":"8.1. Potential Challenges and Resolutions (Ongoing Log)","text":"<p>(This list will be dynamic and updated in phase reports or a dedicated decisions/risks log as they arise.) * Cloud Costs (BigQuery/GCP): Monitor usage, optimize queries, leverage free tiers. * Feature Engineering Complexity: Iterative approach, start simple, leverage domain knowledge and EDA. * Model Validation &amp; Profitability: Rigorous backtesting, realistic wagering simulation. * Data Pipeline Robustness: Error handling, logging, monitoring. * Data Integrity &amp; Correction: Ongoing validation checks, clear process for corrections. * Web Scraping Maintenance: Monitor for HKJC site changes, allocate time for script updates.</p>"},{"location":"master-plan/#82-data-size-projections-and-growth","title":"8.2. Data Size Projections and Growth","text":"<ul> <li>Initial dataset (18 years, ~171k rows, 40-50 cols): ~20-50 MB.</li> <li>With engineered features (~150-200 cols): ~50-100 MB.</li> <li>Long-term growth (next 15-20 years): Potentially doubling to ~200-400 MB.</li> <li>These volumes are manageable within BigQuery free tiers and Colab.</li> </ul>"},{"location":"master-plan/#83-tools-summary","title":"8.3. Tools Summary","text":"<ul> <li>Data Storage &amp; Querying: Google BigQuery.</li> <li>Data Processing &amp; Modeling: Python in Google Colab (Pandas, Scikit-learn, etc.).</li> <li>Web Scraping: Python (Beautiful Soup / Playwright).</li> <li>Version Control: Git / GitHub.</li> <li>Documentation: MkDocs (Material theme).</li> <li>Project Management / Task Tracking: <code>docs/project-status.md</code>.</li> <li>(Original) Intermediary Data/Control: Google Sheets, Google Apps Script (may be revised).</li> </ul>"},{"location":"master-plan/#84-future-considerations","title":"8.4. Future Considerations","text":"<ul> <li>Advanced Deployment: If successful, explore more sophisticated deployment (e.g., dedicated prediction server, API).</li> <li>Alternative Data Sources: If HKJC scraping becomes untenable (unlikely to be better external sources).</li> <li>Deeper Model Exploration: More complex architectures if justified by performance.</li> </ul>"},{"location":"master-plan/#85-version-control-strategy","title":"8.5. Version Control Strategy","text":"<ul> <li>All project code, documentation, and configuration files will be version controlled using Git, hosted on a GitHub repository.</li> <li>Branches will be used for feature development and experimentation (e.g., <code>feature/new-scraper</code>, <code>experiment/new-model-arch</code>).</li> <li>The <code>main</code> branch will represent the stable, working version of the project.</li> <li>Commits should be descriptive and atomic.</li> </ul>"},{"location":"master-plan/#86-references","title":"8.6. References","text":"<p>(Placeholder for links to key documentation, research papers, articles, etc., consulted during the project.)</p> <ul> <li>HKJC Website: <code>[Link to be added]</code></li> <li>Pandas Documentation: <code>https://pandas.pydata.org/pandas-docs/stable/</code></li> <li>Scikit-learn Documentation: <code>https://scikit-learn.org/stable/</code></li> <li>MkDocs Material Theme: <code>https://squidfunk.github.io/mkdocs-material/</code></li> </ul> <p>Appendix A: Phase 1 Data Dictionary</p> <p>The following tables are from the <code>hk_racing_dataset</code></p>"},{"location":"master-plan/#a1-hk_racing_datasetrace_details","title":"A.1. <code>hk_racing_dataset.race_details</code>","text":"Column Name Data Type Description Notes / Example RACE_ID INTEGER Primary key. Unique identifier for each race, combining date and seasonal sequence. e.g. <code>20240414581</code> (YYYYMMDD + <code>581</code>) DATE DATE Calendar date when the race was held. <code>2024-04-14</code> VENUE STRING Name of the racecourse. <code>Sha Tin</code>, <code>Happy Valley</code> SURFACE STRING Track surface type. <code>Turf</code> or <code>AWT</code> (all-weather track) RACE_NUM_SEASON INTEGER Sequence number of this race in the current season (3-digit). <code>581</code> CLASS STRING Classification of the race by quality/conditions. <code>Class 1</code>, <code>Group 1</code>, <code>Griffin</code> DISTANCE INTEGER Race distance in metres. <code>1200</code>, <code>1650</code> RANKING STRING Official rating bracket for eligibility (upper-lower). <code>85-60</code>, <code>100-85</code> GOING STRING Turf going description, or condition of AWT. <code>GOOD</code>, <code>YIELDING (WET SLOW)</code>, <code>AWT</code> RACE_DESCRIPTION STRING Official race title. <code>THE HONG KONG EXCHANGES CHALLENGE CUP</code> TRACK_CONFIG STRING Course layout variant (e.g., inside rail offsets). <code>A</code>, <code>C+2</code>, <code>AWT</code> PRIZE INTEGER Total purse awarded (in HKD). <code>1200000</code> PEN_READING FLOAT Penetrometer reading for turf (strength) or Clegg hammer reading for AWT. <code>2.72</code> (turf), <code>8.4</code> (AWT)"},{"location":"master-plan/#a2-hk_racing_datasetrace_card","title":"A.2. <code>hk_racing_dataset.race_card</code>","text":"Column Name Data Type Description Notes / Example RUNNER_ID STRING Primary key. Uniquely identifies a horse in a specific race. <code>20240414581*CLEARWIN*H255</code> RACE_ID INTEGER Foreign key \u2192 <code>race_details.RACE_ID</code>. <code>20240414581</code> HORSE_ID STRING Foreign key \u2192 <code>horse_register.HORSE_ID</code>. <code>CLEARWIN*H255</code> WEIGHT INTEGER Total impost carried (jockey + equipment), in pounds. <code>126</code> HORSE_WEIGHT INTEGER Declared bodyweight of the horse (taken pre-race), in pounds. <code>1180</code> DRAW INTEGER Barrier (gate) number at start. <code>1</code> (inside rail) JOCKEY STRING Name of the jockey riding this runner. <code>Z Purton</code> TRAINER STRING Name of the trainer responsible for this runner. <code>D J Whyte</code> RATING INTEGER Official HKJC rating at time of race. <code>112</code> DEBUT_BOOL BOOLEAN Indicates if this was the horse\u2019s first-ever start in Hong Kong. <code>TRUE</code>, <code>FALSE</code> REST_DAYS INTEGER Days elapsed since the horse\u2019s previous run. <code>21</code> RACE_AGE INTEGER Age of the horse on race day, in years. <code>6</code> GEAR STRING Codes for equipment fitted (see Gear Key below). <code>PC/XB/TT</code>, <code>E</code>, <code>H1</code> <p>Gear Key (HKJC standard abbreviations):</p> Code Meaning Notes B Blinkers BO Blinker (one cowl) CC Cornell Collar CP Sheepskin Cheek Pieces CO Sheepskin (one side) E Ear Plugs H Hood P Pacifier PC Pacifier + cowls PS Pacifier (one cowl) SB Sheepskin Browband SR Shadow Roll TT Tongue Tie V Visor VO Visor (one cowl) XB Crossed Nose Band *1 First time use of that gear Suffix, e.g. <code>H1</code> *2 Gear replaced Suffix, e.g. <code>B2</code> -* Gear removed Suffix, e.g. <code>CC-</code>"},{"location":"master-plan/#a3-hk_racing_datasetrace_results","title":"A.3. <code>hk_racing_dataset.race_results</code>","text":"Column Name Data Type Description Notes / Example RUNNER_ID STRING Foreign key \u2192 <code>race_card.RUNNER_ID</code>. Matches each runner to its card entry. <code>20240414581*CLEARWIN*H255</code> RACE_ID INTEGER Foreign key \u2192 <code>race_details.RACE_ID</code>. <code>20240414581</code> HORSE_ID STRING Foreign key \u2192 <code>horse_register.HORSE_ID</code>. <code>CLEARWIN*H255</code> FINISH_POS INTEGER Official finishing position. Codes \u226590 may indicate non-finishers (e.g. DNS, UR). <code>1</code>, <code>2</code>, <code>DNF</code> STARTING_ODDS FLOAT Decimal odds at race start. <code>1.8</code>, <code>10.5</code> PLACE_PAYOUTS FLOAT Dividend payout for a successful \u201cplace\u201d bet. <code>0</code> or <code>NULL</code> if unplaced or no payout available. <code>2.5</code>, <code>NULL</code> FINISH_TIME FLOAT Winner\u2019s official finishing time in seconds. <code>71.52</code> SEC_TIME_1 FLOAT Sectional time for first segment (varies by course layout). <code>22.15</code> SEC_TIME_2 FLOAT Sectional time for second segment. <code>23.00</code> SEC_TIME_3 FLOAT Sectional time for third segment. <code>26.37</code> SEC_TIME_4 FLOAT Sectional time for fourth segment (if applicable). \u2014 SEC_TIME_5 FLOAT Sectional time for fifth segment (if race &gt;1,600 m). \u2014 SEC_TIME_6 FLOAT Sectional time for sixth segment (if race &gt;2,200 m). \u2014"},{"location":"master-plan/#a4-hk_racing_datasethorse_register","title":"A.4. <code>hk_racing_dataset.horse_register</code>","text":"Column Name Data Type Description Notes / Example HORSE_ID STRING Primary key. Stable identifier for each horse across all races. <code>DEANSANGEL*D123</code> HORSE_CODE STRING Unique alphanumeric code assigned by HKJC (distinguishes duplicates). <code>D466</code>, <code>H255</code> HORSE_NAME STRING Official registered name of the horse. <code>DEAN\u2019S ANGEL</code> SEX STRING Gender classification. <code>MALE</code>,<code>FEMALE</code> COLOR STRING Coat colour. <code>Bay</code>, <code>Chestnut</code> COUNTRY_OF_ORIGIN STRING Country where the horse was foaled (ISO 3-letter code). <code>AUS</code>, <code>NZ</code>, <code>IRE</code> IMPORT_TYPE STRING Means by which horse entered HK racing. <code>PP</code>, <code>PPG</code>, <code>ISG</code>, <code>VIS</code> SIRE STRING Registered name of the horse\u2019s father. <code>ALL TOO HARD</code> DAM STRING Registered name of the horse\u2019s mother. <code>ANGEL IN MY HEART</code> DAM_SIRE STRING Registered sire of the dam (maternal grandsire). <code>SEBRING</code> OWNER STRING Name(s) of the owner(s) as recorded by HKJC. <code>Mr &amp; Mrs John Smith</code> <p>Key relationship summary:</p> <ul> <li><code>race_details.RACE_ID</code> \u2192 parent of both <code>race_card</code> and <code>race_results</code>.</li> <li><code>race_card.RUNNER_ID</code> \u2192 referenced by <code>race_results.RUNNER_ID</code>.</li> <li><code>horse_register.HORSE_ID</code> \u2192 parent of both <code>race_card.HORSE_ID</code> and <code>race_results.HORSE_ID</code>.</li> </ul> <p>Import Type Key:</p> <ul> <li><code>PP</code>: Privately Purchased Horses (previously raced elsewhere).</li> <li><code>PPG</code>: Privately Purchased Griffins (unraced young horses).</li> <li><code>ISG</code>: International Sale Griffins (unraced horses from approved sales).</li> <li><code>VIS</code>: Visiting Invitational Horses (invited for specific major races).</li> </ul>"},{"location":"phase-01-collection/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-02-cleansing/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-03-eda/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-04-features/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-05-model/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-06-evaluation/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-07-deployment/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"phase-08-management/","title":"NO REPORT OR FINDINGS GENERATED","text":""},{"location":"project-accomplishments/","title":"Accomplishments","text":""},{"location":"project-accomplishments/#genaral-project-setup-accomplishments","title":"Genaral Project Setup Accomplishments","text":"<ul> <li> <p>\u2705 M0.1: Project Repository and Core Structure Established:</p> <ul> <li>GitHub repository (<code>hk_racing_project</code>) initialized and configured.</li> <li>Standardized project directory structure (<code>src</code>, <code>docs</code>, <code>data</code>, <code>tests</code>, <code>notebooks</code>, <code>scripts</code>, <code>config</code>) implemented, promoting clear separation of concerns.</li> <li>Comprehensive <code>.gitignore</code> file established to manage version control hygiene.</li> </ul> </li> <li> <p>\u2705 M0.2: Master Plan Document (<code>master-plan.md</code>) Finalized:</p> <ul> <li>The \"0. Project Definition and Establishment\" section of <code>master-plan.md</code> has been thoroughly reviewed, refined, and finalized.</li> <li>Key decisions regarding project workflow, toolset (VS Code, Colab), data handling strategies (direct BQ ingestion, GCS for models), and configuration management have been documented.</li> <li>The <code>master-plan.md</code> now serves as a robust foundational document for the project.</li> </ul> </li> <li> <p>\u2705 M0.3: Documentation Site (MkDocs) Configured and Operational:</p> <ul> <li>MkDocs and the Material theme successfully installed and configured.</li> <li><code>mkdocs.yml</code> created, defining site navigation, theme settings, and linking to the project repository.</li> <li>The documentation site is buildable locally, providing a clear and accessible way to view project documentation.</li> <li>(Optional, if done) GitHub Pages deployment for the documentation site is operational.</li> </ul> </li> <li> <p>\u2705 M0.4: Standard Project Documentation Shells Created:</p> <ul> <li>Shell markdown files for all project phases (Phase 1 through Phase 8), <code>decisions.md</code>, and <code>project-status.md</code> have been created within the <code>docs/</code> directory.</li> <li>The structure for <code>project-status.md</code> has been defined and implemented, enabling effective manual progress tracking.</li> <li>This establishes a complete framework for ongoing project documentation.</li> </ul> </li> <li> <p>\u2705  M0.5: Development Environment and Tooling Configured:</p> <ul> <li>Local Python virtual environment (<code>.venv</code>) established.</li> <li>Core Python libraries (e.g., <code>pandas</code>, <code>requests</code>, <code>google-cloud-*</code>) installed via <code>requirements.txt</code>.</li> <li>Development libraries (e.g., <code>pytest</code>, <code>mkdocs</code>, <code>black</code>, <code>flake8</code>) installed via <code>requirements-dev.txt</code>.</li> <li>Visual Studio Code configured for Python development, including interpreter selection, linting (Flake8), and formatting (Black).</li> <li>Confirmed access to Google Colab and successful connection to Google Cloud Platform (GCP) services from Colab environment.</li> </ul> </li> <li> <p>\u2705 M0.6: Cloud Services (GCP) Initial Setup and Access Confirmed: Accomplishments:</p> <ul> <li>Google Cloud Platform (GCP) project established.</li> <li>Necessary APIs (BigQuery, Cloud Storage, IAM) enabled in the GCP console.</li> <li>A GCP Service Account created with appropriate roles (e.g., BigQuery Data Editor, Storage Object Admin) for data access.</li> <li>Service account JSON key downloaded, stored securely, and the <code>GOOGLE_APPLICATION_CREDENTIALS</code> environment variable configured for programmatic access.</li> </ul> </li> <li> <p>\u2705 M0.7: Configuration Management Strategy Implemented: Accomplishments:</p> <ul> <li><code>config/</code> directory established at the project root for centralized configuration management.</li> <li>An example configuration file, <code>config/config.yaml.example</code>, created, outlining the structure for data sources, GCP project ID, and BigQuery details.</li> <li>A local <code>config/config.yaml</code> file (copied from the example) created for actual project configurations.</li> <li><code>config/config.yaml</code> added to <code>.gitignore</code> to prevent accidental versioning of sensitive or environment-specific settings.</li> <li>A basic Python utility, <code>src/common/config_loader.py</code>, developed to load configurations from <code>config.yaml</code>.</li> </ul> </li> </ul>"},{"location":"project-accomplishments/#phase-1-accomplishments","title":"Phase 1 Accomplishments","text":"<ul> <li> <p>\u2705 M1.1: BigQuery Environment Setup &amp; Configuration</p> <ul> <li>The <code>hk_racing_dataset</code> and <code>hk_racing_scraped_raw</code> BigQuery datasets are created in the designated GCP project.</li> <li><code>config/config.yaml</code> updated to include <code>bq_main_dataset_id: \"hk_racing_dataset\"</code> and <code>bq_scraped_raw_dataset_id: \"hk_racing_scraped_raw\"</code>.</li> <li><code>src/common/config_loader.py</code> verified to correctly load these dataset IDs.</li> <li>Purpose and intended content of each BigQuery dataset documented in <code>docs/phase-01-collection.md</code> (or equivalent documentation).</li> </ul> </li> <li> <p>\u2705 M1.2: Ingestion of Processed Historical Data (Google Sheets to BigQuery)</p> <ul> <li>Table schemas in <code>hk_racing_dataset</code> (for <code>results</code>, <code>racecard</code>, <code>race_details</code>, <code>horse_register</code>) are defined and documented in Appendix A of <code>master-plan.md</code>, and corresponding tables are understood to be created in BigQuery.</li> <li>The full dataset is correctly uploaded to BigQuery with the defined schemas found in Appendix A.</li> <li>Validate data integrity post-ingestion</li> </ul> </li> </ul>"},{"location":"project-status/","title":"Project Status","text":"<p>Last Manually Updated: 2025-05-30</p> <p>Overall Project Health: YELLOW (behind schedule)</p> <p>Current Phase: Phase 1: Data Collection and Storage</p> <p>BQ Setup is completed and data is loaded. Main pipeline scraping was halted to scrape historical race reports in colab (see week 4 decsions)</p> <p>Key Focus for This Week (ending 2005-05-17):</p> <p>(put on pause) M1.3: Development of HKJC Web Scraping Capability: Develop Python scripts to scrape required data types (racecards, results, horse details, etc.) from the HKJC website for data from 19 March 2025 onwards.</p> <p>the racing calander is to be scraped first as its the starting point of the scraping pipeline.</p>"},{"location":"project-status/#0-general-project-setup","title":"0. General Project Setup","text":"<p>Overall Phase Objective: Complete to overall project infrastructure, documentation, planning, and core technical setup before specific data work begins</p> <p>current status: complete</p>"},{"location":"project-status/#genaral-project-setup-milestones","title":"Genaral Project Setup Milestones","text":"<ul> <li>\u2705M0.1: Project Repository and Core Structure Established: Ensure the GitHub repository is correctly set up with a logical folder structure for code, docs, data, etc.</li> <li>\u2705 M0.2: Master Plan Document (<code>master-plan.md</code>) Finalized: Complete and finalize the comprehensive General Project Setup plan in <code>master-plan.md</code> incorporating all decisions from the initial planning phase.</li> <li>\u2705 M0.3: Documentation Site (MkDocs) Configured and Operational: Set up MkDocs with the chosen theme, configure navigation in <code>mkdocs.yml</code>, and ensure the site builds and deploys correctly (e.g., to GitHub Pages).</li> <li>\u2705 M0.4: Standard Project Documentation Shells Created: Create placeholder markdown files for all planned phases (e.g., <code>phase-01-collection.md</code>, <code>phase-02-cleansing.md</code>, etc.), a <code>decisions.md</code> log, and any other key supporting documentation. Finalize <code>docs/project-status.md</code> structure (current working version).</li> <li>\u2705  M0.5: Development Environment and Tooling Configured: Set up local (VS Code) and cloud (Google Colab) development environments, including Python, necessary libraries, and IDE configurations.</li> <li>\u2705 M0.6: Cloud Services (GCP) Initial Setup and Access Confirmed: Set up the Google Cloud Project, enable necessary APIs (BigQuery, Cloud Storage, IAM), and confirm programmatic access (e.g., service account credentials).</li> <li>\u2705 M0.7: Configuration Management Strategy Implemented: Establish the <code>config/</code> directory structure with example configuration files and ensure sensitive configurations are correctly handled (e.g., via <code>.gitignore</code>).</li> </ul>"},{"location":"project-status/#ongoing-task-and-issues","title":"Ongoing Task and Issues","text":"Status Task / Issue Description Milestone Notes / Resolution Priority Date Due Tags \u2705 No current tasks or issues All completed"},{"location":"project-status/#phase-1-data-collection-and-storage","title":"Phase 1: Data Collection and Storage","text":"<p>Overall Phase Objective: To acquire all relevant raw and processed historical data from 2008 onwards and establish a structured and robust initial storage solution in Google BigQuery. This involves ingesting previously processed data (2008-Nov 2023 from Google Sheets) and developing the capability to collect ongoing race data (Dec 2023 onwards from HKJC website).</p> <p>Current Status: In Progress</p>"},{"location":"project-status/#phase-1-milestones","title":"Phase 1 Milestones","text":"<ul> <li>\u2705 M1.1: BigQuery Environment Setup &amp; Configuration: Ensure BigQuery datasets are created and project configuration is updated.</li> <li>\u2705 M1.2: Ingestion of Processed Historical Data (Google Sheets to BigQuery): Transfer the user's existing processed and error-corrected data (2008 - November 2023)+ and the user scraped data (Decimeber 2023 - 19 March 2025) from Google Sheets into the <code>hk_racing_dataset</code> in BigQuery, matching schemas defined in Appendix A of <code>master-plan.md</code>.</li> <li>M1.3: Development of HKJC Web Scraping Capability: Develop Python scripts to scrape required data types (racecards, results, horse details, etc.) from the HKJC website for data from 19 March 2025 onwards.<ul> <li>M1.3.1: Scrape \"Comments on Running\" for Historical Data (via Colab): As per Week 4 decision, prioritize and execute the scraping of \"Comments on Running\" from historical reports using Google Colab. This is distinct from the ongoing HKJC website scraping for current data.</li> </ul> </li> <li>M1.4: Initial Ingestion of Scraped HKJC Data into BigQuery: Load an initial batch of scraped HKJC data (e.g., December 2023 - current date) into the <code>hk_racing_scraped_raw</code> BigQuery dataset.</li> <li>M1.5: Phase 1 Documentation and Review: Ensure all Phase 1 activities, designs, and processes are documented and reviewed.</li> </ul>"},{"location":"project-status/#phase-1-tasksissues","title":"Phase 1 Tasks/Issues","text":"ID Description Milestone Priority Status Due Date Notes M1.3 Development of HKJC Web Scraping Capability P1.3.1.1 Develop and execute script in Google Colab to scrape \"Comments on Running\" from historical reports (as per Week 3 &amp; 4 decisions regarding historical data focus). M1.3.1 High Open This is a one-off task for historical data, separate from ongoing HKJC scraping. P1.3.2 Identify specific HKJC website URLs and page structures for each required data type (race results, race cards, horse details). M1.3 High Open Investigate if Playwright/Selenium is needed or if <code>requests</code>/<code>BeautifulSoup</code> is sufficient. P1.3.3 Develop initial scraping script for one data type (e.g., Race Results). M1.3 High Open Handle pagination, navigation. Define preliminary data formatting. Structure output for <code>hk_racing_scraped_raw</code>. P1.3.4 Develop scraping scripts for remaining data types (Race Cards, Horse Details). M1.3 High Open P1.3.5 Implement robust error handling, logging, and mechanisms to manage scraping responsibly (e.g., delays, user-agent). M1.3 High Open P1.3.6 Integrate <code>src/ingestion/race_calendar.py</code> to guide the scraping of race-specific data based on meeting dates. M1.3 Medium Open P1.3.7 Store scraping scripts in <code>src/ingestion/</code>. M1.3 Low Open Code organization. P1.3.8 Document scraper design, dependencies, and usage in <code>docs/phase-01-collection.md</code>. M1.3 Medium Open P1.3.9 Refactor <code>src/ingestion/race_calendar.py</code> to serve as the primary trigger for the scraping pipeline, initiating subsequent scraping tasks based on fetched meeting dates. M1.3 High Open Aligns with Week 4 decision on pipeline orchestration. M1.4 Initial Ingestion of Scraped HKJC Data into BigQuery P1.4.1 Define table schemas for the <code>hk_racing_scraped_raw</code> dataset. M1.4 High Open These should initially be flexible to accommodate the raw scraped data structure. P1.4.2 Develop/finalize Python scripts (<code>src/ingestion/load_scraped_data.py</code>) to load formatted scraped data into <code>hk_racing_scraped_raw</code>. M1.4 High Open From intermediate JSON/CSV files or directly from scraper output. P1.4.3 Perform an initial batch load of scraped data (Dec 2023 - present) into BigQuery. M1.4 High Open P1.4.4 Validate data integrity post-ingestion (Scraped data). M1.4 Medium Open P1.4.5 Document scraped data loading process in <code>docs/phase-01-collection.md</code>. M1.4 Medium Open M1.5 Phase 1 Documentation and Review P1.5.1 Ensure <code>docs/master-plan.md</code> accurately reflects all Phase 1 decisions and scope. M1.5 Medium Open Confirm Appendix A is complete and accurate. P1.5.2 Complete all documentation tasks mentioned in previous milestones (within <code>docs/phase-01-collection.md</code> or other relevant documents). M1.5 Medium Open Consolidate documentation for ingestion scripts, scraper design etc. P1.5.3 Update <code>project-status.md</code> to reflect the completion of all Phase 1 tasks and milestones. M1.5 Medium Open P1.5.4 Conduct a review of Phase 1 deliverables and plan for Phase 2. M1.5 High Open"},{"location":"project-status/#phase-2-data-cleansing-and-preprocessing","title":"Phase 2: Data Cleansing and Preprocessing","text":"<p>Overall Phase Objective: To transform raw collected data (from both historical CSVs and ongoing HKJC scrapes) into a clean, consistent, and usable dataset. This includes harmonizing different data structures, handling missing values, and preparing data for exploratory analysis and feature engineering.</p> <p>Current Status: Not Started</p>"},{"location":"project-status/#phase-2-milestones","title":"Phase 2 Milestones","text":"<ul> <li>M2.1: Harmonize Historical and Current Incident Report Data: Address structural differences between historical comprehensive race reports and current incident-focused reports. This includes integrating \"Comments on Running\" with \"Full Stewards' Reports\" and attempting to align data for a cohesive longitudinal dataset, potentially deferring LLM-based nuanced extraction if current cost/reliability issues persist (see Week 4 Decisions).</li> </ul>"}]}