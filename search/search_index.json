{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"HK Racing Project","text":"<p>Executive Summary The HK Racing Project is a data-driven initiative to ingest, model, and analyze horse racing data from the Hong Kong Jockey Club. Our goal is to build a robust end-to-end pipeline\u2014covering data collection, schema design, pipeline orchestration, and analytics dashboards\u2014to enable rapid iteration on performance metrics and machine-learning models.</p> <p>Objectives - Ingest race results, horse and jockey data, and betting odds into BigQuery. - Define a clear, version-controlled data model and dictionary. - Build an automated pipeline (Google Sheets + GCS + BigQuery). - Deliver KPI dashboards and exploratory notebooks for analytics and ML.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ol> <li>Phase 1: Project Definition</li> <li>Phase 2: Data Collection &amp; Storage</li> <li>Phase 3: Data Cleansing &amp; Pre-processing</li> <li>Phase 4: Exploratory Data Analysis</li> <li>Phase 5: Feature Engineering</li> <li>Phase 6: Model Development</li> <li>Phase 7: Model Evaluation</li> <li>Phase 8: Deployment &amp; Monitoring</li> <li>Phase 9: Project Management &amp; Documentation</li> <li>Project Status</li> <li>Decisions</li> <li>Milestones</li> </ol>"},{"location":"decisions/","title":"Key Project Decisions","text":"<p>This document tracks the major design and process decisions for the HK Racing Project, along with context, alternatives considered, and rationale.</p> Date Decision Aspect Alternatives Considered Rationale / Notes 2025-05-04 Use MkDocs + Material theme for docs site Documentation GitHub Pages from <code>/docs</code>, Jekyll Better theming, built-in nav sidebar 2025-05-04 Deploy docs via GitHub Actions to <code>gh-pages</code> CI/CD Manual Pages from <code>/docs</code> folder Full control over build, future plugins 2025-05-05 Design repo for AI-only assistance; skip human-centric features Repository Setup Public repo setup, contributor templates, open-source guidelines Ensures proprietary strategies remain private, limits liability; sharing steps can be added later 2025-05-06 Configure pre-commit hooks for code and notebooks Tooling Manual formatting, commit-by-commit cleaning Automate code style enforcement and strip notebook outputs 2025-05-06 Add GitHub Actions workflows for CI and docs deploy CI/CD Manual test and docs builds Automatically lint, test, and deploy docs on push 2025-05-06 Establish branch protection rules on main Process Unrestricted direct pushes Ensure all changes are reviewed and pass CI before merge 2025-05-06 Create GitHub issue and PR templates Process Freeform issues and PR descriptions Standardize issue reporting and PR reviews 2025-05-06 Scaffold Makefile and setup scripts for environment Developer DX Manual venv creation and pip installs Provide reproducible one-command environment bootstrapping 2025-05-06 Rolled back branch protection rules for personal repo Process Enforced PR and status checks Simplify workflow for solo development; allow direct pushes 2025-05-08 Updated GitHub Pages setup and streamlined milestone tracking Documentation, Project Management Manual tracking, individual project boards Simplify the process with GitHub Issues and checkboxes for clarity and task management 2025-05-08 Remove GitHub Project board and house issues in Markdown Process Online project board Centralize issue tracking within repository docs 2025-05-XX (future decision)"},{"location":"milestones/","title":"Milestones &amp; Tasks","text":"<p>This document tracks the key milestones and tasks for the HK Racing project. Each task is broken down with goals, reasons for the task, tags, and expected output. As tasks are completed, links to corresponding GitHub Issues will be added.</p>"},{"location":"milestones/#phase-1-project-definition","title":"Phase 1 \u2013 Project Definition","text":"<ul> <li>[ ] Define Objectives &amp; Success Criteria</li> <li>Goal: Outline the project's primary objectives and success criteria.</li> <li>Why: To clearly define the project\u2019s direction and measurable outcomes.</li> <li>Tags: project, objectives, success criteria</li> <li> <p>Output: A documented list of objectives and success criteria.</p> </li> <li> <p>[ ] Configure Local &amp; Cloud Environments</p> </li> <li>Goal: Set up local development environment, GCP project, and associated services.</li> <li>Why: Ensures all dependencies and cloud services are ready for the project.</li> <li>Tags: setup, environment, GCP, local</li> <li>Output: Fully configured local dev environment and GCP project with necessary access.</li> </ul>"},{"location":"milestones/#phase-2-data-collection-storage","title":"Phase 2 \u2013 Data Collection &amp; Storage","text":"<ul> <li>[ ] Implement Basic Race Results Scraper</li> <li>Goal: Develop a scraper to retrieve race results from HKJC\u2019s website.</li> <li>Why: This scraper will serve as the foundation for data collection.</li> <li>Tags: scraping, race results, HTML</li> <li> <p>Output: A working scraper saving data in raw format (CSV/JSON).</p> </li> <li> <p>[ ] Create Raw Data Storage Schema</p> </li> <li>Goal: Design the folder structure for storing raw scraped data.</li> <li>Why: Consistent organization of data will simplify processing.</li> <li>Tags: storage, data management, schema</li> <li> <p>Output: Defined directory structure for raw data in BigQuery/GCS.</p> </li> <li> <p>[ ] Implement Retry Logic for Scraper Functions</p> </li> <li>Goal: Add retry mechanisms (e.g., tenacity, exponential backoff) to scraper functions.</li> <li>Why: To make the scraper more resilient to network failures and HTML structure changes.</li> <li>Tags: scraping, retry logic, resilience</li> <li>Output: A retry decorator or class that can be reused across scrapers.</li> </ul>"},{"location":"milestones/#phase-3-data-cleansing-pre-processing","title":"Phase 3 \u2013 Data Cleansing &amp; Pre-processing","text":"<ul> <li>[ ] Implement Data Validation Checks</li> <li>Goal: Ensure the scraped data is valid and clean before processing.</li> <li>Why: To ensure that we work with high-quality data from the start.</li> <li>Tags: data quality, validation, cleansing</li> <li>Output: Validation scripts for data checking.</li> </ul>"},{"location":"milestones/#future-phases-to-be-defined-later","title":"Future Phases (To be defined later)","text":"<ul> <li>[ ] Exploratory Data Analysis (EDA)</li> <li>Goal: Perform initial analysis to understand trends and patterns.</li> <li>Why: EDA will guide the feature engineering and modeling steps.</li> <li>Tags: analysis, EDA, data exploration</li> <li>Output: EDA notebook with key insights.</li> </ul>"},{"location":"phase-01-definition/","title":"Phase 1: Project Definition and Establishment","text":""},{"location":"phase-01-definition/#11-introduction-and-aims","title":"1.1 Introduction and Aims","text":""},{"location":"phase-01-definition/#111-project-objective","title":"1.1.1 Project Objective","text":"<ul> <li>Goal: Develop and implement a machine learning-based handicapping and wagering system aimed at generating a positive return on investment (ROI) from Hong Kong horse racing.</li> <li>Team: Solo project with assistance from Google Gemini.</li> <li>Broader Context: This project focuses on the technical development of a predictive system for financial gain within the domain of horse race wagering. It's acknowledged that this operates within the context of gambling, and responsible practices should guide any potential future application of the system's outputs.</li> </ul>"},{"location":"phase-01-definition/#112-document-purpose","title":"1.1.2 Document Purpose","text":"<p>This document serves several key purposes for the Hong Kong Racing Project: * Centralized Record: Acts as the primary repository for documenting all project plans, methodologies, data sources, findings, and decisions made throughout the project lifecycle. This ensures a comprehensive record of the work undertaken. * Shared Memory for AI Collaboration: Functions as a persistent memory and context for ongoing work and discussions with Google Gemini. By referencing and updating this document, particularly a \"Project Status\" section (in <code>docs/project-status.md</code>), we can ensure continuity across multiple sessions, avoid repeating previous discussions, and efficiently build upon prior work, analyses, and conclusions. * Single Source of Truth: Establishes a definitive reference point for the project's scope, workflow, tools, challenges, and results, reducing ambiguity. * Tracking Evolution: Tracks the project's evolution, including changes in strategy, feature engineering approaches, model selection, and key decisions over time. * Workflow for Collaboration:     * Start of Session: The latest version of project documentation will be reviewed.     * Context Review: The \"Project Status\" section will be reviewed to understand the current project state and immediate next steps.     * Execution: Work on the project tasks will proceed based on the reviewed status.     * End of Session Update: The \"Project Status\" section will be updated to reflect tasks completed, decisions made, and the next steps agreed upon before concluding the session. This ensures the documentation always represents the latest project state.</p>"},{"location":"phase-01-definition/#12-resource-and-environment-configuration","title":"1.2 Resource and Environment Configuration","text":""},{"location":"phase-01-definition/#121-hardware","title":"1.2.1 Hardware","text":"<ul> <li>Local machine: MacBook Air, 8GB RAM, Apple Silicon (M1 chip).</li> <li>Online: Standard Colab CPU Environment (e.g., Intel Xeon, ~13 GB RAM).</li> <li>Note: Google Colab free tier also provides access to GPU (often NVIDIA K80) and TPU accelerators, but availability, specific models, and usage limits are variable and not guaranteed.</li> </ul>"},{"location":"phase-01-definition/#122-software-and-cloud-services-google-ecosystem","title":"1.2.2 Software and Cloud Services (Google Ecosystem)","text":"<p>This project primarily utilizes the Google Cloud ecosystem and related tools for data storage, processing, analysis, and machine learning: * Google BigQuery: Serves as the central data warehouse for storing historical and current race data. Used for scalable storage and potentially light data cleaning or querying. Chosen for its scalability, seamless integration with Colab, and cost-effectiveness within the free tier. * Google Colab: The primary environment for data cleaning, analysis, feature engineering, visualization, and machine learning model development and training[cite: 758]. Leverages free tier CPU, GPU, and TPU resources[cite: 759]. Integrates directly with BigQuery and Google Sheets[cite: 759]. * Google Sheets: Used as a central hub for managing data before uploading to BigQuery, potentially for manual input or initial formatting, and for controlling updates via Apps Script[cite: 760]. * Google Apps Script: Planned for automating the biweekly data update process from Google Sheets to BigQuery[cite: 761]. * Google Cloud Storage (GCS): Considered as an alternative or intermediary step for exporting data from BigQuery (as Parquet files) to Colab, potentially avoiding query costs[cite: 762]. * Related Python Libraries:     * Beautiful Soup: For web scraping HKJC data[cite: 763].     * pandas, NumPy, Polars: For data manipulation and feature engineering[cite: 764].     * <code>google-cloud-bigquery</code>: For interacting with BigQuery from Colab[cite: 765].     * Plotly: For interactive data visualization[cite: 765].     * Machine learning libraries (e.g., Scikit-learn, TensorFlow, PyTorch - specific choices mentioned in Phase 6)[cite: 766].</p>"},{"location":"phase-01-definition/#123-development-environment-colab-vs-code","title":"1.2.3 Development Environment (Colab, VS Code)","text":"<p>The project utilizes a combination of cloud-based and local environments for different tasks[cite: 767]: * Google Colab: This is the primary environment for computationally intensive tasks, including[cite: 767]:     * Data cleaning, exploration (EDA), and visualization (using libraries like Plotly)[cite: 767].     * Feature engineering using Python libraries (pandas, NumPy, Polars)[cite: 768].     * Machine learning model development, training, and validation, leveraging Colab's free access to GPU/TPU resources[cite: 768].     * Direct interaction with Google BigQuery for data querying[cite: 769]. * Visual Studio Code (VS Code) - Local: Used on the local machine (MacBook Air) primarily for[cite: 769]:     * Development of helper scripts, such as those interacting with Google Sheets APIs or potentially Google Apps Script development, if needed outside the cloud editor[cite: 769].     * Managing code versions locally before potentially pushing to a repository (though version control is currently implicit via Google Docs in the original plan, now shifting to Git with this repo structure)[cite: 770].</p>"},{"location":"phase-01-definition/#13-proposed-workflow-outline","title":"1.3 Proposed Workflow Outline","text":""},{"location":"phase-01-definition/#131-rationale-for-hybrid-workflow-sheets-bigquery-colab","title":"1.3.1 Rationale for Hybrid Workflow (Sheets -&gt; BigQuery -&gt; Colab)","text":"<p>The chosen workflow utilizes a hybrid approach leveraging Google Sheets, BigQuery (both External and Native tables), and Google Colab[cite: 771]. This specific architecture was selected primarily to balance the critical need for easy data correction with the performance requirements of data analysis and machine learning[cite: 772]. * Ease of Data Correction: The primary driver is the need for a straightforward method to correct data inaccuracies[cite: 773]. Historical data contains known minor inconsistencies[cite: 774]. Using Google Sheets as the primary, editable data source allows for quick manual fixes[cite: 775]. BigQuery External Tables link directly to these sheets[cite: 776]. * Analytical Performance: To overcome performance limitations of querying Sheets directly, data is periodically materialized into a native BigQuery table[cite: 776]. All downstream analytical tasks query this optimized, native table[cite: 777]. * Scalability: Native BigQuery storage provides excellent scalability[cite: 778]. * Resource Efficiency: Computationally intensive tasks are offloaded to Google Colab[cite: 779]. * Integration &amp; Control: Google ecosystem tools integrate effectively[cite: 780]. Google Sheets, potentially with Apps Script, provides centralized control for refreshing the native BigQuery table[cite: 781]. * Cost-Effectiveness: Leverages free tiers of Google Cloud services where possible[cite: 782]. This hybrid model prioritizes straightforward data maintenance via Google Sheets while ensuring query performance for analysis by using native BigQuery tables[cite: 783].</p>"},{"location":"phase-01-definition/#132-alternative-methodologies-considered","title":"1.3.2 Alternative Methodologies Considered","text":"<p>Several alternatives were evaluated and rejected because they didn't adequately balance ease of data correction, analytical performance, scalability, and resource efficiency[cite: 784, 785]: * DuckDB (Local) + Colab:     * Description: Store data locally in DuckDB, process/clean locally, export to Colab for ML[cite: 785].     * Pros: Fast local analytics, free[cite: 786].     * Cons &amp; Why Rejected: Limited by local 8GB RAM; manual data export to Colab; correcting data in DuckDB less straightforward than Sheets[cite: 786, 787]. * Pandas/Polars (Local only):     * Description: Process data entirely in memory locally[cite: 788].     * Pros: Flexible for initial exploration[cite: 788].     * Cons &amp; Why Rejected: Unsustainable on 8GB RAM as data/features grow; lacks BigQuery's persistence and scalability; data correction is ephemeral[cite: 789, 790]. * SQLite (Local):     * Description: Use SQLite as a local database[cite: 791].     * Pros: Lightweight, embedded[cite: 791].     * Cons &amp; Why Rejected: Row-based storage less performant for analytical queries compared to columnar BigQuery; local resource limits still apply[cite: 792, 793]. * PostgreSQL (Local):     * Description: Run a local PostgreSQL server[cite: 793].     * Pros: Robust relational database features[cite: 793].     * Cons &amp; Why Rejected: High overhead and resource demands unsuitable for local hardware[cite: 794, 795]. * Snowflake (Cloud):     * Description: Use Snowflake as a cloud data warehouse[cite: 796].     * Pros: Scalable and performant like BigQuery[cite: 796].     * Cons &amp; Why Rejected: Lacks a comparable free tier to BigQuery, less cost-effective for this project[cite: 797].</p> <p>The hybrid workflow (Sheets -&gt; External BQ Table -&gt; Native BQ Table -&gt; Colab) was selected as it best balances data correction, performance, scalability, resource efficiency, and cost-effectiveness[cite: 798].</p>"},{"location":"phase-02-collection/","title":"Phase 2 \u2013 Data Collection &amp; Storage","text":""},{"location":"phase-02-collection/#21-source-inventory","title":"2.1 Source Inventory","text":"<ul> <li>Racecards pages (upcoming races)</li> <li>Historical result pages (per race)</li> <li>Stewards\u2019 reports pages (meeting summaries)</li> <li>Horse profile pages (breeding, trackwork, vet records, etc.)</li> <li>Betting odds pages (pre-race odds snapshots)</li> </ul>"},{"location":"phase-02-collection/#22-access-authentication","title":"2.2 Access &amp; Authentication","text":"<ul> <li>No API keys required (public website scraping)</li> <li>Respect robots.txt and site terms of service</li> <li>Rate-limit throttling to avoid hammering the site</li> <li>Optional VPN or IP-rotation strategy to mitigate blocking</li> </ul>"},{"location":"phase-02-collection/#23-web-scraping-design","title":"2.3 Web-Scraping Design","text":"<ul> <li>Stack: BeautifulSoup / Selenium / Playwright choice</li> <li>Pagination &amp; dynamic content (JS-rendered pages)</li> <li>Retry logic &amp; exponential back-off on failures</li> <li>HTML parsing: robust CSS/XPath selectors and schema validation</li> </ul>"},{"location":"phase-02-collection/#24-raw-storage-schema","title":"2.4 Raw Storage Schema","text":"<ul> <li>Storage: Google Cloud Storage (GCS) or BigQuery staging</li> <li>Folder layout:   <code>raw/   \u251c\u2500\u2500 racecards/YYYY-MM-DD/   \u251c\u2500\u2500 results/YYYY-MM-DD/   \u251c\u2500\u2500 stewards/YYYY-MM-DD/   \u2514\u2500\u2500 horses/YYYY-MM-DD/</code> -- Formats: JSON or Parquet for downstream processing</li> </ul>"},{"location":"phase-02-collection/#25-incremental-vs-full-loads","title":"2.5 Incremental vs Full Loads","text":"<ul> <li>Full refresh when meeting date changes or schema updates</li> <li>Delta detection via on-page timestamps or URL patterns</li> <li>Schedule: twice weekly (per HKJC calendar) or on-demand before each race meeting</li> </ul>"},{"location":"phase-02-collection/#26-data-ingestion-orchestration","title":"2.6 Data Ingestion Orchestration","text":"<ul> <li>Orchestration: Airflow / Cloud Composer</li> <li>DAG design:</li> <li>Fetch racecards</li> <li>Scrape results &amp; reports</li> <li>Scrape horse profiles &amp; odds</li> <li>Store raw files in GCS / BQ staging</li> <li>Monitoring &amp; Alerts: track success/failure counts, notify on missed scrapes</li> </ul>"},{"location":"phase-02-collection/#27-collection-success-metrics","title":"2.7 Collection Success Metrics","text":"<ul> <li>[ ] \u2265 95% of pages scraped successfully (per meeting)</li> <li>[ ] Retry count \u2264 3 per page before alerting</li> <li>[ ] SLA: all data available within 1 hour of meeting close</li> </ul> <p>Next Steps: 1. Review these headings and adjust any items. 2. Create GitHub Issues for the first tasks (e.g. \u201cImplement racecards scraper\u201d, \u201cSet up raw storage bucket\u201d). 3. As each Issue is closed, fill in its subsection with code snippets and example outputs.</p>"},{"location":"phase-03-cleansing/","title":"Phase 3","text":"<p>Phase\u00a03\u00a0\u2013\u00a0Data\u202fCleansing &amp; Pre\u2011processing (phase-03-cleansing.md)</p> <p>3.1\u202fData\u00a0Profiling &amp; Quality Checks 3.2\u202fStandardization Rules 3.3\u202fHandling Missing &amp; Anomalous Values 3.4\u202fNormalization &amp; Encoding 3.5\u202fPartitioning Strategy (BigQuery) 3.6\u202fAutomated Validation Tests 3.7\u202fCleansed Layer KPIs</p>"},{"location":"phase-04-eda/","title":"Phase 4","text":"<p>Phase\u00a04\u00a0\u2013\u00a0Exploratory\u202fData\u202fAnalysis (phase-04-eda.md)</p> <p>4.1\u202fExploration Notebook Index 4.2\u202fDescriptive Statistics 4.3\u202fRace &amp; Horse Performance Trends 4.4\u202fCorrelation Heatmaps 4.5\u202fFeature Importance Probes 4.6\u202fEDA Findings Summary</p>"},{"location":"phase-05-features/","title":"Phase 5","text":"<p>Phase\u00a05\u00a0\u2013\u00a0Feature Engineering (phase-05-features.md)</p> <p>5.1\u202fFeature List &amp; Definitions 5.2\u202fRolling Window Calculations 5.3\u202fCategorical Encodings 5.4\u202fTarget Variable Construction 5.5\u202fFeature Store Schema 5.6\u202fFeature Quality Metrics</p>"},{"location":"phase-06-model/","title":"Phase 6","text":"<p>Phase\u00a06\u00a0\u2013\u00a0Model Development (phase-06-model.md)</p> <p>6.1\u202fModelling Objectives 6.2\u202fTrain/Validation Split Strategy 6.3\u202fBaseline Models 6.4\u202fHyper\u2011parameter Tuning Plan 6.5\u202fModel Versioning &amp; Registry 6.6\u202fTraining Pipeline Automation</p>"},{"location":"phase-07-evaluation/","title":"Phase 7","text":"<p>Phase\u00a07\u00a0\u2013\u00a0Model Evaluation (phase-07-evaluation.md)</p> <p>7.1\u202fEvaluation Metrics (AUC,\u00a0LogLoss, ROI) 7.2\u202fCross\u2011Validation Results 7.3\u202fBack\u2011testing on Historical Meets 7.4\u202fError Analysis &amp; Bias Checks 7.5\u202fModel Comparison Dashboard 7.6\u202fGo\u2011/No\u2011Go Decision Criteria</p>"},{"location":"phase-08-deployment/","title":"Phase 8","text":"<p>Phase\u00a08\u00a0\u2013\u00a0Deployment &amp; Monitoring (phase-08-deployment.md)</p> <p>8.1\u202fServing Architecture (Batch vs\u00a0Real\u2011time) 8.2\u202fInfrastructure as Code (Terraform) 8.3\u202fCI/CD Release Flow 8.4\u202fOnline Feature Retrieval 8.5\u202fModel Drift Detection 8.6\u202fAlerting &amp; Incident Response Runbook</p>"},{"location":"phase-09-management/","title":"Phase 9","text":"<p>Phase\u00a09\u00a0\u2013\u00a0Project Management &amp; Documentation (phase-09-management.md)</p> <p>9.1\u202fMilestone Tracking &amp; Burndown 9.2\u202fDecisions Log Maintenance 9.3\u202fRisk Register Updates 9.4\u202fBudget &amp; Cost Monitoring 9.5\u202fDocumentation Publishing Workflow 9.6\u202fLessons Learned / Post\u2011mortems 9.7\u202fFuture Roadmap</p>"},{"location":"project-status/","title":"Project Status","text":"<p>Last Manually Updated: 2025-05-08</p> <p>Overall Project Health: Green Initial setup and planning are progressing well. The new project structure and documentation plan are being finalized.</p> <p>Key Focus for This Week (ending 2025-05-09): - [ ] Complete the first draft of<code>project_plan.md</code> by incorporating all relevant content from the Google Doc. - [ ] Update the repository structure:     - [ ] Rename <code>docs/index.md</code> to <code>docs/project_plan.md</code>.     - [ ] Update <code>mkdocs.yml</code> to reflect <code>project_plan.md</code> as the new home.     - [ ] Rename existing <code>docs/phase-XX-*.md</code> files to align with the new phase numbering (e.g., <code>phase-02-collection.md</code> becomes <code>phase-01-collection.md</code>) and their role as reports.     - [ ] Delete the old <code>docs/milestones.md</code> file. - [ ] Review and confirm the proposed structure for this <code>project-status.md</code> file.</p>"},{"location":"project-status/#table-of-contents","title":"Table of Contents","text":"<p>This can be manually created or you can rely on MkDocs' auto-generated TOC for the page if your theme supports it well for long pages. - General Project Setup - Phase 1: Data Collection - Phase 2: Data Cleansing &amp; Preprocessing - Phase 3: Exploratory Data Analysis (EDA) - Phase 4: Feature Engineering - Phase 5: Model Development - Phase 6: Model Evaluation - Phase 7: Deployment - Phase 8: Ongoing Management &amp; Iteration</p>"},{"location":"project-status/#general-project-setup","title":"General Project Setup","text":"<p>(Tasks related to overall project infrastructure, documentation, and planning)</p> <p>Key Milestones: - [x] Initial project repository configured (<code>2025-05-06</code>) - [ ] <code>project_plan.md</code> created and populated from Google Doc (<code>YYYY-MM-DD</code>) - [ ] <code>mkdocs.yml</code> updated for new site structure (Target: <code>YYYY-MM-DD</code>) - [ ] All phase report Markdown files named and structured (Target: <code>YYYY-MM-DD</code>)</p> <p>Current Tasks &amp; TODOs: - [ ] Final review and sign-off on <code>project_plan.md</code>. - [ ] Rename existing <code>docs/phase-XX-*.md</code> files to new phase numbers and report focus. - [ ] Create template/outline for content expected in each phase report.</p> <p>Open Issues / Blockers: - None currently</p>"},{"location":"project-status/#phase-1-data-collection","title":"Phase 1: Data Collection","text":"<p>(Objective: To gather all necessary raw data from defined sources - see <code>project_plan.md</code> for details)</p> <p>Key Milestones: - [ ] All data sources and specific data fields fully identified and documented in <code>project_plan.md</code>. (Target: <code>YYYY-MM-DD</code>) - [ ] Web scraping scripts for HKJC racecards developed and tested. (Target: <code>YYYY-MM-DD</code>) - [ ] Web scraping scripts for HKJC race results developed and tested. (Target: <code>YYYY-MM-DD</code>) - [ ] Historical data (target: X seasons/Y race days) successfully collected. (Target: <code>YYYY-MM-DD</code>) - [ ] Initial storage solution for raw data implemented (e.g., GCS buckets, specific BigQuery raw tables). (Target: <code>YYYY-MM-DD</code>) - [ ] Report: <code>docs/phase-01-collection.md</code> completed and reviewed. (Target: <code>YYYY-MM-DD</code>)</p> <p>Current Tasks &amp; TODOs: - [ ] Draft <code>docs/phase-01-collection.md</code> structure. - [ ] Research and select Python library for web scraping (e.g., BeautifulSoup, Playwright). - [ ] Implement <code>scrape_race_dates()</code> function. - [ ] Begin initial scraping runs for a small sample of race days. - [ ] Define schema for raw racecard data.</p> <p>Open Issues / Blockers: - [ ] Uncertainty about HKJC website's tolerance for scraping frequency. - [ ] Need to define error handling and retry logic for scrapers.</p>"},{"location":"project-status/#phase-2-data-cleansing-preprocessing","title":"Phase 2: Data Cleansing &amp; Preprocessing","text":"<p>(Objective: To transform raw data into a clean, consistent, and usable format - see <code>project_plan.md</code> for details)</p> <p>Key Milestones: - [ ] Data quality issues and required cleansing steps defined. (Target: <code>YYYY-MM-DD</code>) - [ ] Scripts for data type conversion and standardization developed. (Target: <code>YYYY-MM-DD</code>) - [ ] Strategy for handling missing values and outliers defined and implemented. (Target: <code>YYYY-MM-DD</code>) - [ ] Cleansed dataset validated against defined quality criteria. (Target: <code>YYYY-MM-DD</code>) - [ ] Report: <code>docs/phase-02-cleansing.md</code> completed and reviewed. (Target: <code>YYYY-MM-DD</code>)</p> <p>Current Tasks &amp; TODOs: - [ ] Profile raw data to identify anomalies. - [ ] Develop script to convert date/time fields to consistent format. - [ ] Research imputation techniques for missing <code>HORSE_WEIGHT</code>.</p> <p>Open Issues / Blockers: - None currently</p>"},{"location":"project-status/#phase-3-exploratory-data-analysis-eda","title":"Phase 3: Exploratory Data Analysis (EDA)","text":"<p>(Objective: To understand data patterns, relationships, and formulate initial hypotheses - see <code>project_plan.md</code> for details)</p> <p>Key Milestones: - [ ] Initial descriptive statistics generated for all key variables. (Target: <code>YYYY-MM-DD</code>) - [ ] Key visualizations (distributions, correlations, etc.) created. (Target: <code>YYYY-MM-DD</code>) - [ ] Initial hypotheses about predictive factors documented. (Target: <code>YYYY-MM-DD</code>) - [ ] Report: <code>docs/phase-03-eda.md</code> completed and reviewed. (Target: <code>YYYY-MM-DD</code>)</p> <p>Current Tasks &amp; TODOs: - [ ] Set up EDA Jupyter notebook (<code>notebooks/01-race-eda.ipynb</code>). - [ ] Generate histograms for numerical features. - [ ] Calculate correlation matrix.</p> <p>Open Issues / Blockers: - None currently</p>"},{"location":"project-status/#phase-4-feature-engineering","title":"Phase 4: Feature Engineering","text":"<p>(Objective: To create new predictive features from the cleansed data - see <code>project_plan.md</code> for details)</p> <p>Key Milestones: - [ ] Initial set of engineered features designed and documented. (Target: <code>YYYY-MM-DD</code>) - [ ] Scripts to generate engineered features implemented. (Target: <code>YYYY-MM-DD</code>) - [ ] Feature set validated and stored. (Target: <code>YYYY-MM-DD</code>) - [ ] Report: <code>docs/phase-04-features.md</code> completed and reviewed. (Target: <code>YYYY-MM-DD</code>)</p> <p>Current Tasks &amp; TODOs: - [ ] Brainstorm potential features based on EDA insights. - [ ] Implement rolling average calculations for horse performance.</p> <p>Open Issues / Blockers: - None currently</p>"},{"location":"project-status/#phase-5-model-development","title":"Phase 5: Model Development","text":"<p>(Objective: To train and select predictive models - see <code>project_plan.md</code> for details)</p> <p>Key Milestones: - [ ] Baseline model(s) developed and evaluated. (Target: <code>YYYY-MM-DD</code>) - [ ] Advanced model(s) explored and trained. (Target: <code>YYYY-MM-DD</code>) - [ ] Hyperparameter tuning performed. (Target: <code>YYYY-MM-DD</code>) - [ ] Report: <code>docs/phase-05-modeling.md</code> completed and reviewed. (Target: <code>YYYY-MM-DD</code>)</p> <p>Current Tasks &amp; TODOs: - [ ] Select initial algorithm for baseline model (e.g., Logistic Regression). - [ ] Split data into training and testing sets.</p> <p>Open Issues / Blockers: - None currently</p>"},{"location":"project-status/#phase-6-model-evaluation","title":"Phase 6: Model Evaluation","text":"<p>(Objective: To rigorously assess model performance and potential profitability - see <code>project_plan.md</code> for details)</p> <p>Key Milestones: - [ ] Comprehensive backtesting strategy implemented. (Target: <code>YYYY-MM-DD</code>) - [ ] Key performance metrics (ROI, accuracy, etc.) calculated. (Target: <code>YYYY-MM-DD</code>) - [ ] Wagering strategy simulated and analyzed. (Target: <code>YYYY-MM-DD</code>) - [ ] Report: <code>docs/phase-06-evaluation.md</code> completed and reviewed. (Target: <code>YYYY-MM-DD</code>)</p> <p>Current Tasks &amp; TODOs: - [ ] Define metrics for successful model evaluation. - [ ] Develop backtesting framework.</p> <p>Open Issues / Blockers: - None currently</p>"},{"location":"project-status/#phase-7-deployment","title":"Phase 7: Deployment","text":"<p>(Objective: To set up a system for generating predictions on new races - see <code>project_plan.md</code> for details) (This phase might be more about setting up a repeatable prediction pipeline than a live betting system initially)</p> <p>Key Milestones: - [ ] Prediction generation pipeline designed. (Target: <code>YYYY-MM-DD</code>) - [ ] Pipeline implemented and tested. (Target: <code>YYYY-MM-DD</code>) - [ ] System for monitoring prediction performance outlined. (Target: <code>YYYY-MM-DD</code>) - [ ] Report: <code>docs/phase-07-deployment.md</code> completed and reviewed. (Target: <code>YYYY-MM-DD</code>)</p> <p>Current Tasks &amp; TODOs: - [ ] Design script to take new racecard data and output predictions.</p> <p>Open Issues / Blockers: - None currently</p>"},{"location":"project-status/#phase-8-ongoing-management-iteration","title":"Phase 8: Ongoing Management &amp; Iteration","text":"<p>(Objective: To maintain the system, monitor performance, and plan for future improvements - see <code>project_plan.md</code> for details)</p> <p>Key Milestones: - [ ] Retraining schedule and triggers defined. (Target: <code>YYYY-MM-DD</code>) - [ ] Long-term performance monitoring plan in place. (Target: <code>YYYY-MM-DD</code>) - [ ] Roadmap for future enhancements outlined. (Target: <code>YYYY-MM-DD</code>) - [ ] Report: <code>docs/phase-08-management.md</code> completed and reviewed. (Target: <code>YYYY-MM-DD</code>)</p> <p>Current Tasks &amp; TODOs: - [ ] Review project outcomes against initial objectives. - [ ] Document lessons learned.</p> <p>Open Issues / Blockers: - None currently</p>"}]}